10/12/2023 22:40:01 - INFO -   Effective parameters:
10/12/2023 22:40:01 - INFO -     <<< batch_size: 64
10/12/2023 22:40:01 - INFO -     <<< batch_size_val: 64
10/12/2023 22:40:01 - INFO -     <<< cache_dir: 
10/12/2023 22:40:01 - INFO -     <<< coef_lr: 0.001
10/12/2023 22:40:01 - INFO -     <<< cross_model: cross-base
10/12/2023 22:40:01 - INFO -     <<< cross_num_hidden_layers: 4
10/12/2023 22:40:01 - INFO -     <<< data_path: /home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/
10/12/2023 22:40:01 - INFO -     <<< dataset_ckpt: anet_train2_seed2
10/12/2023 22:40:01 - INFO -     <<< datatype: moviegraph
10/12/2023 22:40:01 - INFO -     <<< do_eval: False
10/12/2023 22:40:01 - INFO -     <<< do_lower_case: False
10/12/2023 22:40:01 - INFO -     <<< do_pretrain: False
10/12/2023 22:40:01 - INFO -     <<< do_train: True
10/12/2023 22:40:01 - INFO -     <<< epochs: 5
10/12/2023 22:40:01 - INFO -     <<< eval_frame_order: 0
10/12/2023 22:40:01 - INFO -     <<< expand_msrvtt_sentences: False
10/12/2023 22:40:01 - INFO -     <<< feature_framerate: 1
10/12/2023 22:40:01 - INFO -     <<< features_path: /home/wiss/zhang/nfs/Anet-compressed
10/12/2023 22:40:01 - INFO -     <<< fp16: False
10/12/2023 22:40:01 - INFO -     <<< fp16_opt_level: O1
10/12/2023 22:40:01 - INFO -     <<< freeze_layer_num: 0
10/12/2023 22:40:01 - INFO -     <<< gradient_accumulation_steps: 1
10/12/2023 22:40:01 - INFO -     <<< hard_negative_rate: 0.5
10/12/2023 22:40:01 - INFO -     <<< init_model: /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2/pytorch_model.bin.2
10/12/2023 22:40:01 - INFO -     <<< linear_patch: 2d
10/12/2023 22:40:01 - INFO -     <<< local_rank: 0
10/12/2023 22:40:01 - INFO -     <<< loose_type: True
10/12/2023 22:40:01 - INFO -     <<< lr: 0.0001
10/12/2023 22:40:01 - INFO -     <<< lr_decay: 0.9
10/12/2023 22:40:01 - INFO -     <<< manipulation: anet_train2_seed2
10/12/2023 22:40:01 - INFO -     <<< margin: 0.1
10/12/2023 22:40:01 - INFO -     <<< max_frames: 12
10/12/2023 22:40:01 - INFO -     <<< max_words: 60
10/12/2023 22:40:01 - INFO -     <<< n_display: 1
10/12/2023 22:40:01 - INFO -     <<< n_gpu: 1
10/12/2023 22:40:01 - INFO -     <<< n_pair: 1
10/12/2023 22:40:01 - INFO -     <<< negative_weighting: 1
10/12/2023 22:40:01 - INFO -     <<< num_thread_reader: 16
10/12/2023 22:40:01 - INFO -     <<< output_dir: /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue
10/12/2023 22:40:01 - INFO -     <<< pretrained_clip_name: ViT-B/32
10/12/2023 22:40:01 - INFO -     <<< rank: 0
10/12/2023 22:40:01 - INFO -     <<< resume_model: None
10/12/2023 22:40:01 - INFO -     <<< sampled_use_mil: False
10/12/2023 22:40:01 - INFO -     <<< scale: 0
10/12/2023 22:40:01 - INFO -     <<< seed: 2
10/12/2023 22:40:01 - INFO -     <<< sim_header: seqTransf
10/12/2023 22:40:01 - INFO -     <<< slice_framepos: 2
10/12/2023 22:40:01 - INFO -     <<< task_type: retrieval
10/12/2023 22:40:01 - INFO -     <<< test_file: temporal_contact_swap.csv
10/12/2023 22:40:01 - INFO -     <<< text_num_hidden_layers: 12
10/12/2023 22:40:01 - INFO -     <<< train_csv: data/.train.csv
10/12/2023 22:40:01 - INFO -     <<< train_file: train_2.csv
10/12/2023 22:40:01 - INFO -     <<< train_frame_order: 0
10/12/2023 22:40:01 - INFO -     <<< use_mil: False
10/12/2023 22:40:01 - INFO -     <<< val_csv: data/.val.csv
10/12/2023 22:40:01 - INFO -     <<< val_file: temporal_contact_swap.csv
10/12/2023 22:40:01 - INFO -     <<< video_dim: 1024
10/12/2023 22:40:01 - INFO -     <<< visual_num_hidden_layers: 12
10/12/2023 22:40:01 - INFO -     <<< warmup_proportion: 0.1
10/12/2023 22:40:01 - INFO -     <<< world_size: 2
10/12/2023 22:40:01 - INFO -   device: cuda:0 n_gpu: 2
10/12/2023 22:40:01 - INFO -   device: cuda:1 n_gpu: 2
10/12/2023 22:40:13 - INFO -   loading archive file /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base
10/12/2023 22:40:13 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

10/12/2023 22:40:13 - INFO -   Weight doesn't exsits. /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base/cross_pytorch_model.bin
10/12/2023 22:40:13 - WARNING -   Stage-One:True, Stage-Two:False
10/12/2023 22:40:13 - WARNING -   Test retrieval by loose type.
10/12/2023 22:40:13 - WARNING -   	 embed_dim: 512
10/12/2023 22:40:13 - WARNING -   	 image_resolution: 224
10/12/2023 22:40:13 - WARNING -   	 vision_layers: 12
10/12/2023 22:40:13 - WARNING -   	 vision_width: 768
10/12/2023 22:40:13 - WARNING -   	 vision_patch_size: 32
10/12/2023 22:40:13 - WARNING -   	 context_length: 77
10/12/2023 22:40:13 - WARNING -   	 vocab_size: 49408
10/12/2023 22:40:13 - WARNING -   	 transformer_width: 512
10/12/2023 22:40:13 - WARNING -   	 transformer_heads: 8
10/12/2023 22:40:13 - WARNING -   	 transformer_layers: 12
10/12/2023 22:40:13 - WARNING -   		 linear_patch: 2d
10/12/2023 22:40:13 - WARNING -   	 cut_top_layer: 0
10/12/2023 22:40:16 - WARNING -   	 sim_header: seqTransf
10/12/2023 22:40:28 - INFO -   --------------------
10/12/2023 22:40:28 - INFO -   Weights from pretrained model not used in XCLIP: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
10/12/2023 22:40:44 - INFO -   ***** Running test *****
10/12/2023 22:40:44 - INFO -     Num examples = 184
10/12/2023 22:40:44 - INFO -     Batch size = 64
10/12/2023 22:40:44 - INFO -     Num steps = 3
10/12/2023 22:40:44 - INFO -   ***** Running val *****
10/12/2023 22:40:44 - INFO -     Num examples = 184
10/12/2023 22:40:48 - INFO -   ***** Running training *****
10/12/2023 22:40:48 - INFO -     Num examples = 9155
10/12/2023 22:40:48 - INFO -     Batch size = 64
10/12/2023 22:40:48 - INFO -     Num steps = 715
10/13/2023 00:05:03 - INFO -   Epoch: 1/5, Step: 1/143, Lr: 0.000000001-0.000001399, Loss: 0.599204, Time/step: 5054.678829
10/13/2023 00:13:02 - INFO -   Epoch: 1/5, Step: 2/143, Lr: 0.000000003-0.000002797, Loss: 0.368404, Time/step: 478.507462
10/13/2023 00:13:12 - INFO -   Epoch: 1/5, Step: 3/143, Lr: 0.000000004-0.000004196, Loss: 0.589261, Time/step: 10.379857
10/13/2023 00:13:23 - INFO -   Epoch: 1/5, Step: 4/143, Lr: 0.000000006-0.000005594, Loss: 0.445356, Time/step: 11.218309
10/13/2023 00:37:09 - INFO -   Epoch: 1/5, Step: 5/143, Lr: 0.000000007-0.000006993, Loss: 0.726536, Time/step: 1425.184620
10/13/2023 00:37:20 - INFO -   Epoch: 1/5, Step: 6/143, Lr: 0.000000008-0.000008392, Loss: 0.428186, Time/step: 11.135514
10/13/2023 00:37:30 - INFO -   Epoch: 1/5, Step: 7/143, Lr: 0.000000010-0.000009790, Loss: 0.559911, Time/step: 10.634469
10/13/2023 00:37:41 - INFO -   Epoch: 1/5, Step: 8/143, Lr: 0.000000011-0.000011189, Loss: 0.438891, Time/step: 10.744226
10/13/2023 00:37:52 - INFO -   Epoch: 1/5, Step: 9/143, Lr: 0.000000013-0.000012587, Loss: 0.533805, Time/step: 10.747597
10/13/2023 00:38:03 - INFO -   Epoch: 1/5, Step: 10/143, Lr: 0.000000014-0.000013986, Loss: 0.613359, Time/step: 10.612274
10/13/2023 00:38:13 - INFO -   Epoch: 1/5, Step: 11/143, Lr: 0.000000015-0.000015385, Loss: 0.448437, Time/step: 10.618802
10/13/2023 00:38:24 - INFO -   Epoch: 1/5, Step: 12/143, Lr: 0.000000017-0.000016783, Loss: 0.541270, Time/step: 11.043575
10/13/2023 00:38:35 - INFO -   Epoch: 1/5, Step: 13/143, Lr: 0.000000018-0.000018182, Loss: 0.390601, Time/step: 10.576066
10/13/2023 00:38:46 - INFO -   Epoch: 1/5, Step: 14/143, Lr: 0.000000020-0.000019580, Loss: 0.390147, Time/step: 11.564077
10/13/2023 00:38:58 - INFO -   Epoch: 1/5, Step: 15/143, Lr: 0.000000021-0.000020979, Loss: 0.537476, Time/step: 11.195069
10/13/2023 00:39:08 - INFO -   Epoch: 1/5, Step: 16/143, Lr: 0.000000022-0.000022378, Loss: 0.326406, Time/step: 10.470032
10/13/2023 01:55:30 - INFO -   Epoch: 1/5, Step: 17/143, Lr: 0.000000024-0.000023776, Loss: 0.537232, Time/step: 4581.979781
10/13/2023 01:57:03 - INFO -   Epoch: 1/5, Step: 18/143, Lr: 0.000000025-0.000025175, Loss: 0.294205, Time/step: 92.744377
10/13/2023 01:57:13 - INFO -   Epoch: 1/5, Step: 19/143, Lr: 0.000000027-0.000026573, Loss: 0.450097, Time/step: 10.640978
10/13/2023 01:57:24 - INFO -   Epoch: 1/5, Step: 20/143, Lr: 0.000000028-0.000027972, Loss: 0.519347, Time/step: 10.216396
10/13/2023 02:04:14 - INFO -   Epoch: 1/5, Step: 21/143, Lr: 0.000000029-0.000029371, Loss: 0.279676, Time/step: 410.538259
10/13/2023 02:04:26 - INFO -   Epoch: 1/5, Step: 22/143, Lr: 0.000000031-0.000030769, Loss: 0.492028, Time/step: 11.166203
10/13/2023 02:04:36 - INFO -   Epoch: 1/5, Step: 23/143, Lr: 0.000000032-0.000032168, Loss: 0.485861, Time/step: 10.616869
10/13/2023 02:04:46 - INFO -   Epoch: 1/5, Step: 24/143, Lr: 0.000000034-0.000033566, Loss: 0.384968, Time/step: 10.203505
10/13/2023 02:04:57 - INFO -   Epoch: 1/5, Step: 25/143, Lr: 0.000000035-0.000034965, Loss: 0.478947, Time/step: 10.583805
10/13/2023 02:05:08 - INFO -   Epoch: 1/5, Step: 26/143, Lr: 0.000000036-0.000036364, Loss: 0.454908, Time/step: 11.012269
10/13/2023 02:05:19 - INFO -   Epoch: 1/5, Step: 27/143, Lr: 0.000000038-0.000037762, Loss: 0.368169, Time/step: 10.743177
10/13/2023 02:09:13 - INFO -   Epoch: 1/5, Step: 28/143, Lr: 0.000000039-0.000039161, Loss: 0.415905, Time/step: 233.904514
10/13/2023 02:09:23 - INFO -   Epoch: 1/5, Step: 29/143, Lr: 0.000000041-0.000040559, Loss: 0.658074, Time/step: 10.002088
10/13/2023 02:09:33 - INFO -   Epoch: 1/5, Step: 30/143, Lr: 0.000000042-0.000041958, Loss: 0.451193, Time/step: 9.880464
10/13/2023 02:09:43 - INFO -   Epoch: 1/5, Step: 31/143, Lr: 0.000000043-0.000043357, Loss: 0.450972, Time/step: 10.757032
10/13/2023 02:09:54 - INFO -   Epoch: 1/5, Step: 32/143, Lr: 0.000000045-0.000044755, Loss: 0.470522, Time/step: 10.563531
10/13/2023 03:49:28 - INFO -   Epoch: 1/5, Step: 33/143, Lr: 0.000000046-0.000046154, Loss: 0.412713, Time/step: 5974.168032
10/13/2023 03:49:38 - INFO -   Epoch: 1/5, Step: 34/143, Lr: 0.000000048-0.000047552, Loss: 0.428125, Time/step: 9.863718
10/13/2023 03:49:49 - INFO -   Epoch: 1/5, Step: 35/143, Lr: 0.000000049-0.000048951, Loss: 0.389544, Time/step: 10.549925
10/13/2023 03:49:59 - INFO -   Epoch: 1/5, Step: 36/143, Lr: 0.000000050-0.000050350, Loss: 0.458140, Time/step: 10.339247
10/13/2023 03:50:09 - INFO -   Epoch: 1/5, Step: 37/143, Lr: 0.000000052-0.000051748, Loss: 0.284348, Time/step: 9.757256
10/13/2023 03:50:19 - INFO -   Epoch: 1/5, Step: 38/143, Lr: 0.000000053-0.000053147, Loss: 0.461615, Time/step: 10.371396
10/13/2023 03:50:29 - INFO -   Epoch: 1/5, Step: 39/143, Lr: 0.000000055-0.000054545, Loss: 0.413604, Time/step: 10.364023
10/13/2023 03:50:39 - INFO -   Epoch: 1/5, Step: 40/143, Lr: 0.000000056-0.000055944, Loss: 0.536779, Time/step: 9.563610
10/13/2023 03:50:49 - INFO -   Epoch: 1/5, Step: 41/143, Lr: 0.000000057-0.000057343, Loss: 0.412586, Time/step: 10.380993
10/13/2023 03:50:59 - INFO -   Epoch: 1/5, Step: 42/143, Lr: 0.000000059-0.000058741, Loss: 0.440664, Time/step: 9.800468
10/13/2023 03:51:10 - INFO -   Epoch: 1/5, Step: 43/143, Lr: 0.000000060-0.000060140, Loss: 0.501010, Time/step: 10.072375
10/13/2023 03:51:20 - INFO -   Epoch: 1/5, Step: 44/143, Lr: 0.000000062-0.000061538, Loss: 0.246428, Time/step: 10.680538
10/13/2023 03:51:30 - INFO -   Epoch: 1/5, Step: 45/143, Lr: 0.000000063-0.000062937, Loss: 0.421014, Time/step: 10.071627
10/13/2023 03:51:42 - INFO -   Epoch: 1/5, Step: 46/143, Lr: 0.000000064-0.000064336, Loss: 0.361561, Time/step: 11.254030
10/13/2023 03:51:52 - INFO -   Epoch: 1/5, Step: 47/143, Lr: 0.000000066-0.000065734, Loss: 0.221195, Time/step: 10.268526
10/13/2023 03:52:03 - INFO -   Epoch: 1/5, Step: 48/143, Lr: 0.000000067-0.000067133, Loss: 0.301262, Time/step: 11.070474
10/13/2023 05:28:44 - INFO -   Epoch: 1/5, Step: 49/143, Lr: 0.000000069-0.000068531, Loss: 0.296914, Time/step: 5800.671015
10/13/2023 05:28:52 - INFO -   Epoch: 1/5, Step: 50/143, Lr: 0.000000070-0.000069930, Loss: 0.583060, Time/step: 8.619677
10/13/2023 05:29:02 - INFO -   Epoch: 1/5, Step: 51/143, Lr: 0.000000071-0.000071329, Loss: 0.500070, Time/step: 9.362853
10/13/2023 05:29:10 - INFO -   Epoch: 1/5, Step: 52/143, Lr: 0.000000073-0.000072727, Loss: 0.488598, Time/step: 8.584619
10/13/2023 05:29:19 - INFO -   Epoch: 1/5, Step: 53/143, Lr: 0.000000074-0.000074126, Loss: 0.318628, Time/step: 9.080066
10/13/2023 05:29:29 - INFO -   Epoch: 1/5, Step: 54/143, Lr: 0.000000076-0.000075524, Loss: 0.310775, Time/step: 9.324356
10/13/2023 05:29:38 - INFO -   Epoch: 1/5, Step: 55/143, Lr: 0.000000077-0.000076923, Loss: 0.374465, Time/step: 8.834375
10/13/2023 05:29:48 - INFO -   Epoch: 1/5, Step: 56/143, Lr: 0.000000078-0.000078322, Loss: 0.613570, Time/step: 10.060225
10/13/2023 05:29:57 - INFO -   Epoch: 1/5, Step: 57/143, Lr: 0.000000080-0.000079720, Loss: 0.636170, Time/step: 9.182258
10/13/2023 05:30:06 - INFO -   Epoch: 1/5, Step: 58/143, Lr: 0.000000081-0.000081119, Loss: 0.549454, Time/step: 9.712328
10/13/2023 05:30:16 - INFO -   Epoch: 1/5, Step: 59/143, Lr: 0.000000083-0.000082517, Loss: 0.536929, Time/step: 9.528231
10/13/2023 05:30:27 - INFO -   Epoch: 1/5, Step: 60/143, Lr: 0.000000084-0.000083916, Loss: 0.442688, Time/step: 10.533598
10/13/2023 05:30:36 - INFO -   Epoch: 1/5, Step: 61/143, Lr: 0.000000085-0.000085315, Loss: 0.427344, Time/step: 9.649796
10/13/2023 05:30:47 - INFO -   Epoch: 1/5, Step: 62/143, Lr: 0.000000087-0.000086713, Loss: 0.326247, Time/step: 10.698613
10/13/2023 05:30:57 - INFO -   Epoch: 1/5, Step: 63/143, Lr: 0.000000088-0.000088112, Loss: 0.432676, Time/step: 10.287930
10/13/2023 05:31:08 - INFO -   Epoch: 1/5, Step: 64/143, Lr: 0.000000090-0.000089510, Loss: 0.660657, Time/step: 11.134707
10/13/2023 06:57:18 - INFO -   Epoch: 1/5, Step: 65/143, Lr: 0.000000091-0.000090909, Loss: 0.613371, Time/step: 5169.671458
10/13/2023 06:57:27 - INFO -   Epoch: 1/5, Step: 66/143, Lr: 0.000000092-0.000092308, Loss: 0.341361, Time/step: 9.274822
10/13/2023 06:57:37 - INFO -   Epoch: 1/5, Step: 67/143, Lr: 0.000000094-0.000093706, Loss: 0.366777, Time/step: 10.123243
10/13/2023 06:57:47 - INFO -   Epoch: 1/5, Step: 68/143, Lr: 0.000000095-0.000095105, Loss: 0.678208, Time/step: 9.494089
10/13/2023 06:57:57 - INFO -   Epoch: 1/5, Step: 69/143, Lr: 0.000000097-0.000096503, Loss: 0.416725, Time/step: 10.271520
10/13/2023 06:58:07 - INFO -   Epoch: 1/5, Step: 70/143, Lr: 0.000000098-0.000097902, Loss: 0.413998, Time/step: 9.490628
10/13/2023 06:58:18 - INFO -   Epoch: 1/5, Step: 71/143, Lr: 0.000000099-0.000099301, Loss: 0.266290, Time/step: 10.867062
10/13/2023 06:58:28 - INFO -   Epoch: 1/5, Step: 72/143, Lr: 0.000000098-0.000097519, Loss: 0.614555, Time/step: 10.452538
10/13/2023 06:58:38 - INFO -   Epoch: 1/5, Step: 73/143, Lr: 0.000000097-0.000097450, Loss: 0.340144, Time/step: 10.203675
10/13/2023 06:58:49 - INFO -   Epoch: 1/5, Step: 74/143, Lr: 0.000000097-0.000097380, Loss: 0.513804, Time/step: 10.535766
10/13/2023 06:58:59 - INFO -   Epoch: 1/5, Step: 75/143, Lr: 0.000000097-0.000097310, Loss: 0.412257, Time/step: 10.414564
10/13/2023 06:59:10 - INFO -   Epoch: 1/5, Step: 76/143, Lr: 0.000000097-0.000097238, Loss: 0.518202, Time/step: 10.516442
10/13/2023 06:59:20 - INFO -   Epoch: 1/5, Step: 77/143, Lr: 0.000000097-0.000097166, Loss: 0.403292, Time/step: 10.524276
10/13/2023 06:59:31 - INFO -   Epoch: 1/5, Step: 78/143, Lr: 0.000000097-0.000097092, Loss: 0.596877, Time/step: 10.471193
10/13/2023 06:59:42 - INFO -   Epoch: 1/5, Step: 79/143, Lr: 0.000000097-0.000097018, Loss: 0.359616, Time/step: 11.041947
10/13/2023 06:59:53 - INFO -   Epoch: 1/5, Step: 80/143, Lr: 0.000000097-0.000096943, Loss: 0.513022, Time/step: 11.563748
10/13/2023 08:33:33 - INFO -   Epoch: 1/5, Step: 81/143, Lr: 0.000000097-0.000096867, Loss: 0.543617, Time/step: 5620.049212
10/13/2023 08:33:43 - INFO -   Epoch: 1/5, Step: 82/143, Lr: 0.000000097-0.000096790, Loss: 0.445418, Time/step: 9.723565
10/13/2023 08:33:54 - INFO -   Epoch: 1/5, Step: 83/143, Lr: 0.000000097-0.000096712, Loss: 0.341485, Time/step: 10.911496
10/13/2023 08:34:04 - INFO -   Epoch: 1/5, Step: 84/143, Lr: 0.000000097-0.000096633, Loss: 0.433841, Time/step: 9.843617
10/13/2023 08:34:14 - INFO -   Epoch: 1/5, Step: 85/143, Lr: 0.000000097-0.000096553, Loss: 0.385117, Time/step: 10.460186
10/13/2023 08:34:24 - INFO -   Epoch: 1/5, Step: 86/143, Lr: 0.000000096-0.000096473, Loss: 0.353172, Time/step: 9.853304
10/13/2023 08:34:36 - INFO -   Epoch: 1/5, Step: 87/143, Lr: 0.000000096-0.000096391, Loss: 0.400440, Time/step: 11.273324
10/13/2023 08:34:46 - INFO -   Epoch: 1/5, Step: 88/143, Lr: 0.000000096-0.000096309, Loss: 0.485399, Time/step: 10.504329
10/13/2023 08:34:56 - INFO -   Epoch: 1/5, Step: 89/143, Lr: 0.000000096-0.000096225, Loss: 0.385724, Time/step: 10.479692
10/13/2023 08:35:07 - INFO -   Epoch: 1/5, Step: 90/143, Lr: 0.000000096-0.000096141, Loss: 0.468223, Time/step: 10.712126
10/13/2023 08:35:18 - INFO -   Epoch: 1/5, Step: 91/143, Lr: 0.000000096-0.000096056, Loss: 0.485736, Time/step: 10.747027
10/13/2023 08:35:28 - INFO -   Epoch: 1/5, Step: 92/143, Lr: 0.000000096-0.000095970, Loss: 0.330209, Time/step: 10.299555
10/13/2023 08:35:39 - INFO -   Epoch: 1/5, Step: 93/143, Lr: 0.000000096-0.000095883, Loss: 0.447911, Time/step: 10.529580
10/13/2023 08:35:50 - INFO -   Epoch: 1/5, Step: 94/143, Lr: 0.000000096-0.000095796, Loss: 0.544940, Time/step: 10.831064
10/13/2023 08:36:00 - INFO -   Epoch: 1/5, Step: 95/143, Lr: 0.000000096-0.000095707, Loss: 0.377262, Time/step: 10.560252
10/13/2023 08:36:12 - INFO -   Epoch: 1/5, Step: 96/143, Lr: 0.000000096-0.000095618, Loss: 0.483795, Time/step: 11.341201
10/13/2023 09:41:22 - INFO -   Epoch: 1/5, Step: 97/143, Lr: 0.000000096-0.000095527, Loss: 0.501090, Time/step: 3910.210341
10/13/2023 09:41:32 - INFO -   Epoch: 1/5, Step: 98/143, Lr: 0.000000095-0.000095436, Loss: 0.431258, Time/step: 10.245887
10/13/2023 09:41:43 - INFO -   Epoch: 1/5, Step: 99/143, Lr: 0.000000095-0.000095344, Loss: 0.328772, Time/step: 10.990835
10/13/2023 09:41:54 - INFO -   Epoch: 1/5, Step: 100/143, Lr: 0.000000095-0.000095251, Loss: 0.290033, Time/step: 10.891808
10/13/2023 09:42:04 - INFO -   Epoch: 1/5, Step: 101/143, Lr: 0.000000095-0.000095157, Loss: 0.538135, Time/step: 10.486136
10/13/2023 09:52:51 - INFO -   Epoch: 1/5, Step: 102/143, Lr: 0.000000095-0.000095062, Loss: 0.456357, Time/step: 646.559621
10/13/2023 09:53:02 - INFO -   Epoch: 1/5, Step: 103/143, Lr: 0.000000095-0.000094966, Loss: 0.355358, Time/step: 10.690641
10/13/2023 09:53:12 - INFO -   Epoch: 1/5, Step: 104/143, Lr: 0.000000095-0.000094870, Loss: 0.410391, Time/step: 10.414361
10/13/2023 09:53:23 - INFO -   Epoch: 1/5, Step: 105/143, Lr: 0.000000095-0.000094773, Loss: 0.365738, Time/step: 10.858415
10/13/2023 09:54:38 - INFO -   Epoch: 1/5, Step: 106/143, Lr: 0.000000095-0.000094674, Loss: 0.576133, Time/step: 74.625279
10/13/2023 09:54:49 - INFO -   Epoch: 1/5, Step: 107/143, Lr: 0.000000095-0.000094575, Loss: 0.513359, Time/step: 10.922117
10/13/2023 10:19:10 - INFO -   Epoch: 1/5, Step: 108/143, Lr: 0.000000094-0.000094475, Loss: 0.762205, Time/step: 1461.512276
10/13/2023 10:19:21 - INFO -   Epoch: 1/5, Step: 109/143, Lr: 0.000000094-0.000094374, Loss: 0.462703, Time/step: 10.590574
10/13/2023 10:19:32 - INFO -   Epoch: 1/5, Step: 110/143, Lr: 0.000000094-0.000094273, Loss: 0.318568, Time/step: 10.634008
10/13/2023 10:19:43 - INFO -   Epoch: 1/5, Step: 111/143, Lr: 0.000000094-0.000094170, Loss: 0.366954, Time/step: 11.240910
10/13/2023 10:19:53 - INFO -   Epoch: 1/5, Step: 112/143, Lr: 0.000000094-0.000094067, Loss: 0.380946, Time/step: 10.336730
10/13/2023 10:47:53 - INFO -   Epoch: 1/5, Step: 113/143, Lr: 0.000000094-0.000093963, Loss: 0.425954, Time/step: 1679.551338
10/13/2023 11:04:40 - INFO -   Epoch: 1/5, Step: 114/143, Lr: 0.000000094-0.000093858, Loss: 0.459077, Time/step: 1006.849740
10/13/2023 11:04:50 - INFO -   Epoch: 1/5, Step: 115/143, Lr: 0.000000094-0.000093752, Loss: 0.664592, Time/step: 9.923905
10/13/2023 11:04:59 - INFO -   Epoch: 1/5, Step: 116/143, Lr: 0.000000094-0.000093645, Loss: 0.747970, Time/step: 9.704608
10/13/2023 11:09:07 - INFO -   Epoch: 1/5, Step: 117/143, Lr: 0.000000094-0.000093537, Loss: 0.497823, Time/step: 247.166930
10/13/2023 11:09:16 - INFO -   Epoch: 1/5, Step: 118/143, Lr: 0.000000093-0.000093429, Loss: 0.359805, Time/step: 9.584922
10/13/2023 11:09:27 - INFO -   Epoch: 1/5, Step: 119/143, Lr: 0.000000093-0.000093320, Loss: 0.408936, Time/step: 10.403299
10/13/2023 11:09:36 - INFO -   Epoch: 1/5, Step: 120/143, Lr: 0.000000093-0.000093209, Loss: 0.443676, Time/step: 9.575898
10/13/2023 11:09:46 - INFO -   Epoch: 1/5, Step: 121/143, Lr: 0.000000093-0.000093098, Loss: 0.413291, Time/step: 10.063264
10/13/2023 11:23:32 - INFO -   Epoch: 1/5, Step: 122/143, Lr: 0.000000093-0.000092987, Loss: 0.570086, Time/step: 825.447583
10/13/2023 11:23:42 - INFO -   Epoch: 1/5, Step: 123/143, Lr: 0.000000093-0.000092874, Loss: 0.446760, Time/step: 9.602214
10/13/2023 11:38:30 - INFO -   Epoch: 1/5, Step: 124/143, Lr: 0.000000093-0.000092761, Loss: 0.199146, Time/step: 887.983413
10/13/2023 11:38:37 - INFO -   Epoch: 1/5, Step: 125/143, Lr: 0.000000093-0.000092646, Loss: 0.319016, Time/step: 7.268523
10/13/2023 11:38:44 - INFO -   Epoch: 1/5, Step: 126/143, Lr: 0.000000093-0.000092531, Loss: 0.498406, Time/step: 7.393916
10/13/2023 11:38:52 - INFO -   Epoch: 1/5, Step: 127/143, Lr: 0.000000092-0.000092415, Loss: 0.368537, Time/step: 7.546540
10/13/2023 11:38:59 - INFO -   Epoch: 1/5, Step: 128/143, Lr: 0.000000092-0.000092299, Loss: 0.374330, Time/step: 7.243282
10/13/2023 11:54:55 - INFO -   Epoch: 1/5, Step: 129/143, Lr: 0.000000092-0.000092181, Loss: 0.358285, Time/step: 955.930291
10/13/2023 11:56:08 - INFO -   Epoch: 1/5, Step: 130/143, Lr: 0.000000092-0.000092063, Loss: 0.394810, Time/step: 72.844398
10/13/2023 11:56:10 - INFO -   Epoch: 1/5, Step: 131/143, Lr: 0.000000092-0.000091943, Loss: 0.191969, Time/step: 2.211808
10/13/2023 11:56:12 - INFO -   Epoch: 1/5, Step: 132/143, Lr: 0.000000092-0.000091824, Loss: 0.282952, Time/step: 2.299302
10/13/2023 11:58:46 - INFO -   Epoch: 1/5, Step: 133/143, Lr: 0.000000092-0.000091703, Loss: 0.578756, Time/step: 153.193346
10/13/2023 11:58:48 - INFO -   Epoch: 1/5, Step: 134/143, Lr: 0.000000092-0.000091581, Loss: 0.543280, Time/step: 1.909947
10/13/2023 11:58:50 - INFO -   Epoch: 1/5, Step: 135/143, Lr: 0.000000091-0.000091459, Loss: 0.474438, Time/step: 2.074804
10/13/2023 11:58:52 - INFO -   Epoch: 1/5, Step: 136/143, Lr: 0.000000091-0.000091335, Loss: 0.425277, Time/step: 2.031021
10/13/2023 11:58:54 - INFO -   Epoch: 1/5, Step: 137/143, Lr: 0.000000091-0.000091211, Loss: 0.674543, Time/step: 1.942468
10/13/2023 11:59:48 - INFO -   Epoch: 1/5, Step: 138/143, Lr: 0.000000091-0.000091087, Loss: 0.186286, Time/step: 54.530356
10/13/2023 11:59:49 - INFO -   Epoch: 1/5, Step: 139/143, Lr: 0.000000091-0.000090961, Loss: 0.437688, Time/step: 0.959423
10/13/2023 11:59:50 - INFO -   Epoch: 1/5, Step: 140/143, Lr: 0.000000091-0.000090835, Loss: 0.448408, Time/step: 0.966076
10/13/2023 11:59:51 - INFO -   Epoch: 1/5, Step: 141/143, Lr: 0.000000091-0.000090708, Loss: 0.544157, Time/step: 0.960165
10/13/2023 11:59:52 - INFO -   Epoch: 1/5, Step: 142/143, Lr: 0.000000091-0.000090580, Loss: 0.301129, Time/step: 0.950622
10/13/2023 11:59:53 - INFO -   Epoch: 1/5, Step: 143/143, Lr: 0.000000090-0.000090451, Loss: 0.154564, Time/step: 0.938884
10/13/2023 11:59:54 - INFO -   Epoch 1/5 Finished, Train Loss: 0.443713
10/13/2023 12:00:15 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_model.bin.0
10/13/2023 12:00:15 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_opt.bin.0
10/13/2023 12:00:15 - INFO -   Eval on val dataset
10/13/2023 13:40:49 - INFO -   sim matrix size: 184, 184
10/13/2023 13:40:49 - INFO -   	 Length-T: 184, Length-V:184
10/13/2023 13:40:49 - INFO -   Text-to-Video:
10/13/2023 13:40:49 - INFO -   	>>>  R@1: 53.3 - R@5: 78.8 - R@10: 88.6 - Median R: 1.0 - Mean R: 4.3
10/13/2023 13:40:49 - INFO -   Video-to-Text:
10/13/2023 13:40:49 - INFO -   	>>>  V2T$R@1: 54.9 - V2T$R@5: 83.2 - V2T$R@10: 91.8 - V2T$Median R: 1.0 - V2T$Mean R: 4.7
10/13/2023 13:40:49 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_model.bin.0, the R1 is: 53.2609
10/13/2023 14:25:06 - INFO -   Epoch: 2/5, Step: 1/143, Lr: 0.000000090-0.000090321, Loss: 0.208722, Time/step: 2656.788875
10/13/2023 14:33:08 - INFO -   Epoch: 2/5, Step: 2/143, Lr: 0.000000090-0.000090191, Loss: 0.252033, Time/step: 481.423867
10/13/2023 14:33:14 - INFO -   Epoch: 2/5, Step: 3/143, Lr: 0.000000090-0.000090060, Loss: 0.330010, Time/step: 6.457166
10/13/2023 14:35:20 - INFO -   Epoch: 2/5, Step: 4/143, Lr: 0.000000090-0.000089928, Loss: 0.243908, Time/step: 125.877768
10/13/2023 14:35:27 - INFO -   Epoch: 2/5, Step: 5/143, Lr: 0.000000090-0.000089795, Loss: 0.099494, Time/step: 7.217064
10/13/2023 14:35:35 - INFO -   Epoch: 2/5, Step: 6/143, Lr: 0.000000090-0.000089662, Loss: 0.348652, Time/step: 7.225480
10/13/2023 14:35:42 - INFO -   Epoch: 2/5, Step: 7/143, Lr: 0.000000090-0.000089528, Loss: 0.173829, Time/step: 7.564294
10/13/2023 14:35:50 - INFO -   Epoch: 2/5, Step: 8/143, Lr: 0.000000089-0.000089393, Loss: 0.419708, Time/step: 8.128940
10/13/2023 14:35:59 - INFO -   Epoch: 2/5, Step: 9/143, Lr: 0.000000089-0.000089257, Loss: 0.116935, Time/step: 8.458569
10/13/2023 14:36:07 - INFO -   Epoch: 2/5, Step: 10/143, Lr: 0.000000089-0.000089121, Loss: 0.148336, Time/step: 8.207572
10/13/2023 14:36:16 - INFO -   Epoch: 2/5, Step: 11/143, Lr: 0.000000089-0.000088984, Loss: 0.127438, Time/step: 8.888016
10/13/2023 14:36:26 - INFO -   Epoch: 2/5, Step: 12/143, Lr: 0.000000089-0.000088846, Loss: 0.433904, Time/step: 9.604979
10/13/2023 14:50:37 - INFO -   Epoch: 2/5, Step: 13/143, Lr: 0.000000089-0.000088707, Loss: 0.155542, Time/step: 851.802928
10/13/2023 14:50:48 - INFO -   Epoch: 2/5, Step: 14/143, Lr: 0.000000089-0.000088568, Loss: 0.115338, Time/step: 10.086602
10/13/2023 14:50:58 - INFO -   Epoch: 2/5, Step: 15/143, Lr: 0.000000088-0.000088427, Loss: 0.242701, Time/step: 10.307351
10/13/2023 14:51:08 - INFO -   Epoch: 2/5, Step: 16/143, Lr: 0.000000088-0.000088287, Loss: 0.244289, Time/step: 10.622081
10/13/2023 16:01:15 - INFO -   Epoch: 2/5, Step: 17/143, Lr: 0.000000088-0.000088145, Loss: 0.254775, Time/step: 4206.498468
10/13/2023 16:01:23 - INFO -   Epoch: 2/5, Step: 18/143, Lr: 0.000000088-0.000088002, Loss: 0.146097, Time/step: 8.091043
10/13/2023 16:01:32 - INFO -   Epoch: 2/5, Step: 19/143, Lr: 0.000000088-0.000087859, Loss: 0.218775, Time/step: 8.638328
10/13/2023 16:01:40 - INFO -   Epoch: 2/5, Step: 20/143, Lr: 0.000000088-0.000087715, Loss: 0.148781, Time/step: 8.403863
10/13/2023 16:01:49 - INFO -   Epoch: 2/5, Step: 21/143, Lr: 0.000000088-0.000087571, Loss: 0.219345, Time/step: 8.792884
10/13/2023 16:01:58 - INFO -   Epoch: 2/5, Step: 22/143, Lr: 0.000000087-0.000087426, Loss: 0.160731, Time/step: 8.790323
10/13/2023 16:02:07 - INFO -   Epoch: 2/5, Step: 23/143, Lr: 0.000000087-0.000087279, Loss: 0.213933, Time/step: 9.337628
10/13/2023 16:08:10 - INFO -   Epoch: 2/5, Step: 24/143, Lr: 0.000000087-0.000087133, Loss: 0.275364, Time/step: 363.164205
10/13/2023 16:08:20 - INFO -   Epoch: 2/5, Step: 25/143, Lr: 0.000000087-0.000086985, Loss: 0.369278, Time/step: 9.272341
10/13/2023 16:08:29 - INFO -   Epoch: 2/5, Step: 26/143, Lr: 0.000000087-0.000086837, Loss: 0.374781, Time/step: 9.354388
10/13/2023 16:08:39 - INFO -   Epoch: 2/5, Step: 27/143, Lr: 0.000000087-0.000086688, Loss: 0.335019, Time/step: 10.349283
10/13/2023 16:08:49 - INFO -   Epoch: 2/5, Step: 28/143, Lr: 0.000000087-0.000086539, Loss: 0.311111, Time/step: 10.103271
10/13/2023 16:09:00 - INFO -   Epoch: 2/5, Step: 29/143, Lr: 0.000000086-0.000086388, Loss: 0.267019, Time/step: 10.844354
10/13/2023 16:09:12 - INFO -   Epoch: 2/5, Step: 30/143, Lr: 0.000000086-0.000086237, Loss: 0.239192, Time/step: 11.511777
10/13/2023 16:09:22 - INFO -   Epoch: 2/5, Step: 31/143, Lr: 0.000000086-0.000086085, Loss: 0.206439, Time/step: 10.502791
10/13/2023 16:09:34 - INFO -   Epoch: 2/5, Step: 32/143, Lr: 0.000000086-0.000085933, Loss: 0.551642, Time/step: 11.561198
10/13/2023 17:25:57 - INFO -   Epoch: 2/5, Step: 33/143, Lr: 0.000000086-0.000085780, Loss: 0.279801, Time/step: 4582.661368
10/13/2023 17:26:07 - INFO -   Epoch: 2/5, Step: 34/143, Lr: 0.000000086-0.000085626, Loss: 0.199407, Time/step: 9.901011
10/13/2023 17:26:17 - INFO -   Epoch: 2/5, Step: 35/143, Lr: 0.000000085-0.000085472, Loss: 0.442980, Time/step: 10.635370
10/13/2023 17:30:38 - INFO -   Epoch: 2/5, Step: 36/143, Lr: 0.000000085-0.000085316, Loss: 0.272085, Time/step: 260.447717
10/13/2023 17:34:12 - INFO -   Epoch: 2/5, Step: 37/143, Lr: 0.000000085-0.000085161, Loss: 0.361748, Time/step: 214.816572
10/13/2023 17:34:22 - INFO -   Epoch: 2/5, Step: 38/143, Lr: 0.000000085-0.000085004, Loss: 0.304272, Time/step: 9.067520
10/13/2023 17:36:18 - INFO -   Epoch: 2/5, Step: 39/143, Lr: 0.000000085-0.000084847, Loss: 0.234074, Time/step: 116.147086
10/13/2023 18:01:39 - INFO -   Epoch: 2/5, Step: 40/143, Lr: 0.000000085-0.000084689, Loss: 0.183336, Time/step: 1521.043465
10/13/2023 18:01:48 - INFO -   Epoch: 2/5, Step: 41/143, Lr: 0.000000085-0.000084530, Loss: 0.177852, Time/step: 8.709077
10/13/2023 18:01:57 - INFO -   Epoch: 2/5, Step: 42/143, Lr: 0.000000084-0.000084371, Loss: 0.137022, Time/step: 8.808293
10/13/2023 18:02:06 - INFO -   Epoch: 2/5, Step: 43/143, Lr: 0.000000084-0.000084211, Loss: 0.345717, Time/step: 9.150673
10/13/2023 18:02:15 - INFO -   Epoch: 2/5, Step: 44/143, Lr: 0.000000084-0.000084051, Loss: 0.462113, Time/step: 9.000010
10/13/2023 18:02:24 - INFO -   Epoch: 2/5, Step: 45/143, Lr: 0.000000084-0.000083890, Loss: 0.171522, Time/step: 9.630532
10/13/2023 18:02:34 - INFO -   Epoch: 2/5, Step: 46/143, Lr: 0.000000084-0.000083728, Loss: 0.287102, Time/step: 9.616161
10/13/2023 18:02:45 - INFO -   Epoch: 2/5, Step: 47/143, Lr: 0.000000084-0.000083565, Loss: 0.192895, Time/step: 10.774415
10/13/2023 18:02:56 - INFO -   Epoch: 2/5, Step: 48/143, Lr: 0.000000083-0.000083402, Loss: 0.292132, Time/step: 11.008442
10/13/2023 18:43:00 - INFO -   Epoch: 2/5, Step: 49/143, Lr: 0.000000083-0.000083238, Loss: 0.339427, Time/step: 2404.124287
10/13/2023 18:43:31 - INFO -   Epoch: 2/5, Step: 50/143, Lr: 0.000000083-0.000083074, Loss: 0.180783, Time/step: 30.765082
10/13/2023 18:54:00 - INFO -   Epoch: 2/5, Step: 51/143, Lr: 0.000000083-0.000082909, Loss: 0.377372, Time/step: 628.786001
10/13/2023 18:54:10 - INFO -   Epoch: 2/5, Step: 52/143, Lr: 0.000000083-0.000082743, Loss: 0.163760, Time/step: 10.568364
10/13/2023 19:06:34 - INFO -   Epoch: 2/5, Step: 53/143, Lr: 0.000000083-0.000082577, Loss: 0.312535, Time/step: 744.079995
10/13/2023 19:06:46 - INFO -   Epoch: 2/5, Step: 54/143, Lr: 0.000000082-0.000082410, Loss: 0.184068, Time/step: 11.561670
10/13/2023 19:06:57 - INFO -   Epoch: 2/5, Step: 55/143, Lr: 0.000000082-0.000082242, Loss: 0.151456, Time/step: 10.787370
10/13/2023 19:42:46 - INFO -   Epoch: 2/5, Step: 56/143, Lr: 0.000000082-0.000082074, Loss: 0.297775, Time/step: 2149.645175
10/13/2023 19:42:55 - INFO -   Epoch: 2/5, Step: 57/143, Lr: 0.000000082-0.000081905, Loss: 0.184886, Time/step: 8.731612
10/13/2023 19:43:04 - INFO -   Epoch: 2/5, Step: 58/143, Lr: 0.000000082-0.000081736, Loss: 0.253869, Time/step: 9.197337
10/13/2023 19:43:14 - INFO -   Epoch: 2/5, Step: 59/143, Lr: 0.000000082-0.000081566, Loss: 0.127305, Time/step: 9.360300
10/13/2023 19:43:24 - INFO -   Epoch: 2/5, Step: 60/143, Lr: 0.000000081-0.000081395, Loss: 0.363314, Time/step: 10.170578
10/13/2023 19:43:34 - INFO -   Epoch: 2/5, Step: 61/143, Lr: 0.000000081-0.000081224, Loss: 0.144918, Time/step: 9.789112
10/13/2023 19:43:44 - INFO -   Epoch: 2/5, Step: 62/143, Lr: 0.000000081-0.000081052, Loss: 0.143212, Time/step: 9.688544
10/13/2023 19:43:54 - INFO -   Epoch: 2/5, Step: 63/143, Lr: 0.000000081-0.000080879, Loss: 0.282968, Time/step: 10.824721
10/13/2023 19:44:05 - INFO -   Epoch: 2/5, Step: 64/143, Lr: 0.000000081-0.000080706, Loss: 0.282269, Time/step: 10.236815
10/13/2023 20:00:54 - INFO -   Epoch: 2/5, Step: 65/143, Lr: 0.000000081-0.000080532, Loss: 0.309257, Time/step: 1008.910943
10/13/2023 20:05:13 - INFO -   Epoch: 2/5, Step: 66/143, Lr: 0.000000080-0.000080358, Loss: 0.352693, Time/step: 259.331460
10/13/2023 20:10:53 - INFO -   Epoch: 2/5, Step: 67/143, Lr: 0.000000080-0.000080183, Loss: 0.240557, Time/step: 339.963507
10/13/2023 20:11:04 - INFO -   Epoch: 2/5, Step: 68/143, Lr: 0.000000080-0.000080008, Loss: 0.252078, Time/step: 11.063315
10/13/2023 20:50:39 - INFO -   Epoch: 2/5, Step: 69/143, Lr: 0.000000080-0.000079832, Loss: 0.104343, Time/step: 2374.788464
10/13/2023 20:50:50 - INFO -   Epoch: 2/5, Step: 70/143, Lr: 0.000000080-0.000079655, Loss: 0.481852, Time/step: 11.133737
10/13/2023 20:51:01 - INFO -   Epoch: 2/5, Step: 71/143, Lr: 0.000000079-0.000079478, Loss: 0.143755, Time/step: 10.891053
10/13/2023 21:04:27 - INFO -   Epoch: 2/5, Step: 72/143, Lr: 0.000000079-0.000079300, Loss: 0.311519, Time/step: 806.016948
10/13/2023 21:04:37 - INFO -   Epoch: 2/5, Step: 73/143, Lr: 0.000000079-0.000079122, Loss: 0.338000, Time/step: 9.129012
10/13/2023 21:04:46 - INFO -   Epoch: 2/5, Step: 74/143, Lr: 0.000000079-0.000078943, Loss: 0.164432, Time/step: 9.572283
10/13/2023 21:04:57 - INFO -   Epoch: 2/5, Step: 75/143, Lr: 0.000000079-0.000078764, Loss: 0.093668, Time/step: 10.717796
10/13/2023 21:05:07 - INFO -   Epoch: 2/5, Step: 76/143, Lr: 0.000000079-0.000078584, Loss: 0.200512, Time/step: 9.870745
10/13/2023 21:05:17 - INFO -   Epoch: 2/5, Step: 77/143, Lr: 0.000000078-0.000078403, Loss: 0.289010, Time/step: 10.301729
10/13/2023 21:05:27 - INFO -   Epoch: 2/5, Step: 78/143, Lr: 0.000000078-0.000078222, Loss: 0.182572, Time/step: 10.361456
10/13/2023 21:05:37 - INFO -   Epoch: 2/5, Step: 79/143, Lr: 0.000000078-0.000078041, Loss: 0.214444, Time/step: 9.827445
10/13/2023 21:05:49 - INFO -   Epoch: 2/5, Step: 80/143, Lr: 0.000000078-0.000077858, Loss: 0.186431, Time/step: 11.468492
10/13/2023 21:44:44 - INFO -   Epoch: 2/5, Step: 81/143, Lr: 0.000000078-0.000077676, Loss: 0.155487, Time/step: 2335.023249
10/13/2023 21:53:25 - INFO -   Epoch: 2/5, Step: 82/143, Lr: 0.000000077-0.000077492, Loss: 0.387158, Time/step: 520.786365
10/13/2023 21:53:35 - INFO -   Epoch: 2/5, Step: 83/143, Lr: 0.000000077-0.000077309, Loss: 0.241693, Time/step: 10.260125
10/13/2023 21:53:47 - INFO -   Epoch: 2/5, Step: 84/143, Lr: 0.000000077-0.000077124, Loss: 0.273025, Time/step: 11.580369
10/13/2023 22:40:05 - INFO -   Epoch: 2/5, Step: 85/143, Lr: 0.000000077-0.000076940, Loss: 0.219073, Time/step: 2778.660307
10/13/2023 22:40:14 - INFO -   Epoch: 2/5, Step: 86/143, Lr: 0.000000077-0.000076754, Loss: 0.173212, Time/step: 8.343059
10/13/2023 22:40:22 - INFO -   Epoch: 2/5, Step: 87/143, Lr: 0.000000077-0.000076568, Loss: 0.312388, Time/step: 8.185417
10/13/2023 22:40:31 - INFO -   Epoch: 2/5, Step: 88/143, Lr: 0.000000076-0.000076382, Loss: 0.164973, Time/step: 9.051283
10/13/2023 22:40:40 - INFO -   Epoch: 2/5, Step: 89/143, Lr: 0.000000076-0.000076195, Loss: 0.230304, Time/step: 8.721090
10/13/2023 22:40:49 - INFO -   Epoch: 2/5, Step: 90/143, Lr: 0.000000076-0.000076008, Loss: 0.081866, Time/step: 9.454263
10/13/2023 22:40:59 - INFO -   Epoch: 2/5, Step: 91/143, Lr: 0.000000076-0.000075820, Loss: 0.254834, Time/step: 9.916123
10/13/2023 22:41:09 - INFO -   Epoch: 2/5, Step: 92/143, Lr: 0.000000076-0.000075631, Loss: 0.196600, Time/step: 10.268416
10/13/2023 22:41:20 - INFO -   Epoch: 2/5, Step: 93/143, Lr: 0.000000075-0.000075443, Loss: 0.160014, Time/step: 10.119829
10/13/2023 22:41:30 - INFO -   Epoch: 2/5, Step: 94/143, Lr: 0.000000075-0.000075253, Loss: 0.347399, Time/step: 10.611882
10/13/2023 22:41:40 - INFO -   Epoch: 2/5, Step: 95/143, Lr: 0.000000075-0.000075063, Loss: 0.199563, Time/step: 10.111062
10/13/2023 22:41:51 - INFO -   Epoch: 2/5, Step: 96/143, Lr: 0.000000075-0.000074873, Loss: 0.473588, Time/step: 10.611383
10/13/2023 22:52:51 - INFO -   Epoch: 2/5, Step: 97/143, Lr: 0.000000075-0.000074682, Loss: 0.196096, Time/step: 660.319460
10/13/2023 23:02:07 - INFO -   Epoch: 2/5, Step: 98/143, Lr: 0.000000074-0.000074491, Loss: 0.209860, Time/step: 555.425889
10/13/2023 23:02:17 - INFO -   Epoch: 2/5, Step: 99/143, Lr: 0.000000074-0.000074299, Loss: 0.292858, Time/step: 10.503741
10/13/2023 23:02:28 - INFO -   Epoch: 2/5, Step: 100/143, Lr: 0.000000074-0.000074107, Loss: 0.253351, Time/step: 10.742422
10/14/2023 00:01:42 - INFO -   Epoch: 2/5, Step: 101/143, Lr: 0.000000074-0.000073914, Loss: 0.216468, Time/step: 3553.717965
10/14/2023 00:01:52 - INFO -   Epoch: 2/5, Step: 102/143, Lr: 0.000000074-0.000073721, Loss: 0.327787, Time/step: 10.019572
10/14/2023 00:02:02 - INFO -   Epoch: 2/5, Step: 103/143, Lr: 0.000000074-0.000073527, Loss: 0.192357, Time/step: 10.351773
10/14/2023 00:22:07 - INFO -   Epoch: 2/5, Step: 104/143, Lr: 0.000000073-0.000073333, Loss: 0.300513, Time/step: 1205.099190
10/14/2023 00:22:15 - INFO -   Epoch: 2/5, Step: 105/143, Lr: 0.000000073-0.000073139, Loss: 0.217167, Time/step: 7.692153
10/14/2023 00:22:24 - INFO -   Epoch: 2/5, Step: 106/143, Lr: 0.000000073-0.000072944, Loss: 0.192169, Time/step: 8.758026
10/14/2023 00:22:32 - INFO -   Epoch: 2/5, Step: 107/143, Lr: 0.000000073-0.000072748, Loss: 0.246740, Time/step: 8.476982
10/14/2023 00:22:41 - INFO -   Epoch: 2/5, Step: 108/143, Lr: 0.000000073-0.000072553, Loss: 0.216943, Time/step: 8.955978
10/14/2023 00:22:51 - INFO -   Epoch: 2/5, Step: 109/143, Lr: 0.000000072-0.000072356, Loss: 0.379490, Time/step: 9.804131
10/14/2023 00:23:02 - INFO -   Epoch: 2/5, Step: 110/143, Lr: 0.000000072-0.000072160, Loss: 0.240474, Time/step: 10.399398
10/14/2023 00:23:12 - INFO -   Epoch: 2/5, Step: 111/143, Lr: 0.000000072-0.000071962, Loss: 0.257919, Time/step: 10.088269
10/14/2023 00:23:22 - INFO -   Epoch: 2/5, Step: 112/143, Lr: 0.000000072-0.000071765, Loss: 0.261764, Time/step: 10.647353
10/14/2023 00:37:53 - INFO -   Epoch: 2/5, Step: 113/143, Lr: 0.000000072-0.000071567, Loss: 0.188312, Time/step: 870.475409
10/14/2023 00:38:03 - INFO -   Epoch: 2/5, Step: 114/143, Lr: 0.000000071-0.000071368, Loss: 0.243469, Time/step: 9.900803
10/14/2023 00:38:13 - INFO -   Epoch: 2/5, Step: 115/143, Lr: 0.000000071-0.000071170, Loss: 0.147910, Time/step: 9.951721
10/14/2023 00:38:23 - INFO -   Epoch: 2/5, Step: 116/143, Lr: 0.000000071-0.000070970, Loss: 0.127009, Time/step: 10.177939
10/14/2023 01:13:24 - INFO -   Epoch: 2/5, Step: 117/143, Lr: 0.000000071-0.000070771, Loss: 0.277875, Time/step: 2101.019977
10/14/2023 01:13:32 - INFO -   Epoch: 2/5, Step: 118/143, Lr: 0.000000071-0.000070571, Loss: 0.199137, Time/step: 7.875789
10/14/2023 01:13:39 - INFO -   Epoch: 2/5, Step: 119/143, Lr: 0.000000070-0.000070370, Loss: 0.383841, Time/step: 7.493100
10/14/2023 01:16:46 - INFO -   Epoch: 2/5, Step: 120/143, Lr: 0.000000070-0.000070169, Loss: 0.304236, Time/step: 186.772485
10/14/2023 01:16:54 - INFO -   Epoch: 2/5, Step: 121/143, Lr: 0.000000070-0.000069968, Loss: 0.113518, Time/step: 8.062154
10/14/2023 01:17:02 - INFO -   Epoch: 2/5, Step: 122/143, Lr: 0.000000070-0.000069767, Loss: 0.182656, Time/step: 7.414835
10/14/2023 01:17:09 - INFO -   Epoch: 2/5, Step: 123/143, Lr: 0.000000070-0.000069565, Loss: 0.420482, Time/step: 7.709826
10/14/2023 01:17:17 - INFO -   Epoch: 2/5, Step: 124/143, Lr: 0.000000069-0.000069362, Loss: 0.221437, Time/step: 7.982659
10/14/2023 01:17:25 - INFO -   Epoch: 2/5, Step: 125/143, Lr: 0.000000069-0.000069160, Loss: 0.173849, Time/step: 7.892697
10/14/2023 01:17:33 - INFO -   Epoch: 2/5, Step: 126/143, Lr: 0.000000069-0.000068956, Loss: 0.209624, Time/step: 7.818738
10/14/2023 01:17:41 - INFO -   Epoch: 2/5, Step: 127/143, Lr: 0.000000069-0.000068753, Loss: 0.219306, Time/step: 7.513572
10/14/2023 01:17:49 - INFO -   Epoch: 2/5, Step: 128/143, Lr: 0.000000069-0.000068549, Loss: 0.112621, Time/step: 7.877648
10/14/2023 01:25:40 - INFO -   Epoch: 2/5, Step: 129/143, Lr: 0.000000068-0.000068345, Loss: 0.178000, Time/step: 471.749393
10/14/2023 01:32:03 - INFO -   Epoch: 2/5, Step: 130/143, Lr: 0.000000068-0.000068140, Loss: 0.125039, Time/step: 382.878354
10/14/2023 01:36:57 - INFO -   Epoch: 2/5, Step: 131/143, Lr: 0.000000068-0.000067935, Loss: 0.357101, Time/step: 293.343299
10/14/2023 01:36:59 - INFO -   Epoch: 2/5, Step: 132/143, Lr: 0.000000068-0.000067730, Loss: 0.325666, Time/step: 2.804701
10/14/2023 01:43:09 - INFO -   Epoch: 2/5, Step: 133/143, Lr: 0.000000068-0.000067525, Loss: 0.100230, Time/step: 369.600867
10/14/2023 01:43:10 - INFO -   Epoch: 2/5, Step: 134/143, Lr: 0.000000067-0.000067319, Loss: 0.226321, Time/step: 1.264697
10/14/2023 01:43:12 - INFO -   Epoch: 2/5, Step: 135/143, Lr: 0.000000067-0.000067112, Loss: 0.268517, Time/step: 1.285123
10/14/2023 01:43:13 - INFO -   Epoch: 2/5, Step: 136/143, Lr: 0.000000067-0.000066906, Loss: 0.139064, Time/step: 1.345844
10/14/2023 01:43:14 - INFO -   Epoch: 2/5, Step: 137/143, Lr: 0.000000067-0.000066699, Loss: 0.181989, Time/step: 1.276192
10/14/2023 01:43:16 - INFO -   Epoch: 2/5, Step: 138/143, Lr: 0.000000066-0.000066492, Loss: 0.206706, Time/step: 1.326614
10/14/2023 01:43:17 - INFO -   Epoch: 2/5, Step: 139/143, Lr: 0.000000066-0.000066284, Loss: 0.284911, Time/step: 1.353045
10/14/2023 01:43:34 - INFO -   Epoch: 2/5, Step: 140/143, Lr: 0.000000066-0.000066076, Loss: 0.203609, Time/step: 16.823071
10/14/2023 01:43:35 - INFO -   Epoch: 2/5, Step: 141/143, Lr: 0.000000066-0.000065868, Loss: 0.336812, Time/step: 0.942996
10/14/2023 01:43:36 - INFO -   Epoch: 2/5, Step: 142/143, Lr: 0.000000066-0.000065660, Loss: 0.229119, Time/step: 0.972974
10/14/2023 01:43:37 - INFO -   Epoch: 2/5, Step: 143/143, Lr: 0.000000065-0.000065451, Loss: 0.273463, Time/step: 0.978612
10/14/2023 01:43:38 - INFO -   Epoch 2/5 Finished, Train Loss: 0.243267
10/14/2023 01:44:00 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_model.bin.1
10/14/2023 01:44:00 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_opt.bin.1
10/14/2023 01:44:00 - INFO -   Eval on val dataset
10/14/2023 03:24:30 - INFO -   sim matrix size: 184, 184
10/14/2023 03:24:30 - INFO -   	 Length-T: 184, Length-V:184
10/14/2023 03:24:30 - INFO -   Text-to-Video:
10/14/2023 03:24:30 - INFO -   	>>>  R@1: 54.9 - R@5: 79.9 - R@10: 86.4 - Median R: 1.0 - Mean R: 5.1
10/14/2023 03:24:30 - INFO -   Video-to-Text:
10/14/2023 03:24:30 - INFO -   	>>>  V2T$R@1: 55.4 - V2T$R@5: 82.6 - V2T$R@10: 88.0 - V2T$Median R: 1.0 - V2T$Mean R: 5.5
10/14/2023 03:24:30 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue/pytorch_model.bin.1, the R1 is: 54.8913
10/14/2023 04:15:59 - INFO -   Epoch: 3/5, Step: 1/143, Lr: 0.000000065-0.000065242, Loss: 0.072387, Time/step: 3088.956943
10/14/2023 04:16:06 - INFO -   Epoch: 3/5, Step: 2/143, Lr: 0.000000065-0.000065032, Loss: 0.119129, Time/step: 6.301548
10/14/2023 04:16:12 - INFO -   Epoch: 3/5, Step: 3/143, Lr: 0.000000065-0.000064823, Loss: 0.169559, Time/step: 6.230117
10/14/2023 04:18:36 - INFO -   Epoch: 3/5, Step: 4/143, Lr: 0.000000065-0.000064613, Loss: 0.052581, Time/step: 144.069336
10/14/2023 04:18:44 - INFO -   Epoch: 3/5, Step: 5/143, Lr: 0.000000064-0.000064403, Loss: 0.056365, Time/step: 7.433594
10/14/2023 04:18:51 - INFO -   Epoch: 3/5, Step: 6/143, Lr: 0.000000064-0.000064192, Loss: 0.122821, Time/step: 7.257850
10/14/2023 04:18:59 - INFO -   Epoch: 3/5, Step: 7/143, Lr: 0.000000064-0.000063981, Loss: 0.068616, Time/step: 8.110405
10/14/2023 04:34:29 - INFO -   Epoch: 3/5, Step: 8/143, Lr: 0.000000064-0.000063770, Loss: 0.095135, Time/step: 930.043211
10/14/2023 04:34:38 - INFO -   Epoch: 3/5, Step: 9/143, Lr: 0.000000064-0.000063559, Loss: 0.202949, Time/step: 8.366037
10/14/2023 04:34:47 - INFO -   Epoch: 3/5, Step: 10/143, Lr: 0.000000063-0.000063347, Loss: 0.148964, Time/step: 9.319873
10/14/2023 04:34:56 - INFO -   Epoch: 3/5, Step: 11/143, Lr: 0.000000063-0.000063135, Loss: 0.071835, Time/step: 9.360180
10/14/2023 04:35:06 - INFO -   Epoch: 3/5, Step: 12/143, Lr: 0.000000063-0.000062923, Loss: 0.089158, Time/step: 9.691565
10/14/2023 04:35:16 - INFO -   Epoch: 3/5, Step: 13/143, Lr: 0.000000063-0.000062711, Loss: 0.094485, Time/step: 9.827007
10/14/2023 04:35:26 - INFO -   Epoch: 3/5, Step: 14/143, Lr: 0.000000062-0.000062498, Loss: 0.150904, Time/step: 10.296923
10/14/2023 04:35:37 - INFO -   Epoch: 3/5, Step: 15/143, Lr: 0.000000062-0.000062285, Loss: 0.116084, Time/step: 11.230334
10/14/2023 04:35:48 - INFO -   Epoch: 3/5, Step: 16/143, Lr: 0.000000062-0.000062072, Loss: 0.112986, Time/step: 10.438473
10/14/2023 05:37:20 - INFO -   Epoch: 3/5, Step: 17/143, Lr: 0.000000062-0.000061859, Loss: 0.102019, Time/step: 3692.644878
10/14/2023 05:37:31 - INFO -   Epoch: 3/5, Step: 18/143, Lr: 0.000000062-0.000061646, Loss: 0.065961, Time/step: 10.312222
10/14/2023 05:37:41 - INFO -   Epoch: 3/5, Step: 19/143, Lr: 0.000000061-0.000061432, Loss: 0.073763, Time/step: 10.396331
10/14/2023 05:58:16 - INFO -   Epoch: 3/5, Step: 20/143, Lr: 0.000000061-0.000061218, Loss: 0.111559, Time/step: 1234.689560
10/14/2023 05:58:24 - INFO -   Epoch: 3/5, Step: 21/143, Lr: 0.000000061-0.000061004, Loss: 0.047706, Time/step: 8.549444
10/14/2023 05:58:35 - INFO -   Epoch: 3/5, Step: 22/143, Lr: 0.000000061-0.000060789, Loss: 0.097836, Time/step: 10.028663
10/14/2023 05:58:44 - INFO -   Epoch: 3/5, Step: 23/143, Lr: 0.000000061-0.000060575, Loss: 0.056092, Time/step: 9.259669
10/14/2023 06:10:12 - INFO -   Epoch: 3/5, Step: 24/143, Lr: 0.000000060-0.000060360, Loss: 0.054916, Time/step: 688.342493
10/14/2023 06:10:22 - INFO -   Epoch: 3/5, Step: 25/143, Lr: 0.000000060-0.000060145, Loss: 0.117649, Time/step: 9.338644
10/14/2023 06:10:30 - INFO -   Epoch: 3/5, Step: 26/143, Lr: 0.000000060-0.000059930, Loss: 0.144568, Time/step: 8.894095
10/14/2023 06:10:40 - INFO -   Epoch: 3/5, Step: 27/143, Lr: 0.000000060-0.000059714, Loss: 0.117646, Time/step: 9.435220
10/14/2023 06:10:50 - INFO -   Epoch: 3/5, Step: 28/143, Lr: 0.000000059-0.000059499, Loss: 0.196306, Time/step: 10.258044
10/14/2023 06:10:59 - INFO -   Epoch: 3/5, Step: 29/143, Lr: 0.000000059-0.000059283, Loss: 0.059698, Time/step: 9.227705
10/14/2023 06:11:10 - INFO -   Epoch: 3/5, Step: 30/143, Lr: 0.000000059-0.000059067, Loss: 0.123027, Time/step: 10.176382
10/14/2023 06:11:20 - INFO -   Epoch: 3/5, Step: 31/143, Lr: 0.000000059-0.000058851, Loss: 0.045588, Time/step: 10.350019
10/14/2023 06:11:31 - INFO -   Epoch: 3/5, Step: 32/143, Lr: 0.000000059-0.000058634, Loss: 0.086344, Time/step: 10.721933
10/14/2023 07:31:18 - INFO -   Epoch: 3/5, Step: 33/143, Lr: 0.000000058-0.000058418, Loss: 0.056841, Time/step: 4787.317816
10/14/2023 07:31:25 - INFO -   Epoch: 3/5, Step: 34/143, Lr: 0.000000058-0.000058201, Loss: 0.190344, Time/step: 7.346247
10/14/2023 07:31:33 - INFO -   Epoch: 3/5, Step: 35/143, Lr: 0.000000058-0.000057984, Loss: 0.071160, Time/step: 7.554060
10/14/2023 07:35:22 - INFO -   Epoch: 3/5, Step: 36/143, Lr: 0.000000058-0.000057767, Loss: 0.122372, Time/step: 229.001437
10/14/2023 07:35:30 - INFO -   Epoch: 3/5, Step: 37/143, Lr: 0.000000058-0.000057550, Loss: 0.125308, Time/step: 8.348929
10/14/2023 07:35:39 - INFO -   Epoch: 3/5, Step: 38/143, Lr: 0.000000057-0.000057333, Loss: 0.070249, Time/step: 8.496035
10/14/2023 07:35:47 - INFO -   Epoch: 3/5, Step: 39/143, Lr: 0.000000057-0.000057116, Loss: 0.036294, Time/step: 8.212553
10/14/2023 07:41:31 - INFO -   Epoch: 3/5, Step: 40/143, Lr: 0.000000057-0.000056898, Loss: 0.102810, Time/step: 344.000642
10/14/2023 07:41:40 - INFO -   Epoch: 3/5, Step: 41/143, Lr: 0.000000057-0.000056681, Loss: 0.190631, Time/step: 8.640544
10/14/2023 07:41:49 - INFO -   Epoch: 3/5, Step: 42/143, Lr: 0.000000056-0.000056463, Loss: 0.098508, Time/step: 8.959111
10/14/2023 07:41:58 - INFO -   Epoch: 3/5, Step: 43/143, Lr: 0.000000056-0.000056245, Loss: 0.079380, Time/step: 9.677886
10/14/2023 07:42:08 - INFO -   Epoch: 3/5, Step: 44/143, Lr: 0.000000056-0.000056027, Loss: 0.148276, Time/step: 9.689625
10/14/2023 07:42:18 - INFO -   Epoch: 3/5, Step: 45/143, Lr: 0.000000056-0.000055809, Loss: 0.056222, Time/step: 9.805866
10/14/2023 07:42:29 - INFO -   Epoch: 3/5, Step: 46/143, Lr: 0.000000056-0.000055590, Loss: 0.167398, Time/step: 11.042403
10/14/2023 07:42:40 - INFO -   Epoch: 3/5, Step: 47/143, Lr: 0.000000055-0.000055372, Loss: 0.147097, Time/step: 10.643398
10/14/2023 07:42:51 - INFO -   Epoch: 3/5, Step: 48/143, Lr: 0.000000055-0.000055154, Loss: 0.090101, Time/step: 11.095635
10/14/2023 09:18:22 - INFO -   Epoch: 3/5, Step: 49/143, Lr: 0.000000055-0.000054935, Loss: 0.153337, Time/step: 5731.005878
10/14/2023 09:18:28 - INFO -   Epoch: 3/5, Step: 50/143, Lr: 0.000000055-0.000054716, Loss: 0.078058, Time/step: 6.574940
10/14/2023 09:18:35 - INFO -   Epoch: 3/5, Step: 51/143, Lr: 0.000000054-0.000054498, Loss: 0.085990, Time/step: 6.872705
10/14/2023 09:18:43 - INFO -   Epoch: 3/5, Step: 52/143, Lr: 0.000000054-0.000054279, Loss: 0.090370, Time/step: 7.856236
10/14/2023 09:18:50 - INFO -   Epoch: 3/5, Step: 53/143, Lr: 0.000000054-0.000054060, Loss: 0.063926, Time/step: 7.454824
10/14/2023 09:18:59 - INFO -   Epoch: 3/5, Step: 54/143, Lr: 0.000000054-0.000053841, Loss: 0.112427, Time/step: 8.376831
10/14/2023 09:19:07 - INFO -   Epoch: 3/5, Step: 55/143, Lr: 0.000000054-0.000053622, Loss: 0.146903, Time/step: 8.238082
10/14/2023 09:19:16 - INFO -   Epoch: 3/5, Step: 56/143, Lr: 0.000000053-0.000053403, Loss: 0.051115, Time/step: 8.923655
10/14/2023 09:19:24 - INFO -   Epoch: 3/5, Step: 57/143, Lr: 0.000000053-0.000053183, Loss: 0.119355, Time/step: 8.357414
10/14/2023 09:19:34 - INFO -   Epoch: 3/5, Step: 58/143, Lr: 0.000000053-0.000052964, Loss: 0.051503, Time/step: 9.402496
10/14/2023 09:19:43 - INFO -   Epoch: 3/5, Step: 59/143, Lr: 0.000000053-0.000052745, Loss: 0.043987, Time/step: 8.814746
10/14/2023 09:19:52 - INFO -   Epoch: 3/5, Step: 60/143, Lr: 0.000000053-0.000052525, Loss: 0.180275, Time/step: 9.607669
10/14/2023 09:20:02 - INFO -   Epoch: 3/5, Step: 61/143, Lr: 0.000000052-0.000052306, Loss: 0.128295, Time/step: 10.005226
10/14/2023 09:20:12 - INFO -   Epoch: 3/5, Step: 62/143, Lr: 0.000000052-0.000052086, Loss: 0.105229, Time/step: 9.860376
10/14/2023 09:20:22 - INFO -   Epoch: 3/5, Step: 63/143, Lr: 0.000000052-0.000051867, Loss: 0.083691, Time/step: 10.096347
10/14/2023 09:20:33 - INFO -   Epoch: 3/5, Step: 64/143, Lr: 0.000000052-0.000051647, Loss: 0.038840, Time/step: 10.988179
10/14/2023 10:39:09 - INFO -   Epoch: 3/5, Step: 65/143, Lr: 0.000000051-0.000051428, Loss: 0.156725, Time/step: 4716.097001
10/14/2023 10:39:19 - INFO -   Epoch: 3/5, Step: 66/143, Lr: 0.000000051-0.000051208, Loss: 0.056501, Time/step: 9.774923
10/14/2023 10:39:29 - INFO -   Epoch: 3/5, Step: 67/143, Lr: 0.000000051-0.000050989, Loss: 0.111372, Time/step: 9.206094
10/14/2023 10:39:39 - INFO -   Epoch: 3/5, Step: 68/143, Lr: 0.000000051-0.000050769, Loss: 0.127697, Time/step: 10.027592
10/14/2023 10:39:48 - INFO -   Epoch: 3/5, Step: 69/143, Lr: 0.000000051-0.000050549, Loss: 0.078566, Time/step: 9.330070
10/14/2023 10:39:58 - INFO -   Epoch: 3/5, Step: 70/143, Lr: 0.000000050-0.000050330, Loss: 0.210831, Time/step: 10.271997
Traceback (most recent call last):
  File "main_xclip.py", line 555, in <module>
    ## ##############################################################
  File "main_xclip.py", line 529, in main
    logger.info("  Batch size = %d", args.batch_size_val)
  File "main_xclip.py", line 267, in train_epoch
    for step, batch in enumerate(train_dataloader):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1065, in _next_data
    return self._process_data(data)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 6.
Original Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 188, in __getitem__
    video, video_mask = self._get_rawvideo(choice_video_ids)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 179, in _get_rawvideo
    raise excep
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 149, in _get_rawvideo
    raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 85, in get_video_data
    image_input = self.video_to_tensor(video_path, self.transform, sample_fp=self.framerate, start_time=start_time, end_time=end_time)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 45, in video_to_tensor
    total_duration = (frameCount + fps - 1) // fps
ZeroDivisionError: integer division or modulo by zero

Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 255, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/home/wiss/zhang/anaconda3/envs/clip4clip/bin/python', '-u', 'main_xclip.py', '--local_rank=1', '--do_train', '--num_thread_reader=16', '--epochs=5', '--batch_size=64', '--n_display=1', '--data_path', '/home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/', '--features_path', '/home/wiss/zhang/nfs/Anet-compressed', '--output_dir', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2_continue', '--lr', '1e-4', '--max_words', '60', '--max_frames', '12', '--batch_size_val', '64', '--datatype', 'moviegraph', '--feature_framerate', '1', '--coef_lr', '1e-3', '--freeze_layer_num', '0', '--slice_framepos', '2', '--loose_type', '--linear_patch', '2d', '--sim_header', 'seqTransf', '--pretrained_clip_name', 'ViT-B/32', '--init_model', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train2_seed2/pytorch_model.bin.2', '--manipulation', 'anet_train2_seed2', '--scale', '0', '--dataset_ckpt', 'anet_train2_seed2', '--train_file', 'train_2.csv', '--val_file', 'temporal_contact_swap.csv', '--test_file', 'temporal_contact_swap.csv', '--seed', '2']' returned non-zero exit status 1.
