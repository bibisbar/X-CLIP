10/12/2023 22:40:01 - INFO -   Effective parameters:
10/12/2023 22:40:01 - INFO -     <<< batch_size: 64
10/12/2023 22:40:01 - INFO -     <<< batch_size_val: 64
10/12/2023 22:40:01 - INFO -     <<< cache_dir: 
10/12/2023 22:40:01 - INFO -     <<< coef_lr: 0.001
10/12/2023 22:40:01 - INFO -     <<< cross_model: cross-base
10/12/2023 22:40:01 - INFO -     <<< cross_num_hidden_layers: 4
10/12/2023 22:40:01 - INFO -     <<< data_path: /home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/
10/12/2023 22:40:01 - INFO -     <<< dataset_ckpt: anet_train3_seed3
10/12/2023 22:40:01 - INFO -     <<< datatype: moviegraph
10/12/2023 22:40:01 - INFO -     <<< do_eval: False
10/12/2023 22:40:01 - INFO -     <<< do_lower_case: False
10/12/2023 22:40:01 - INFO -     <<< do_pretrain: False
10/12/2023 22:40:01 - INFO -     <<< do_train: True
10/12/2023 22:40:01 - INFO -     <<< epochs: 5
10/12/2023 22:40:01 - INFO -     <<< eval_frame_order: 0
10/12/2023 22:40:01 - INFO -     <<< expand_msrvtt_sentences: False
10/12/2023 22:40:01 - INFO -     <<< feature_framerate: 1
10/12/2023 22:40:01 - INFO -     <<< features_path: /home/wiss/zhang/nfs/Anet-compressed
10/12/2023 22:40:01 - INFO -     <<< fp16: False
10/12/2023 22:40:01 - INFO -     <<< fp16_opt_level: O1
10/12/2023 22:40:01 - INFO -     <<< freeze_layer_num: 0
10/12/2023 22:40:01 - INFO -     <<< gradient_accumulation_steps: 1
10/12/2023 22:40:01 - INFO -     <<< hard_negative_rate: 0.5
10/12/2023 22:40:01 - INFO -     <<< init_model: /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3/pytorch_model.bin.2
10/12/2023 22:40:01 - INFO -     <<< linear_patch: 2d
10/12/2023 22:40:01 - INFO -     <<< local_rank: 0
10/12/2023 22:40:01 - INFO -     <<< loose_type: True
10/12/2023 22:40:01 - INFO -     <<< lr: 0.0001
10/12/2023 22:40:01 - INFO -     <<< lr_decay: 0.9
10/12/2023 22:40:01 - INFO -     <<< manipulation: anet_train3_seed3
10/12/2023 22:40:01 - INFO -     <<< margin: 0.1
10/12/2023 22:40:01 - INFO -     <<< max_frames: 12
10/12/2023 22:40:01 - INFO -     <<< max_words: 60
10/12/2023 22:40:01 - INFO -     <<< n_display: 1
10/12/2023 22:40:01 - INFO -     <<< n_gpu: 1
10/12/2023 22:40:01 - INFO -     <<< n_pair: 1
10/12/2023 22:40:01 - INFO -     <<< negative_weighting: 1
10/12/2023 22:40:01 - INFO -     <<< num_thread_reader: 16
10/12/2023 22:40:01 - INFO -     <<< output_dir: /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue
10/12/2023 22:40:01 - INFO -     <<< pretrained_clip_name: ViT-B/32
10/12/2023 22:40:01 - INFO -     <<< rank: 0
10/12/2023 22:40:01 - INFO -     <<< resume_model: None
10/12/2023 22:40:01 - INFO -     <<< sampled_use_mil: False
10/12/2023 22:40:01 - INFO -     <<< scale: 0
10/12/2023 22:40:01 - INFO -     <<< seed: 3
10/12/2023 22:40:01 - INFO -     <<< sim_header: seqTransf
10/12/2023 22:40:01 - INFO -     <<< slice_framepos: 2
10/12/2023 22:40:01 - INFO -     <<< task_type: retrieval
10/12/2023 22:40:01 - INFO -     <<< test_file: temporal_contact_swap.csv
10/12/2023 22:40:01 - INFO -     <<< text_num_hidden_layers: 12
10/12/2023 22:40:01 - INFO -     <<< train_csv: data/.train.csv
10/12/2023 22:40:01 - INFO -     <<< train_file: train_3.csv
10/12/2023 22:40:01 - INFO -     <<< train_frame_order: 0
10/12/2023 22:40:01 - INFO -     <<< use_mil: False
10/12/2023 22:40:01 - INFO -     <<< val_csv: data/.val.csv
10/12/2023 22:40:01 - INFO -     <<< val_file: temporal_contact_swap.csv
10/12/2023 22:40:01 - INFO -     <<< video_dim: 1024
10/12/2023 22:40:01 - INFO -     <<< visual_num_hidden_layers: 12
10/12/2023 22:40:01 - INFO -     <<< warmup_proportion: 0.1
10/12/2023 22:40:01 - INFO -     <<< world_size: 2
10/12/2023 22:40:01 - INFO -   device: cuda:0 n_gpu: 2
10/12/2023 22:40:01 - INFO -   device: cuda:1 n_gpu: 2
10/12/2023 22:40:13 - INFO -   loading archive file /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base
10/12/2023 22:40:13 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

10/12/2023 22:40:13 - INFO -   Weight doesn't exsits. /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base/cross_pytorch_model.bin
10/12/2023 22:40:13 - WARNING -   Stage-One:True, Stage-Two:False
10/12/2023 22:40:13 - WARNING -   Test retrieval by loose type.
10/12/2023 22:40:13 - WARNING -   	 embed_dim: 512
10/12/2023 22:40:13 - WARNING -   	 image_resolution: 224
10/12/2023 22:40:13 - WARNING -   	 vision_layers: 12
10/12/2023 22:40:13 - WARNING -   	 vision_width: 768
10/12/2023 22:40:13 - WARNING -   	 vision_patch_size: 32
10/12/2023 22:40:13 - WARNING -   	 context_length: 77
10/12/2023 22:40:13 - WARNING -   	 vocab_size: 49408
10/12/2023 22:40:13 - WARNING -   	 transformer_width: 512
10/12/2023 22:40:13 - WARNING -   	 transformer_heads: 8
10/12/2023 22:40:13 - WARNING -   	 transformer_layers: 12
10/12/2023 22:40:13 - WARNING -   		 linear_patch: 2d
10/12/2023 22:40:13 - WARNING -   	 cut_top_layer: 0
10/12/2023 22:40:16 - WARNING -   	 sim_header: seqTransf
10/12/2023 22:40:28 - INFO -   --------------------
10/12/2023 22:40:28 - INFO -   Weights from pretrained model not used in XCLIP: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
10/12/2023 22:40:44 - INFO -   ***** Running test *****
10/12/2023 22:40:44 - INFO -     Num examples = 184
10/12/2023 22:40:44 - INFO -     Batch size = 64
10/12/2023 22:40:44 - INFO -     Num steps = 3
10/12/2023 22:40:44 - INFO -   ***** Running val *****
10/12/2023 22:40:44 - INFO -     Num examples = 184
10/12/2023 22:40:48 - INFO -   ***** Running training *****
10/12/2023 22:40:48 - INFO -     Num examples = 9155
10/12/2023 22:40:48 - INFO -     Batch size = 64
10/12/2023 22:40:48 - INFO -     Num steps = 715
10/13/2023 00:04:58 - INFO -   Epoch: 1/5, Step: 1/143, Lr: 0.000000001-0.000001399, Loss: 0.378321, Time/step: 5049.532098
10/13/2023 00:12:46 - INFO -   Epoch: 1/5, Step: 2/143, Lr: 0.000000003-0.000002797, Loss: 0.213062, Time/step: 468.215110
10/13/2023 00:12:57 - INFO -   Epoch: 1/5, Step: 3/143, Lr: 0.000000004-0.000004196, Loss: 0.475543, Time/step: 10.295192
10/13/2023 00:13:08 - INFO -   Epoch: 1/5, Step: 4/143, Lr: 0.000000006-0.000005594, Loss: 0.434639, Time/step: 11.319000
10/13/2023 00:36:50 - INFO -   Epoch: 1/5, Step: 5/143, Lr: 0.000000007-0.000006993, Loss: 0.709798, Time/step: 1422.057169
10/13/2023 00:37:01 - INFO -   Epoch: 1/5, Step: 6/143, Lr: 0.000000008-0.000008392, Loss: 0.358218, Time/step: 10.732574
10/13/2023 00:37:11 - INFO -   Epoch: 1/5, Step: 7/143, Lr: 0.000000010-0.000009790, Loss: 0.464988, Time/step: 10.415156
10/13/2023 00:37:22 - INFO -   Epoch: 1/5, Step: 8/143, Lr: 0.000000011-0.000011189, Loss: 0.390765, Time/step: 10.680399
10/13/2023 00:37:33 - INFO -   Epoch: 1/5, Step: 9/143, Lr: 0.000000013-0.000012587, Loss: 0.535171, Time/step: 10.310384
10/13/2023 00:37:44 - INFO -   Epoch: 1/5, Step: 10/143, Lr: 0.000000014-0.000013986, Loss: 0.667390, Time/step: 11.457004
10/13/2023 00:37:55 - INFO -   Epoch: 1/5, Step: 11/143, Lr: 0.000000015-0.000015385, Loss: 0.584356, Time/step: 10.564189
10/13/2023 00:38:05 - INFO -   Epoch: 1/5, Step: 12/143, Lr: 0.000000017-0.000016783, Loss: 0.357741, Time/step: 10.332065
10/13/2023 00:38:15 - INFO -   Epoch: 1/5, Step: 13/143, Lr: 0.000000018-0.000018182, Loss: 0.402877, Time/step: 10.546219
10/13/2023 00:38:27 - INFO -   Epoch: 1/5, Step: 14/143, Lr: 0.000000020-0.000019580, Loss: 0.287954, Time/step: 11.206939
10/13/2023 00:38:37 - INFO -   Epoch: 1/5, Step: 15/143, Lr: 0.000000021-0.000020979, Loss: 0.458496, Time/step: 10.328844
10/13/2023 00:38:48 - INFO -   Epoch: 1/5, Step: 16/143, Lr: 0.000000022-0.000022378, Loss: 0.432437, Time/step: 10.799222
10/13/2023 01:55:28 - INFO -   Epoch: 1/5, Step: 17/143, Lr: 0.000000024-0.000023776, Loss: 0.596354, Time/step: 4600.706902
10/13/2023 01:57:00 - INFO -   Epoch: 1/5, Step: 18/143, Lr: 0.000000025-0.000025175, Loss: 0.365518, Time/step: 91.269686
10/13/2023 01:57:10 - INFO -   Epoch: 1/5, Step: 19/143, Lr: 0.000000027-0.000026573, Loss: 0.532531, Time/step: 10.610349
10/13/2023 01:57:21 - INFO -   Epoch: 1/5, Step: 20/143, Lr: 0.000000028-0.000027972, Loss: 0.407054, Time/step: 10.643239
10/13/2023 02:03:40 - INFO -   Epoch: 1/5, Step: 21/143, Lr: 0.000000029-0.000029371, Loss: 0.409515, Time/step: 378.805213
10/13/2023 02:03:51 - INFO -   Epoch: 1/5, Step: 22/143, Lr: 0.000000031-0.000030769, Loss: 0.424839, Time/step: 11.084513
10/13/2023 02:04:01 - INFO -   Epoch: 1/5, Step: 23/143, Lr: 0.000000032-0.000032168, Loss: 0.340954, Time/step: 10.057839
10/13/2023 02:04:11 - INFO -   Epoch: 1/5, Step: 24/143, Lr: 0.000000034-0.000033566, Loss: 0.375521, Time/step: 10.015190
10/13/2023 02:04:22 - INFO -   Epoch: 1/5, Step: 25/143, Lr: 0.000000035-0.000034965, Loss: 0.378245, Time/step: 11.113944
10/13/2023 02:04:33 - INFO -   Epoch: 1/5, Step: 26/143, Lr: 0.000000036-0.000036364, Loss: 0.603541, Time/step: 10.496597
10/13/2023 02:04:43 - INFO -   Epoch: 1/5, Step: 27/143, Lr: 0.000000038-0.000037762, Loss: 0.272844, Time/step: 10.258493
10/13/2023 02:08:39 - INFO -   Epoch: 1/5, Step: 28/143, Lr: 0.000000039-0.000039161, Loss: 0.455085, Time/step: 236.407535
10/13/2023 02:08:50 - INFO -   Epoch: 1/5, Step: 29/143, Lr: 0.000000041-0.000040559, Loss: 0.338112, Time/step: 10.127913
10/13/2023 02:09:01 - INFO -   Epoch: 1/5, Step: 30/143, Lr: 0.000000042-0.000041958, Loss: 0.570668, Time/step: 11.209581
10/13/2023 02:09:11 - INFO -   Epoch: 1/5, Step: 31/143, Lr: 0.000000043-0.000043357, Loss: 0.395242, Time/step: 10.480645
10/13/2023 02:09:22 - INFO -   Epoch: 1/5, Step: 32/143, Lr: 0.000000045-0.000044755, Loss: 0.447834, Time/step: 10.496110
10/13/2023 03:49:27 - INFO -   Epoch: 1/5, Step: 33/143, Lr: 0.000000046-0.000046154, Loss: 0.545718, Time/step: 6005.571330
10/13/2023 03:49:37 - INFO -   Epoch: 1/5, Step: 34/143, Lr: 0.000000048-0.000047552, Loss: 0.484929, Time/step: 9.908072
10/13/2023 03:49:47 - INFO -   Epoch: 1/5, Step: 35/143, Lr: 0.000000049-0.000048951, Loss: 0.230231, Time/step: 9.543289
10/13/2023 03:49:57 - INFO -   Epoch: 1/5, Step: 36/143, Lr: 0.000000050-0.000050350, Loss: 0.339710, Time/step: 9.856511
10/13/2023 03:50:06 - INFO -   Epoch: 1/5, Step: 37/143, Lr: 0.000000052-0.000051748, Loss: 0.377106, Time/step: 9.469161
10/13/2023 03:50:16 - INFO -   Epoch: 1/5, Step: 38/143, Lr: 0.000000053-0.000053147, Loss: 0.370992, Time/step: 9.803272
10/13/2023 03:50:26 - INFO -   Epoch: 1/5, Step: 39/143, Lr: 0.000000055-0.000054545, Loss: 0.354469, Time/step: 9.716965
10/13/2023 03:50:36 - INFO -   Epoch: 1/5, Step: 40/143, Lr: 0.000000056-0.000055944, Loss: 0.535457, Time/step: 10.551615
10/13/2023 03:50:46 - INFO -   Epoch: 1/5, Step: 41/143, Lr: 0.000000057-0.000057343, Loss: 0.232393, Time/step: 9.604299
10/13/2023 03:50:56 - INFO -   Epoch: 1/5, Step: 42/143, Lr: 0.000000059-0.000058741, Loss: 0.254751, Time/step: 9.958708
10/13/2023 03:51:06 - INFO -   Epoch: 1/5, Step: 43/143, Lr: 0.000000060-0.000060140, Loss: 0.448475, Time/step: 10.322973
10/13/2023 03:51:17 - INFO -   Epoch: 1/5, Step: 44/143, Lr: 0.000000062-0.000061538, Loss: 0.218723, Time/step: 10.131997
10/13/2023 03:51:27 - INFO -   Epoch: 1/5, Step: 45/143, Lr: 0.000000063-0.000062937, Loss: 0.402870, Time/step: 10.727847
10/13/2023 03:51:38 - INFO -   Epoch: 1/5, Step: 46/143, Lr: 0.000000064-0.000064336, Loss: 0.356227, Time/step: 10.874310
10/13/2023 03:51:49 - INFO -   Epoch: 1/5, Step: 47/143, Lr: 0.000000066-0.000065734, Loss: 0.324561, Time/step: 10.607708
10/13/2023 03:51:59 - INFO -   Epoch: 1/5, Step: 48/143, Lr: 0.000000067-0.000067133, Loss: 0.423706, Time/step: 10.459048
10/13/2023 05:28:37 - INFO -   Epoch: 1/5, Step: 49/143, Lr: 0.000000069-0.000068531, Loss: 0.402074, Time/step: 5797.519969
10/13/2023 05:28:46 - INFO -   Epoch: 1/5, Step: 50/143, Lr: 0.000000070-0.000069930, Loss: 0.554462, Time/step: 8.802176
10/13/2023 05:28:54 - INFO -   Epoch: 1/5, Step: 51/143, Lr: 0.000000071-0.000071329, Loss: 0.412098, Time/step: 8.198914
10/13/2023 05:29:03 - INFO -   Epoch: 1/5, Step: 52/143, Lr: 0.000000073-0.000072727, Loss: 0.344479, Time/step: 8.834281
10/13/2023 05:29:11 - INFO -   Epoch: 1/5, Step: 53/143, Lr: 0.000000074-0.000074126, Loss: 0.456127, Time/step: 8.543088
10/13/2023 05:29:20 - INFO -   Epoch: 1/5, Step: 54/143, Lr: 0.000000076-0.000075524, Loss: 0.579778, Time/step: 8.614789
10/13/2023 05:29:29 - INFO -   Epoch: 1/5, Step: 55/143, Lr: 0.000000077-0.000076923, Loss: 0.172512, Time/step: 8.842740
10/13/2023 05:29:39 - INFO -   Epoch: 1/5, Step: 56/143, Lr: 0.000000078-0.000078322, Loss: 0.405640, Time/step: 9.940525
10/13/2023 05:29:48 - INFO -   Epoch: 1/5, Step: 57/143, Lr: 0.000000080-0.000079720, Loss: 0.670946, Time/step: 9.569162
10/13/2023 05:29:58 - INFO -   Epoch: 1/5, Step: 58/143, Lr: 0.000000081-0.000081119, Loss: 0.461462, Time/step: 10.086212
10/13/2023 05:30:08 - INFO -   Epoch: 1/5, Step: 59/143, Lr: 0.000000083-0.000082517, Loss: 0.466817, Time/step: 9.624118
10/13/2023 05:30:18 - INFO -   Epoch: 1/5, Step: 60/143, Lr: 0.000000084-0.000083916, Loss: 0.290539, Time/step: 10.215793
10/13/2023 05:30:28 - INFO -   Epoch: 1/5, Step: 61/143, Lr: 0.000000085-0.000085315, Loss: 0.494833, Time/step: 10.117399
10/13/2023 05:30:38 - INFO -   Epoch: 1/5, Step: 62/143, Lr: 0.000000087-0.000086713, Loss: 0.315377, Time/step: 9.952977
10/13/2023 05:30:49 - INFO -   Epoch: 1/5, Step: 63/143, Lr: 0.000000088-0.000088112, Loss: 0.379423, Time/step: 10.647580
10/13/2023 05:30:59 - INFO -   Epoch: 1/5, Step: 64/143, Lr: 0.000000090-0.000089510, Loss: 0.588233, Time/step: 10.479849
10/13/2023 06:57:12 - INFO -   Epoch: 1/5, Step: 65/143, Lr: 0.000000091-0.000090909, Loss: 0.434906, Time/step: 5172.927771
10/13/2023 06:57:22 - INFO -   Epoch: 1/5, Step: 66/143, Lr: 0.000000092-0.000092308, Loss: 0.316644, Time/step: 9.250535
10/13/2023 06:57:31 - INFO -   Epoch: 1/5, Step: 67/143, Lr: 0.000000094-0.000093706, Loss: 0.368657, Time/step: 9.821193
10/13/2023 06:57:41 - INFO -   Epoch: 1/5, Step: 68/143, Lr: 0.000000095-0.000095105, Loss: 0.526924, Time/step: 9.648481
10/13/2023 06:57:52 - INFO -   Epoch: 1/5, Step: 69/143, Lr: 0.000000097-0.000096503, Loss: 0.338623, Time/step: 10.486021
10/13/2023 06:58:01 - INFO -   Epoch: 1/5, Step: 70/143, Lr: 0.000000098-0.000097902, Loss: 0.482175, Time/step: 9.435938
10/13/2023 06:58:11 - INFO -   Epoch: 1/5, Step: 71/143, Lr: 0.000000099-0.000099301, Loss: 0.388711, Time/step: 9.954556
10/13/2023 06:58:21 - INFO -   Epoch: 1/5, Step: 72/143, Lr: 0.000000098-0.000097519, Loss: 0.433648, Time/step: 10.035219
10/13/2023 06:58:32 - INFO -   Epoch: 1/5, Step: 73/143, Lr: 0.000000097-0.000097450, Loss: 0.414623, Time/step: 10.404662
10/13/2023 06:58:41 - INFO -   Epoch: 1/5, Step: 74/143, Lr: 0.000000097-0.000097380, Loss: 0.520101, Time/step: 9.842174
10/13/2023 06:58:52 - INFO -   Epoch: 1/5, Step: 75/143, Lr: 0.000000097-0.000097310, Loss: 0.437043, Time/step: 10.744891
10/13/2023 06:59:03 - INFO -   Epoch: 1/5, Step: 76/143, Lr: 0.000000097-0.000097238, Loss: 0.382214, Time/step: 10.437389
10/13/2023 06:59:13 - INFO -   Epoch: 1/5, Step: 77/143, Lr: 0.000000097-0.000097166, Loss: 0.385458, Time/step: 10.306581
10/13/2023 06:59:24 - INFO -   Epoch: 1/5, Step: 78/143, Lr: 0.000000097-0.000097092, Loss: 0.793120, Time/step: 10.838996
10/13/2023 06:59:34 - INFO -   Epoch: 1/5, Step: 79/143, Lr: 0.000000097-0.000097018, Loss: 0.423674, Time/step: 10.678656
10/13/2023 06:59:45 - INFO -   Epoch: 1/5, Step: 80/143, Lr: 0.000000097-0.000096943, Loss: 0.490592, Time/step: 10.463426
10/13/2023 08:33:30 - INFO -   Epoch: 1/5, Step: 81/143, Lr: 0.000000097-0.000096867, Loss: 0.507124, Time/step: 5624.642066
10/13/2023 08:33:40 - INFO -   Epoch: 1/5, Step: 82/143, Lr: 0.000000097-0.000096790, Loss: 0.652562, Time/step: 10.084891
10/13/2023 08:33:49 - INFO -   Epoch: 1/5, Step: 83/143, Lr: 0.000000097-0.000096712, Loss: 0.605663, Time/step: 9.733267
10/13/2023 08:33:59 - INFO -   Epoch: 1/5, Step: 84/143, Lr: 0.000000097-0.000096633, Loss: 0.377814, Time/step: 9.714113
10/13/2023 08:34:09 - INFO -   Epoch: 1/5, Step: 85/143, Lr: 0.000000097-0.000096553, Loss: 0.601702, Time/step: 9.808723
10/13/2023 08:34:20 - INFO -   Epoch: 1/5, Step: 86/143, Lr: 0.000000096-0.000096473, Loss: 0.291558, Time/step: 10.796113
10/13/2023 08:34:30 - INFO -   Epoch: 1/5, Step: 87/143, Lr: 0.000000096-0.000096391, Loss: 0.378617, Time/step: 10.682970
10/13/2023 08:34:41 - INFO -   Epoch: 1/5, Step: 88/143, Lr: 0.000000096-0.000096309, Loss: 0.661758, Time/step: 10.707345
10/13/2023 08:34:52 - INFO -   Epoch: 1/5, Step: 89/143, Lr: 0.000000096-0.000096225, Loss: 0.510191, Time/step: 10.132545
10/13/2023 08:35:02 - INFO -   Epoch: 1/5, Step: 90/143, Lr: 0.000000096-0.000096141, Loss: 0.324628, Time/step: 10.296974
10/13/2023 08:35:12 - INFO -   Epoch: 1/5, Step: 91/143, Lr: 0.000000096-0.000096056, Loss: 0.627466, Time/step: 10.325508
10/13/2023 08:35:23 - INFO -   Epoch: 1/5, Step: 92/143, Lr: 0.000000096-0.000095970, Loss: 0.437029, Time/step: 11.184445
10/13/2023 08:35:34 - INFO -   Epoch: 1/5, Step: 93/143, Lr: 0.000000096-0.000095883, Loss: 0.734967, Time/step: 10.225479
10/13/2023 08:35:45 - INFO -   Epoch: 1/5, Step: 94/143, Lr: 0.000000096-0.000095796, Loss: 0.672098, Time/step: 11.085288
10/13/2023 08:35:55 - INFO -   Epoch: 1/5, Step: 95/143, Lr: 0.000000096-0.000095707, Loss: 0.439650, Time/step: 10.422336
10/13/2023 08:36:06 - INFO -   Epoch: 1/5, Step: 96/143, Lr: 0.000000096-0.000095618, Loss: 0.707419, Time/step: 10.671452
10/13/2023 09:41:22 - INFO -   Epoch: 1/5, Step: 97/143, Lr: 0.000000096-0.000095527, Loss: 0.420549, Time/step: 3916.091344
10/13/2023 09:41:33 - INFO -   Epoch: 1/5, Step: 98/143, Lr: 0.000000095-0.000095436, Loss: 0.387277, Time/step: 10.770499
10/13/2023 09:41:44 - INFO -   Epoch: 1/5, Step: 99/143, Lr: 0.000000095-0.000095344, Loss: 0.301342, Time/step: 11.197925
10/13/2023 09:41:55 - INFO -   Epoch: 1/5, Step: 100/143, Lr: 0.000000095-0.000095251, Loss: 0.436900, Time/step: 10.621440
10/13/2023 09:42:05 - INFO -   Epoch: 1/5, Step: 101/143, Lr: 0.000000095-0.000095157, Loss: 0.511302, Time/step: 10.121414
10/13/2023 09:50:57 - INFO -   Epoch: 1/5, Step: 102/143, Lr: 0.000000095-0.000095062, Loss: 0.631231, Time/step: 532.776871
10/13/2023 09:51:08 - INFO -   Epoch: 1/5, Step: 103/143, Lr: 0.000000095-0.000094966, Loss: 0.394853, Time/step: 10.733438
10/13/2023 09:51:18 - INFO -   Epoch: 1/5, Step: 104/143, Lr: 0.000000095-0.000094870, Loss: 0.487303, Time/step: 10.222956
10/13/2023 09:51:29 - INFO -   Epoch: 1/5, Step: 105/143, Lr: 0.000000095-0.000094773, Loss: 0.515584, Time/step: 10.377784
10/13/2023 09:52:44 - INFO -   Epoch: 1/5, Step: 106/143, Lr: 0.000000095-0.000094674, Loss: 0.763199, Time/step: 74.933008
10/13/2023 09:52:55 - INFO -   Epoch: 1/5, Step: 107/143, Lr: 0.000000095-0.000094575, Loss: 0.769906, Time/step: 10.754997
10/13/2023 10:16:47 - INFO -   Epoch: 1/5, Step: 108/143, Lr: 0.000000094-0.000094475, Loss: 0.592538, Time/step: 1432.448577
10/13/2023 10:16:58 - INFO -   Epoch: 1/5, Step: 109/143, Lr: 0.000000094-0.000094374, Loss: 0.460626, Time/step: 10.888256
10/13/2023 10:17:09 - INFO -   Epoch: 1/5, Step: 110/143, Lr: 0.000000094-0.000094273, Loss: 0.459646, Time/step: 10.681811
10/13/2023 10:17:19 - INFO -   Epoch: 1/5, Step: 111/143, Lr: 0.000000094-0.000094170, Loss: 0.405813, Time/step: 10.450238
10/13/2023 10:17:30 - INFO -   Epoch: 1/5, Step: 112/143, Lr: 0.000000094-0.000094067, Loss: 0.401602, Time/step: 10.738838
10/13/2023 10:47:54 - INFO -   Epoch: 1/5, Step: 113/143, Lr: 0.000000094-0.000093963, Loss: 0.446207, Time/step: 1824.190212
10/13/2023 11:03:10 - INFO -   Epoch: 1/5, Step: 114/143, Lr: 0.000000094-0.000093858, Loss: 0.669266, Time/step: 916.071744
10/13/2023 11:03:20 - INFO -   Epoch: 1/5, Step: 115/143, Lr: 0.000000094-0.000093752, Loss: 0.495139, Time/step: 9.519298
10/13/2023 11:03:30 - INFO -   Epoch: 1/5, Step: 116/143, Lr: 0.000000094-0.000093645, Loss: 0.566052, Time/step: 9.685069
10/13/2023 11:07:06 - INFO -   Epoch: 1/5, Step: 117/143, Lr: 0.000000094-0.000093537, Loss: 0.413734, Time/step: 216.473308
10/13/2023 11:07:16 - INFO -   Epoch: 1/5, Step: 118/143, Lr: 0.000000093-0.000093429, Loss: 0.389520, Time/step: 9.699467
10/13/2023 11:07:26 - INFO -   Epoch: 1/5, Step: 119/143, Lr: 0.000000093-0.000093320, Loss: 0.654501, Time/step: 9.917297
10/13/2023 11:07:35 - INFO -   Epoch: 1/5, Step: 120/143, Lr: 0.000000093-0.000093209, Loss: 0.753978, Time/step: 9.776507
10/13/2023 11:07:45 - INFO -   Epoch: 1/5, Step: 121/143, Lr: 0.000000093-0.000093098, Loss: 0.368697, Time/step: 9.533086
10/13/2023 11:21:43 - INFO -   Epoch: 1/5, Step: 122/143, Lr: 0.000000093-0.000092987, Loss: 0.428316, Time/step: 838.226716
10/13/2023 11:21:53 - INFO -   Epoch: 1/5, Step: 123/143, Lr: 0.000000093-0.000092874, Loss: 0.622813, Time/step: 9.387309
10/13/2023 11:36:18 - INFO -   Epoch: 1/5, Step: 124/143, Lr: 0.000000093-0.000092761, Loss: 0.252486, Time/step: 865.221420
10/13/2023 11:36:25 - INFO -   Epoch: 1/5, Step: 125/143, Lr: 0.000000093-0.000092646, Loss: 0.598272, Time/step: 7.227945
10/13/2023 11:36:33 - INFO -   Epoch: 1/5, Step: 126/143, Lr: 0.000000093-0.000092531, Loss: 0.450175, Time/step: 7.689676
10/13/2023 11:36:40 - INFO -   Epoch: 1/5, Step: 127/143, Lr: 0.000000092-0.000092415, Loss: 0.489283, Time/step: 7.234604
10/13/2023 11:36:48 - INFO -   Epoch: 1/5, Step: 128/143, Lr: 0.000000092-0.000092299, Loss: 0.485308, Time/step: 7.817120
10/13/2023 11:53:59 - INFO -   Epoch: 1/5, Step: 129/143, Lr: 0.000000092-0.000092181, Loss: 0.503084, Time/step: 1030.731784
10/13/2023 11:54:43 - INFO -   Epoch: 1/5, Step: 130/143, Lr: 0.000000092-0.000092063, Loss: 0.603323, Time/step: 44.053742
10/13/2023 11:54:45 - INFO -   Epoch: 1/5, Step: 131/143, Lr: 0.000000092-0.000091943, Loss: 0.256887, Time/step: 2.263421
10/13/2023 11:54:47 - INFO -   Epoch: 1/5, Step: 132/143, Lr: 0.000000092-0.000091824, Loss: 0.244648, Time/step: 2.326460
10/13/2023 11:57:19 - INFO -   Epoch: 1/5, Step: 133/143, Lr: 0.000000092-0.000091703, Loss: 0.469584, Time/step: 151.606095
10/13/2023 11:57:21 - INFO -   Epoch: 1/5, Step: 134/143, Lr: 0.000000092-0.000091581, Loss: 0.377776, Time/step: 1.905206
10/13/2023 11:57:23 - INFO -   Epoch: 1/5, Step: 135/143, Lr: 0.000000091-0.000091459, Loss: 0.383328, Time/step: 1.945664
10/13/2023 11:57:25 - INFO -   Epoch: 1/5, Step: 136/143, Lr: 0.000000091-0.000091335, Loss: 0.378271, Time/step: 1.954669
10/13/2023 11:57:27 - INFO -   Epoch: 1/5, Step: 137/143, Lr: 0.000000091-0.000091211, Loss: 0.533496, Time/step: 1.973889
10/13/2023 11:58:23 - INFO -   Epoch: 1/5, Step: 138/143, Lr: 0.000000091-0.000091087, Loss: 0.528206, Time/step: 56.042306
10/13/2023 11:58:24 - INFO -   Epoch: 1/5, Step: 139/143, Lr: 0.000000091-0.000090961, Loss: 0.341730, Time/step: 0.957860
10/13/2023 11:58:25 - INFO -   Epoch: 1/5, Step: 140/143, Lr: 0.000000091-0.000090835, Loss: 0.498740, Time/step: 0.969221
10/13/2023 11:58:26 - INFO -   Epoch: 1/5, Step: 141/143, Lr: 0.000000091-0.000090708, Loss: 0.647000, Time/step: 0.948063
10/13/2023 11:58:27 - INFO -   Epoch: 1/5, Step: 142/143, Lr: 0.000000091-0.000090580, Loss: 0.504276, Time/step: 0.947609
10/13/2023 11:58:28 - INFO -   Epoch: 1/5, Step: 143/143, Lr: 0.000000090-0.000090451, Loss: 0.409618, Time/step: 1.245294
10/13/2023 11:58:29 - INFO -   Epoch 1/5 Finished, Train Loss: 0.456863
10/13/2023 11:58:53 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_model.bin.0
10/13/2023 11:58:53 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_opt.bin.0
10/13/2023 11:58:53 - INFO -   Eval on val dataset
10/13/2023 13:39:22 - INFO -   sim matrix size: 184, 184
10/13/2023 13:39:22 - INFO -   	 Length-T: 184, Length-V:184
10/13/2023 13:39:22 - INFO -   Text-to-Video:
10/13/2023 13:39:22 - INFO -   	>>>  R@1: 53.3 - R@5: 78.8 - R@10: 87.5 - Median R: 1.0 - Mean R: 5.5
10/13/2023 13:39:22 - INFO -   Video-to-Text:
10/13/2023 13:39:22 - INFO -   	>>>  V2T$R@1: 54.9 - V2T$R@5: 82.6 - V2T$R@10: 87.5 - V2T$Median R: 1.0 - V2T$Mean R: 5.7
10/13/2023 13:39:22 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_model.bin.0, the R1 is: 53.2609
10/13/2023 14:23:38 - INFO -   Epoch: 2/5, Step: 1/143, Lr: 0.000000090-0.000090321, Loss: 0.257490, Time/step: 2655.031595
10/13/2023 14:31:39 - INFO -   Epoch: 2/5, Step: 2/143, Lr: 0.000000090-0.000090191, Loss: 0.240878, Time/step: 481.684481
10/13/2023 14:31:46 - INFO -   Epoch: 2/5, Step: 3/143, Lr: 0.000000090-0.000090060, Loss: 0.306281, Time/step: 6.180369
10/13/2023 14:33:39 - INFO -   Epoch: 2/5, Step: 4/143, Lr: 0.000000090-0.000089928, Loss: 0.281144, Time/step: 112.983819
10/13/2023 14:33:45 - INFO -   Epoch: 2/5, Step: 5/143, Lr: 0.000000090-0.000089795, Loss: 0.174868, Time/step: 6.716125
10/13/2023 14:33:53 - INFO -   Epoch: 2/5, Step: 6/143, Lr: 0.000000090-0.000089662, Loss: 0.411605, Time/step: 7.871257
10/13/2023 14:34:01 - INFO -   Epoch: 2/5, Step: 7/143, Lr: 0.000000090-0.000089528, Loss: 0.107134, Time/step: 7.389653
10/13/2023 14:34:09 - INFO -   Epoch: 2/5, Step: 8/143, Lr: 0.000000089-0.000089393, Loss: 0.260690, Time/step: 8.252012
10/13/2023 14:34:17 - INFO -   Epoch: 2/5, Step: 9/143, Lr: 0.000000089-0.000089257, Loss: 0.196546, Time/step: 8.177208
10/13/2023 14:34:25 - INFO -   Epoch: 2/5, Step: 10/143, Lr: 0.000000089-0.000089121, Loss: 0.261472, Time/step: 8.394008
10/13/2023 14:34:34 - INFO -   Epoch: 2/5, Step: 11/143, Lr: 0.000000089-0.000088984, Loss: 0.220241, Time/step: 8.812194
10/13/2023 14:34:44 - INFO -   Epoch: 2/5, Step: 12/143, Lr: 0.000000089-0.000088846, Loss: 0.293596, Time/step: 9.997166
10/13/2023 14:49:01 - INFO -   Epoch: 2/5, Step: 13/143, Lr: 0.000000089-0.000088707, Loss: 0.216210, Time/step: 856.533229
10/13/2023 14:49:11 - INFO -   Epoch: 2/5, Step: 14/143, Lr: 0.000000089-0.000088568, Loss: 0.207705, Time/step: 9.741199
10/13/2023 14:49:20 - INFO -   Epoch: 2/5, Step: 15/143, Lr: 0.000000088-0.000088427, Loss: 0.170245, Time/step: 9.924224
10/13/2023 14:49:32 - INFO -   Epoch: 2/5, Step: 16/143, Lr: 0.000000088-0.000088287, Loss: 0.426610, Time/step: 11.023391
10/13/2023 15:59:45 - INFO -   Epoch: 2/5, Step: 17/143, Lr: 0.000000088-0.000088145, Loss: 0.250852, Time/step: 4213.598509
10/13/2023 15:59:53 - INFO -   Epoch: 2/5, Step: 18/143, Lr: 0.000000088-0.000088002, Loss: 0.282296, Time/step: 8.191818
10/13/2023 16:00:02 - INFO -   Epoch: 2/5, Step: 19/143, Lr: 0.000000088-0.000087859, Loss: 0.226126, Time/step: 8.698137
10/13/2023 16:00:11 - INFO -   Epoch: 2/5, Step: 20/143, Lr: 0.000000088-0.000087715, Loss: 0.321720, Time/step: 8.394279
10/13/2023 16:00:19 - INFO -   Epoch: 2/5, Step: 21/143, Lr: 0.000000088-0.000087571, Loss: 0.276622, Time/step: 8.775769
10/13/2023 16:00:28 - INFO -   Epoch: 2/5, Step: 22/143, Lr: 0.000000087-0.000087426, Loss: 0.107377, Time/step: 9.078128
10/13/2023 16:00:38 - INFO -   Epoch: 2/5, Step: 23/143, Lr: 0.000000087-0.000087279, Loss: 0.389680, Time/step: 9.486075
10/13/2023 16:06:40 - INFO -   Epoch: 2/5, Step: 24/143, Lr: 0.000000087-0.000087133, Loss: 0.350595, Time/step: 362.292898
10/13/2023 16:06:49 - INFO -   Epoch: 2/5, Step: 25/143, Lr: 0.000000087-0.000086985, Loss: 0.218356, Time/step: 8.955579
10/13/2023 16:06:59 - INFO -   Epoch: 2/5, Step: 26/143, Lr: 0.000000087-0.000086837, Loss: 0.300365, Time/step: 9.865107
10/13/2023 16:07:09 - INFO -   Epoch: 2/5, Step: 27/143, Lr: 0.000000087-0.000086688, Loss: 0.185045, Time/step: 9.717386
10/13/2023 16:07:19 - INFO -   Epoch: 2/5, Step: 28/143, Lr: 0.000000087-0.000086539, Loss: 0.251420, Time/step: 10.140276
10/13/2023 16:07:29 - INFO -   Epoch: 2/5, Step: 29/143, Lr: 0.000000086-0.000086388, Loss: 0.164760, Time/step: 10.469922
10/13/2023 16:07:41 - INFO -   Epoch: 2/5, Step: 30/143, Lr: 0.000000086-0.000086237, Loss: 0.306018, Time/step: 11.334118
10/13/2023 16:07:51 - INFO -   Epoch: 2/5, Step: 31/143, Lr: 0.000000086-0.000086085, Loss: 0.208390, Time/step: 10.649095
10/13/2023 16:08:02 - INFO -   Epoch: 2/5, Step: 32/143, Lr: 0.000000086-0.000085933, Loss: 0.219624, Time/step: 10.815301
10/13/2023 17:24:19 - INFO -   Epoch: 2/5, Step: 33/143, Lr: 0.000000086-0.000085780, Loss: 0.301715, Time/step: 4576.192564
10/13/2023 17:24:28 - INFO -   Epoch: 2/5, Step: 34/143, Lr: 0.000000086-0.000085626, Loss: 0.324655, Time/step: 9.952470
10/13/2023 17:24:39 - INFO -   Epoch: 2/5, Step: 35/143, Lr: 0.000000085-0.000085472, Loss: 0.280082, Time/step: 10.494589
10/13/2023 17:28:37 - INFO -   Epoch: 2/5, Step: 36/143, Lr: 0.000000085-0.000085316, Loss: 0.205637, Time/step: 237.965406
10/13/2023 17:32:00 - INFO -   Epoch: 2/5, Step: 37/143, Lr: 0.000000085-0.000085161, Loss: 0.238972, Time/step: 203.314914
10/13/2023 17:32:10 - INFO -   Epoch: 2/5, Step: 38/143, Lr: 0.000000085-0.000085004, Loss: 0.344035, Time/step: 9.842551
10/13/2023 17:34:17 - INFO -   Epoch: 2/5, Step: 39/143, Lr: 0.000000085-0.000084847, Loss: 0.170339, Time/step: 127.221772
10/13/2023 17:59:56 - INFO -   Epoch: 2/5, Step: 40/143, Lr: 0.000000085-0.000084689, Loss: 0.404490, Time/step: 1538.447916
10/13/2023 18:00:05 - INFO -   Epoch: 2/5, Step: 41/143, Lr: 0.000000085-0.000084530, Loss: 0.329727, Time/step: 8.549811
10/13/2023 18:00:14 - INFO -   Epoch: 2/5, Step: 42/143, Lr: 0.000000084-0.000084371, Loss: 0.221086, Time/step: 8.813358
10/13/2023 18:00:23 - INFO -   Epoch: 2/5, Step: 43/143, Lr: 0.000000084-0.000084211, Loss: 0.229681, Time/step: 9.193145
10/13/2023 18:00:33 - INFO -   Epoch: 2/5, Step: 44/143, Lr: 0.000000084-0.000084051, Loss: 0.279645, Time/step: 9.841334
10/13/2023 18:00:42 - INFO -   Epoch: 2/5, Step: 45/143, Lr: 0.000000084-0.000083890, Loss: 0.117853, Time/step: 9.723623
10/13/2023 18:00:52 - INFO -   Epoch: 2/5, Step: 46/143, Lr: 0.000000084-0.000083728, Loss: 0.261094, Time/step: 9.931001
10/13/2023 18:01:03 - INFO -   Epoch: 2/5, Step: 47/143, Lr: 0.000000084-0.000083565, Loss: 0.089539, Time/step: 10.382994
10/13/2023 18:01:13 - INFO -   Epoch: 2/5, Step: 48/143, Lr: 0.000000083-0.000083402, Loss: 0.235171, Time/step: 10.383494
10/13/2023 18:41:12 - INFO -   Epoch: 2/5, Step: 49/143, Lr: 0.000000083-0.000083238, Loss: 0.302008, Time/step: 2399.462258
10/13/2023 18:41:23 - INFO -   Epoch: 2/5, Step: 50/143, Lr: 0.000000083-0.000083074, Loss: 0.149049, Time/step: 10.103433
10/13/2023 18:52:03 - INFO -   Epoch: 2/5, Step: 51/143, Lr: 0.000000083-0.000082909, Loss: 0.158656, Time/step: 640.074289
10/13/2023 18:52:13 - INFO -   Epoch: 2/5, Step: 52/143, Lr: 0.000000083-0.000082743, Loss: 0.233412, Time/step: 10.264963
10/13/2023 19:04:08 - INFO -   Epoch: 2/5, Step: 53/143, Lr: 0.000000083-0.000082577, Loss: 0.272933, Time/step: 715.023955
10/13/2023 19:04:19 - INFO -   Epoch: 2/5, Step: 54/143, Lr: 0.000000082-0.000082410, Loss: 0.150536, Time/step: 10.911555
10/13/2023 19:04:30 - INFO -   Epoch: 2/5, Step: 55/143, Lr: 0.000000082-0.000082242, Loss: 0.137588, Time/step: 11.102259
10/13/2023 19:40:50 - INFO -   Epoch: 2/5, Step: 56/143, Lr: 0.000000082-0.000082074, Loss: 0.341823, Time/step: 2179.749057
10/13/2023 19:40:58 - INFO -   Epoch: 2/5, Step: 57/143, Lr: 0.000000082-0.000081905, Loss: 0.218063, Time/step: 8.039697
10/13/2023 19:41:08 - INFO -   Epoch: 2/5, Step: 58/143, Lr: 0.000000082-0.000081736, Loss: 0.221335, Time/step: 9.526357
10/13/2023 19:41:17 - INFO -   Epoch: 2/5, Step: 59/143, Lr: 0.000000082-0.000081566, Loss: 0.158818, Time/step: 9.443014
10/13/2023 19:41:27 - INFO -   Epoch: 2/5, Step: 60/143, Lr: 0.000000081-0.000081395, Loss: 0.281490, Time/step: 10.287884
10/13/2023 19:41:36 - INFO -   Epoch: 2/5, Step: 61/143, Lr: 0.000000081-0.000081224, Loss: 0.143733, Time/step: 9.234132
10/13/2023 19:41:46 - INFO -   Epoch: 2/5, Step: 62/143, Lr: 0.000000081-0.000081052, Loss: 0.128943, Time/step: 9.909101
10/13/2023 19:41:57 - INFO -   Epoch: 2/5, Step: 63/143, Lr: 0.000000081-0.000080879, Loss: 0.238469, Time/step: 10.958104
10/13/2023 19:42:08 - INFO -   Epoch: 2/5, Step: 64/143, Lr: 0.000000081-0.000080706, Loss: 0.138660, Time/step: 10.220977
10/13/2023 19:59:00 - INFO -   Epoch: 2/5, Step: 65/143, Lr: 0.000000081-0.000080532, Loss: 0.330761, Time/step: 1012.269409
10/13/2023 20:02:50 - INFO -   Epoch: 2/5, Step: 66/143, Lr: 0.000000080-0.000080358, Loss: 0.631834, Time/step: 229.548067
10/13/2023 20:08:56 - INFO -   Epoch: 2/5, Step: 67/143, Lr: 0.000000080-0.000080183, Loss: 0.301871, Time/step: 365.932095
10/13/2023 20:09:07 - INFO -   Epoch: 2/5, Step: 68/143, Lr: 0.000000080-0.000080008, Loss: 0.222856, Time/step: 10.793084
10/13/2023 20:47:51 - INFO -   Epoch: 2/5, Step: 69/143, Lr: 0.000000080-0.000079832, Loss: 0.269967, Time/step: 2324.978326
10/13/2023 20:48:02 - INFO -   Epoch: 2/5, Step: 70/143, Lr: 0.000000080-0.000079655, Loss: 0.183552, Time/step: 10.159763
10/13/2023 20:48:12 - INFO -   Epoch: 2/5, Step: 71/143, Lr: 0.000000079-0.000079478, Loss: 0.174265, Time/step: 10.433904
10/13/2023 21:02:14 - INFO -   Epoch: 2/5, Step: 72/143, Lr: 0.000000079-0.000079300, Loss: 0.272921, Time/step: 841.369120
10/13/2023 21:02:23 - INFO -   Epoch: 2/5, Step: 73/143, Lr: 0.000000079-0.000079122, Loss: 0.452305, Time/step: 9.060882
10/13/2023 21:02:32 - INFO -   Epoch: 2/5, Step: 74/143, Lr: 0.000000079-0.000078943, Loss: 0.152576, Time/step: 9.324035
10/13/2023 21:02:42 - INFO -   Epoch: 2/5, Step: 75/143, Lr: 0.000000079-0.000078764, Loss: 0.143892, Time/step: 9.827360
10/13/2023 21:02:52 - INFO -   Epoch: 2/5, Step: 76/143, Lr: 0.000000079-0.000078584, Loss: 0.252153, Time/step: 9.767814
10/13/2023 21:03:02 - INFO -   Epoch: 2/5, Step: 77/143, Lr: 0.000000078-0.000078403, Loss: 0.284492, Time/step: 9.760016
10/13/2023 21:03:12 - INFO -   Epoch: 2/5, Step: 78/143, Lr: 0.000000078-0.000078222, Loss: 0.209422, Time/step: 10.168240
10/13/2023 21:03:22 - INFO -   Epoch: 2/5, Step: 79/143, Lr: 0.000000078-0.000078041, Loss: 0.383691, Time/step: 9.909531
10/13/2023 21:03:33 - INFO -   Epoch: 2/5, Step: 80/143, Lr: 0.000000078-0.000077858, Loss: 0.170854, Time/step: 11.006507
10/13/2023 21:42:37 - INFO -   Epoch: 2/5, Step: 81/143, Lr: 0.000000078-0.000077676, Loss: 0.205766, Time/step: 2344.659218
10/13/2023 21:50:42 - INFO -   Epoch: 2/5, Step: 82/143, Lr: 0.000000077-0.000077492, Loss: 0.453943, Time/step: 484.933738
10/13/2023 21:50:53 - INFO -   Epoch: 2/5, Step: 83/143, Lr: 0.000000077-0.000077309, Loss: 0.206553, Time/step: 11.095011
10/13/2023 21:51:04 - INFO -   Epoch: 2/5, Step: 84/143, Lr: 0.000000077-0.000077124, Loss: 0.181334, Time/step: 10.557334
10/13/2023 22:37:13 - INFO -   Epoch: 2/5, Step: 85/143, Lr: 0.000000077-0.000076940, Loss: 0.290543, Time/step: 2768.549251
10/13/2023 22:37:21 - INFO -   Epoch: 2/5, Step: 86/143, Lr: 0.000000077-0.000076754, Loss: 0.154602, Time/step: 8.638373
10/13/2023 22:37:29 - INFO -   Epoch: 2/5, Step: 87/143, Lr: 0.000000077-0.000076568, Loss: 0.354700, Time/step: 8.076263
10/13/2023 22:37:38 - INFO -   Epoch: 2/5, Step: 88/143, Lr: 0.000000076-0.000076382, Loss: 0.190088, Time/step: 8.952497
10/13/2023 22:37:47 - INFO -   Epoch: 2/5, Step: 89/143, Lr: 0.000000076-0.000076195, Loss: 0.216112, Time/step: 9.057256
10/13/2023 22:37:57 - INFO -   Epoch: 2/5, Step: 90/143, Lr: 0.000000076-0.000076008, Loss: 0.159552, Time/step: 10.004089
10/13/2023 22:38:07 - INFO -   Epoch: 2/5, Step: 91/143, Lr: 0.000000076-0.000075820, Loss: 0.444670, Time/step: 9.658453
10/13/2023 22:38:18 - INFO -   Epoch: 2/5, Step: 92/143, Lr: 0.000000076-0.000075631, Loss: 0.323698, Time/step: 10.545481
10/13/2023 22:38:28 - INFO -   Epoch: 2/5, Step: 93/143, Lr: 0.000000075-0.000075443, Loss: 0.138813, Time/step: 10.349222
10/13/2023 22:38:38 - INFO -   Epoch: 2/5, Step: 94/143, Lr: 0.000000075-0.000075253, Loss: 0.231093, Time/step: 10.113922
10/13/2023 22:38:48 - INFO -   Epoch: 2/5, Step: 95/143, Lr: 0.000000075-0.000075063, Loss: 0.246653, Time/step: 10.451715
10/13/2023 22:39:00 - INFO -   Epoch: 2/5, Step: 96/143, Lr: 0.000000075-0.000074873, Loss: 0.410534, Time/step: 11.441998
10/13/2023 22:50:44 - INFO -   Epoch: 2/5, Step: 97/143, Lr: 0.000000075-0.000074682, Loss: 0.279541, Time/step: 704.097990
10/13/2023 22:59:19 - INFO -   Epoch: 2/5, Step: 98/143, Lr: 0.000000074-0.000074491, Loss: 0.288148, Time/step: 514.827655
10/13/2023 22:59:30 - INFO -   Epoch: 2/5, Step: 99/143, Lr: 0.000000074-0.000074299, Loss: 0.150297, Time/step: 10.622053
10/13/2023 22:59:41 - INFO -   Epoch: 2/5, Step: 100/143, Lr: 0.000000074-0.000074107, Loss: 0.320041, Time/step: 11.532852
10/13/2023 23:58:42 - INFO -   Epoch: 2/5, Step: 101/143, Lr: 0.000000074-0.000073914, Loss: 0.213124, Time/step: 3541.251413
10/13/2023 23:58:53 - INFO -   Epoch: 2/5, Step: 102/143, Lr: 0.000000074-0.000073721, Loss: 0.374996, Time/step: 10.203147
10/13/2023 23:59:03 - INFO -   Epoch: 2/5, Step: 103/143, Lr: 0.000000074-0.000073527, Loss: 0.204834, Time/step: 10.158971
10/14/2023 00:19:36 - INFO -   Epoch: 2/5, Step: 104/143, Lr: 0.000000073-0.000073333, Loss: 0.377839, Time/step: 1233.502247
10/14/2023 00:19:44 - INFO -   Epoch: 2/5, Step: 105/143, Lr: 0.000000073-0.000073139, Loss: 0.233037, Time/step: 7.583330
10/14/2023 00:19:53 - INFO -   Epoch: 2/5, Step: 106/143, Lr: 0.000000073-0.000072944, Loss: 0.199646, Time/step: 9.233080
10/14/2023 00:20:02 - INFO -   Epoch: 2/5, Step: 107/143, Lr: 0.000000073-0.000072748, Loss: 0.290865, Time/step: 8.278245
10/14/2023 00:20:11 - INFO -   Epoch: 2/5, Step: 108/143, Lr: 0.000000073-0.000072553, Loss: 0.138177, Time/step: 8.913122
10/14/2023 00:20:21 - INFO -   Epoch: 2/5, Step: 109/143, Lr: 0.000000072-0.000072356, Loss: 0.389237, Time/step: 10.076783
10/14/2023 00:20:30 - INFO -   Epoch: 2/5, Step: 110/143, Lr: 0.000000072-0.000072160, Loss: 0.197785, Time/step: 9.893455
10/14/2023 00:20:41 - INFO -   Epoch: 2/5, Step: 111/143, Lr: 0.000000072-0.000071962, Loss: 0.221567, Time/step: 10.620966
10/14/2023 00:20:51 - INFO -   Epoch: 2/5, Step: 112/143, Lr: 0.000000072-0.000071765, Loss: 0.191951, Time/step: 10.240534
10/14/2023 00:35:18 - INFO -   Epoch: 2/5, Step: 113/143, Lr: 0.000000072-0.000071567, Loss: 0.190855, Time/step: 866.325938
10/14/2023 00:35:28 - INFO -   Epoch: 2/5, Step: 114/143, Lr: 0.000000071-0.000071368, Loss: 0.343176, Time/step: 9.776124
10/14/2023 00:35:38 - INFO -   Epoch: 2/5, Step: 115/143, Lr: 0.000000071-0.000071170, Loss: 0.158523, Time/step: 10.614472
10/14/2023 00:35:48 - INFO -   Epoch: 2/5, Step: 116/143, Lr: 0.000000071-0.000070970, Loss: 0.246517, Time/step: 9.873226
10/14/2023 01:09:57 - INFO -   Epoch: 2/5, Step: 117/143, Lr: 0.000000071-0.000070771, Loss: 0.157280, Time/step: 2049.006108
10/14/2023 01:10:05 - INFO -   Epoch: 2/5, Step: 118/143, Lr: 0.000000071-0.000070571, Loss: 0.292137, Time/step: 7.517207
10/14/2023 01:10:13 - INFO -   Epoch: 2/5, Step: 119/143, Lr: 0.000000070-0.000070370, Loss: 0.222368, Time/step: 8.183508
10/14/2023 01:13:52 - INFO -   Epoch: 2/5, Step: 120/143, Lr: 0.000000070-0.000070169, Loss: 0.222032, Time/step: 218.707183
10/14/2023 01:13:59 - INFO -   Epoch: 2/5, Step: 121/143, Lr: 0.000000070-0.000069968, Loss: 0.150555, Time/step: 7.510962
10/14/2023 01:14:07 - INFO -   Epoch: 2/5, Step: 122/143, Lr: 0.000000070-0.000069767, Loss: 0.302374, Time/step: 8.321956
10/14/2023 01:14:15 - INFO -   Epoch: 2/5, Step: 123/143, Lr: 0.000000070-0.000069565, Loss: 0.245238, Time/step: 7.650402
10/14/2023 01:14:23 - INFO -   Epoch: 2/5, Step: 124/143, Lr: 0.000000069-0.000069362, Loss: 0.224622, Time/step: 8.003485
10/14/2023 01:14:31 - INFO -   Epoch: 2/5, Step: 125/143, Lr: 0.000000069-0.000069160, Loss: 0.220510, Time/step: 7.593071
10/14/2023 01:14:39 - INFO -   Epoch: 2/5, Step: 126/143, Lr: 0.000000069-0.000068956, Loss: 0.251944, Time/step: 8.158210
10/14/2023 01:14:46 - INFO -   Epoch: 2/5, Step: 127/143, Lr: 0.000000069-0.000068753, Loss: 0.194388, Time/step: 7.585836
10/14/2023 01:14:55 - INFO -   Epoch: 2/5, Step: 128/143, Lr: 0.000000069-0.000068549, Loss: 0.218888, Time/step: 8.217299
10/14/2023 01:22:42 - INFO -   Epoch: 2/5, Step: 129/143, Lr: 0.000000068-0.000068345, Loss: 0.119007, Time/step: 467.858601
10/14/2023 01:28:45 - INFO -   Epoch: 2/5, Step: 130/143, Lr: 0.000000068-0.000068140, Loss: 0.117911, Time/step: 362.006411
10/14/2023 01:33:55 - INFO -   Epoch: 2/5, Step: 131/143, Lr: 0.000000068-0.000067935, Loss: 0.373140, Time/step: 310.198245
10/14/2023 01:33:58 - INFO -   Epoch: 2/5, Step: 132/143, Lr: 0.000000068-0.000067730, Loss: 0.228234, Time/step: 2.800820
10/14/2023 01:40:01 - INFO -   Epoch: 2/5, Step: 133/143, Lr: 0.000000068-0.000067525, Loss: 0.218462, Time/step: 363.142394
10/14/2023 01:40:02 - INFO -   Epoch: 2/5, Step: 134/143, Lr: 0.000000067-0.000067319, Loss: 0.330298, Time/step: 1.272202
10/14/2023 01:40:03 - INFO -   Epoch: 2/5, Step: 135/143, Lr: 0.000000067-0.000067112, Loss: 0.376141, Time/step: 1.325898
10/14/2023 01:40:05 - INFO -   Epoch: 2/5, Step: 136/143, Lr: 0.000000067-0.000066906, Loss: 0.136626, Time/step: 1.352117
10/14/2023 01:40:06 - INFO -   Epoch: 2/5, Step: 137/143, Lr: 0.000000067-0.000066699, Loss: 0.178919, Time/step: 1.298743
10/14/2023 01:40:07 - INFO -   Epoch: 2/5, Step: 138/143, Lr: 0.000000066-0.000066492, Loss: 0.243950, Time/step: 1.341306
10/14/2023 01:40:09 - INFO -   Epoch: 2/5, Step: 139/143, Lr: 0.000000066-0.000066284, Loss: 0.371069, Time/step: 1.277943
10/14/2023 01:40:26 - INFO -   Epoch: 2/5, Step: 140/143, Lr: 0.000000066-0.000066076, Loss: 0.239129, Time/step: 17.249347
10/14/2023 01:40:27 - INFO -   Epoch: 2/5, Step: 141/143, Lr: 0.000000066-0.000065868, Loss: 0.296200, Time/step: 0.962338
10/14/2023 01:40:28 - INFO -   Epoch: 2/5, Step: 142/143, Lr: 0.000000066-0.000065660, Loss: 0.189754, Time/step: 0.955850
10/14/2023 01:40:29 - INFO -   Epoch: 2/5, Step: 143/143, Lr: 0.000000065-0.000065451, Loss: 0.458635, Time/step: 0.966091
10/14/2023 01:40:30 - INFO -   Epoch 2/5 Finished, Train Loss: 0.249211
10/14/2023 01:40:51 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_model.bin.1
10/14/2023 01:40:51 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_opt.bin.1
10/14/2023 01:40:51 - INFO -   Eval on val dataset
10/14/2023 03:21:24 - INFO -   sim matrix size: 184, 184
10/14/2023 03:21:24 - INFO -   	 Length-T: 184, Length-V:184
10/14/2023 03:21:24 - INFO -   Text-to-Video:
10/14/2023 03:21:24 - INFO -   	>>>  R@1: 57.6 - R@5: 79.9 - R@10: 89.1 - Median R: 1.0 - Mean R: 4.9
10/14/2023 03:21:24 - INFO -   Video-to-Text:
10/14/2023 03:21:24 - INFO -   	>>>  V2T$R@1: 54.9 - V2T$R@5: 82.6 - V2T$R@10: 89.1 - V2T$Median R: 1.0 - V2T$Mean R: 5.2
10/14/2023 03:21:24 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue/pytorch_model.bin.1, the R1 is: 57.6087
10/14/2023 04:12:43 - INFO -   Epoch: 3/5, Step: 1/143, Lr: 0.000000065-0.000065242, Loss: 0.078173, Time/step: 3077.625302
10/14/2023 04:12:49 - INFO -   Epoch: 3/5, Step: 2/143, Lr: 0.000000065-0.000065032, Loss: 0.113378, Time/step: 5.835662
10/14/2023 04:12:55 - INFO -   Epoch: 3/5, Step: 3/143, Lr: 0.000000065-0.000064823, Loss: 0.076412, Time/step: 6.857892
10/14/2023 04:15:28 - INFO -   Epoch: 3/5, Step: 4/143, Lr: 0.000000065-0.000064613, Loss: 0.087151, Time/step: 152.293895
10/14/2023 04:15:35 - INFO -   Epoch: 3/5, Step: 5/143, Lr: 0.000000064-0.000064403, Loss: 0.089214, Time/step: 7.561683
10/14/2023 04:15:42 - INFO -   Epoch: 3/5, Step: 6/143, Lr: 0.000000064-0.000064192, Loss: 0.105970, Time/step: 7.146540
10/14/2023 04:15:51 - INFO -   Epoch: 3/5, Step: 7/143, Lr: 0.000000064-0.000063981, Loss: 0.094624, Time/step: 8.176056
10/14/2023 04:31:25 - INFO -   Epoch: 3/5, Step: 8/143, Lr: 0.000000064-0.000063770, Loss: 0.065358, Time/step: 933.970077
10/14/2023 04:31:33 - INFO -   Epoch: 3/5, Step: 9/143, Lr: 0.000000064-0.000063559, Loss: 0.146342, Time/step: 8.001641
10/14/2023 04:31:41 - INFO -   Epoch: 3/5, Step: 10/143, Lr: 0.000000063-0.000063347, Loss: 0.090910, Time/step: 8.486863
10/14/2023 04:31:50 - INFO -   Epoch: 3/5, Step: 11/143, Lr: 0.000000063-0.000063135, Loss: 0.115328, Time/step: 8.793478
10/14/2023 04:31:59 - INFO -   Epoch: 3/5, Step: 12/143, Lr: 0.000000063-0.000062923, Loss: 0.071561, Time/step: 9.105536
10/14/2023 04:32:09 - INFO -   Epoch: 3/5, Step: 13/143, Lr: 0.000000063-0.000062711, Loss: 0.127126, Time/step: 10.176417
10/14/2023 04:32:19 - INFO -   Epoch: 3/5, Step: 14/143, Lr: 0.000000062-0.000062498, Loss: 0.083510, Time/step: 9.904186
10/14/2023 04:32:30 - INFO -   Epoch: 3/5, Step: 15/143, Lr: 0.000000062-0.000062285, Loss: 0.121215, Time/step: 10.500480
10/14/2023 04:32:40 - INFO -   Epoch: 3/5, Step: 16/143, Lr: 0.000000062-0.000062072, Loss: 0.097218, Time/step: 10.319161
10/14/2023 05:33:54 - INFO -   Epoch: 3/5, Step: 17/143, Lr: 0.000000062-0.000061859, Loss: 0.125719, Time/step: 3674.200983
10/14/2023 05:34:05 - INFO -   Epoch: 3/5, Step: 18/143, Lr: 0.000000062-0.000061646, Loss: 0.125683, Time/step: 10.625011
10/14/2023 05:34:15 - INFO -   Epoch: 3/5, Step: 19/143, Lr: 0.000000061-0.000061432, Loss: 0.121617, Time/step: 10.179463
10/14/2023 05:55:08 - INFO -   Epoch: 3/5, Step: 20/143, Lr: 0.000000061-0.000061218, Loss: 0.111718, Time/step: 1253.027558
10/14/2023 05:55:17 - INFO -   Epoch: 3/5, Step: 21/143, Lr: 0.000000061-0.000061004, Loss: 0.057074, Time/step: 9.114678
10/14/2023 05:55:26 - INFO -   Epoch: 3/5, Step: 22/143, Lr: 0.000000061-0.000060789, Loss: 0.073988, Time/step: 9.113846
10/14/2023 05:55:36 - INFO -   Epoch: 3/5, Step: 23/143, Lr: 0.000000061-0.000060575, Loss: 0.059706, Time/step: 9.834129
10/14/2023 06:06:52 - INFO -   Epoch: 3/5, Step: 24/143, Lr: 0.000000060-0.000060360, Loss: 0.104846, Time/step: 675.575538
10/14/2023 06:07:00 - INFO -   Epoch: 3/5, Step: 25/143, Lr: 0.000000060-0.000060145, Loss: 0.110760, Time/step: 8.302146
10/14/2023 06:07:09 - INFO -   Epoch: 3/5, Step: 26/143, Lr: 0.000000060-0.000059930, Loss: 0.133382, Time/step: 9.049233
10/14/2023 06:07:19 - INFO -   Epoch: 3/5, Step: 27/143, Lr: 0.000000060-0.000059714, Loss: 0.083431, Time/step: 9.822487
10/14/2023 06:07:29 - INFO -   Epoch: 3/5, Step: 28/143, Lr: 0.000000059-0.000059499, Loss: 0.114106, Time/step: 9.489404
10/14/2023 06:07:38 - INFO -   Epoch: 3/5, Step: 29/143, Lr: 0.000000059-0.000059283, Loss: 0.040672, Time/step: 9.653027
10/14/2023 06:07:48 - INFO -   Epoch: 3/5, Step: 30/143, Lr: 0.000000059-0.000059067, Loss: 0.160658, Time/step: 9.819089
10/14/2023 06:07:58 - INFO -   Epoch: 3/5, Step: 31/143, Lr: 0.000000059-0.000058851, Loss: 0.145074, Time/step: 10.107111
10/14/2023 06:08:09 - INFO -   Epoch: 3/5, Step: 32/143, Lr: 0.000000059-0.000058634, Loss: 0.192416, Time/step: 10.961771
10/14/2023 07:27:32 - INFO -   Epoch: 3/5, Step: 33/143, Lr: 0.000000058-0.000058418, Loss: 0.044395, Time/step: 4762.884654
10/14/2023 07:27:40 - INFO -   Epoch: 3/5, Step: 34/143, Lr: 0.000000058-0.000058201, Loss: 0.159199, Time/step: 7.425187
10/14/2023 07:27:47 - INFO -   Epoch: 3/5, Step: 35/143, Lr: 0.000000058-0.000057984, Loss: 0.117688, Time/step: 7.623279
10/14/2023 07:31:54 - INFO -   Epoch: 3/5, Step: 36/143, Lr: 0.000000058-0.000057767, Loss: 0.133542, Time/step: 247.283740
10/14/2023 07:32:02 - INFO -   Epoch: 3/5, Step: 37/143, Lr: 0.000000058-0.000057550, Loss: 0.070380, Time/step: 7.818320
10/14/2023 07:32:11 - INFO -   Epoch: 3/5, Step: 38/143, Lr: 0.000000057-0.000057333, Loss: 0.066017, Time/step: 8.532748
10/14/2023 07:32:19 - INFO -   Epoch: 3/5, Step: 39/143, Lr: 0.000000057-0.000057116, Loss: 0.105468, Time/step: 8.498918
10/14/2023 07:37:57 - INFO -   Epoch: 3/5, Step: 40/143, Lr: 0.000000057-0.000056898, Loss: 0.133062, Time/step: 337.834297
10/14/2023 07:38:06 - INFO -   Epoch: 3/5, Step: 41/143, Lr: 0.000000057-0.000056681, Loss: 0.175679, Time/step: 8.339791
10/14/2023 07:38:14 - INFO -   Epoch: 3/5, Step: 42/143, Lr: 0.000000056-0.000056463, Loss: 0.090028, Time/step: 8.768912
10/14/2023 07:38:24 - INFO -   Epoch: 3/5, Step: 43/143, Lr: 0.000000056-0.000056245, Loss: 0.142292, Time/step: 9.631174
10/14/2023 07:38:33 - INFO -   Epoch: 3/5, Step: 44/143, Lr: 0.000000056-0.000056027, Loss: 0.186510, Time/step: 9.497974
10/14/2023 07:38:44 - INFO -   Epoch: 3/5, Step: 45/143, Lr: 0.000000056-0.000055809, Loss: 0.064411, Time/step: 10.108367
10/14/2023 07:38:54 - INFO -   Epoch: 3/5, Step: 46/143, Lr: 0.000000056-0.000055590, Loss: 0.054047, Time/step: 10.662243
10/14/2023 07:39:05 - INFO -   Epoch: 3/5, Step: 47/143, Lr: 0.000000055-0.000055372, Loss: 0.133455, Time/step: 10.596457
10/14/2023 07:39:16 - INFO -   Epoch: 3/5, Step: 48/143, Lr: 0.000000055-0.000055154, Loss: 0.093706, Time/step: 11.197024
10/14/2023 09:14:22 - INFO -   Epoch: 3/5, Step: 49/143, Lr: 0.000000055-0.000054935, Loss: 0.085671, Time/step: 5705.589061
10/14/2023 09:14:28 - INFO -   Epoch: 3/5, Step: 50/143, Lr: 0.000000055-0.000054716, Loss: 0.116641, Time/step: 6.631387
10/14/2023 09:14:35 - INFO -   Epoch: 3/5, Step: 51/143, Lr: 0.000000054-0.000054498, Loss: 0.066986, Time/step: 6.840288
10/14/2023 09:14:43 - INFO -   Epoch: 3/5, Step: 52/143, Lr: 0.000000054-0.000054279, Loss: 0.090870, Time/step: 7.423229
10/14/2023 09:14:50 - INFO -   Epoch: 3/5, Step: 53/143, Lr: 0.000000054-0.000054060, Loss: 0.150528, Time/step: 7.529409
10/14/2023 09:14:58 - INFO -   Epoch: 3/5, Step: 54/143, Lr: 0.000000054-0.000053841, Loss: 0.064224, Time/step: 8.068884
10/14/2023 09:15:06 - INFO -   Epoch: 3/5, Step: 55/143, Lr: 0.000000054-0.000053622, Loss: 0.097464, Time/step: 8.136068
10/14/2023 09:15:16 - INFO -   Epoch: 3/5, Step: 56/143, Lr: 0.000000053-0.000053403, Loss: 0.079187, Time/step: 9.069098
10/14/2023 09:15:25 - INFO -   Epoch: 3/5, Step: 57/143, Lr: 0.000000053-0.000053183, Loss: 0.097387, Time/step: 9.012019
10/14/2023 09:15:33 - INFO -   Epoch: 3/5, Step: 58/143, Lr: 0.000000053-0.000052964, Loss: 0.075924, Time/step: 8.541131
10/14/2023 09:15:42 - INFO -   Epoch: 3/5, Step: 59/143, Lr: 0.000000053-0.000052745, Loss: 0.045350, Time/step: 8.994239
10/14/2023 09:15:52 - INFO -   Epoch: 3/5, Step: 60/143, Lr: 0.000000053-0.000052525, Loss: 0.098448, Time/step: 9.498989
10/14/2023 09:16:01 - INFO -   Epoch: 3/5, Step: 61/143, Lr: 0.000000052-0.000052306, Loss: 0.053218, Time/step: 9.866766
10/14/2023 09:16:12 - INFO -   Epoch: 3/5, Step: 62/143, Lr: 0.000000052-0.000052086, Loss: 0.125168, Time/step: 10.151252
10/14/2023 09:16:22 - INFO -   Epoch: 3/5, Step: 63/143, Lr: 0.000000052-0.000051867, Loss: 0.080411, Time/step: 10.015041
10/14/2023 09:16:33 - INFO -   Epoch: 3/5, Step: 64/143, Lr: 0.000000052-0.000051647, Loss: 0.029228, Time/step: 11.634824
10/14/2023 10:30:40 - INFO -   Epoch: 3/5, Step: 65/143, Lr: 0.000000051-0.000051428, Loss: 0.150055, Time/step: 4447.112120
10/14/2023 10:30:49 - INFO -   Epoch: 3/5, Step: 66/143, Lr: 0.000000051-0.000051208, Loss: 0.070504, Time/step: 8.916671
10/14/2023 10:30:59 - INFO -   Epoch: 3/5, Step: 67/143, Lr: 0.000000051-0.000050989, Loss: 0.160132, Time/step: 9.500428
10/14/2023 10:31:09 - INFO -   Epoch: 3/5, Step: 68/143, Lr: 0.000000051-0.000050769, Loss: 0.128503, Time/step: 9.696982
10/14/2023 10:31:18 - INFO -   Epoch: 3/5, Step: 69/143, Lr: 0.000000051-0.000050549, Loss: 0.104536, Time/step: 8.956078
10/14/2023 10:31:27 - INFO -   Epoch: 3/5, Step: 70/143, Lr: 0.000000050-0.000050330, Loss: 0.112912, Time/step: 9.126334
10/14/2023 10:31:36 - INFO -   Epoch: 3/5, Step: 71/143, Lr: 0.000000050-0.000050110, Loss: 0.158735, Time/step: 9.317937
10/14/2023 10:31:46 - INFO -   Epoch: 3/5, Step: 72/143, Lr: 0.000000050-0.000049890, Loss: 0.182526, Time/step: 9.595429
10/14/2023 10:31:56 - INFO -   Epoch: 3/5, Step: 73/143, Lr: 0.000000050-0.000049670, Loss: 0.162769, Time/step: 10.348725
10/14/2023 10:32:06 - INFO -   Epoch: 3/5, Step: 74/143, Lr: 0.000000049-0.000049451, Loss: 0.093460, Time/step: 9.842601
Traceback (most recent call last):
  File "main_xclip.py", line 555, in <module>
    ## ##############################################################
  File "main_xclip.py", line 529, in main
    logger.info("  Batch size = %d", args.batch_size_val)
  File "main_xclip.py", line 267, in train_epoch
    for step, batch in enumerate(train_dataloader):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1065, in _next_data
    return self._process_data(data)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 10.
Original Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 188, in __getitem__
    video, video_mask = self._get_rawvideo(choice_video_ids)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 179, in _get_rawvideo
    raise excep
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 149, in _get_rawvideo
    raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 85, in get_video_data
    image_input = self.video_to_tensor(video_path, self.transform, sample_fp=self.framerate, start_time=start_time, end_time=end_time)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 45, in video_to_tensor
    total_duration = (frameCount + fps - 1) // fps
ZeroDivisionError: integer division or modulo by zero

Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 255, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/home/wiss/zhang/anaconda3/envs/clip4clip/bin/python', '-u', 'main_xclip.py', '--local_rank=1', '--do_train', '--num_thread_reader=16', '--epochs=5', '--batch_size=64', '--n_display=1', '--data_path', '/home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/', '--features_path', '/home/wiss/zhang/nfs/Anet-compressed', '--output_dir', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3_continue', '--lr', '1e-4', '--max_words', '60', '--max_frames', '12', '--batch_size_val', '64', '--datatype', 'moviegraph', '--feature_framerate', '1', '--coef_lr', '1e-3', '--freeze_layer_num', '0', '--slice_framepos', '2', '--loose_type', '--linear_patch', '2d', '--sim_header', 'seqTransf', '--pretrained_clip_name', 'ViT-B/32', '--init_model', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train3_seed3/pytorch_model.bin.2', '--manipulation', 'anet_train3_seed3', '--scale', '0', '--dataset_ckpt', 'anet_train3_seed3', '--train_file', 'train_3.csv', '--val_file', 'temporal_contact_swap.csv', '--test_file', 'temporal_contact_swap.csv', '--seed', '3']' returned non-zero exit status 1.
