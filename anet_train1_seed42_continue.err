10/12/2023 21:42:26 - INFO -   device: cuda:1 n_gpu: 2
10/12/2023 21:42:26 - INFO -   Effective parameters:
10/12/2023 21:42:26 - INFO -     <<< batch_size: 64
10/12/2023 21:42:26 - INFO -     <<< batch_size_val: 64
10/12/2023 21:42:26 - INFO -     <<< cache_dir: 
10/12/2023 21:42:26 - INFO -     <<< coef_lr: 0.001
10/12/2023 21:42:26 - INFO -     <<< cross_model: cross-base
10/12/2023 21:42:26 - INFO -     <<< cross_num_hidden_layers: 4
10/12/2023 21:42:26 - INFO -     <<< data_path: /home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/
10/12/2023 21:42:26 - INFO -     <<< dataset_ckpt: anet_train1_seed42
10/12/2023 21:42:26 - INFO -     <<< datatype: moviegraph
10/12/2023 21:42:26 - INFO -     <<< do_eval: False
10/12/2023 21:42:26 - INFO -     <<< do_lower_case: False
10/12/2023 21:42:26 - INFO -     <<< do_pretrain: False
10/12/2023 21:42:26 - INFO -     <<< do_train: True
10/12/2023 21:42:26 - INFO -     <<< epochs: 5
10/12/2023 21:42:26 - INFO -     <<< eval_frame_order: 0
10/12/2023 21:42:26 - INFO -     <<< expand_msrvtt_sentences: False
10/12/2023 21:42:26 - INFO -     <<< feature_framerate: 1
10/12/2023 21:42:26 - INFO -     <<< features_path: /home/wiss/zhang/nfs/Anet-compressed
10/12/2023 21:42:26 - INFO -     <<< fp16: False
10/12/2023 21:42:26 - INFO -     <<< fp16_opt_level: O1
10/12/2023 21:42:26 - INFO -     <<< freeze_layer_num: 0
10/12/2023 21:42:26 - INFO -     <<< gradient_accumulation_steps: 1
10/12/2023 21:42:26 - INFO -     <<< hard_negative_rate: 0.5
10/12/2023 21:42:26 - INFO -     <<< init_model: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.1
10/12/2023 21:42:26 - INFO -     <<< linear_patch: 2d
10/12/2023 21:42:26 - INFO -     <<< local_rank: 0
10/12/2023 21:42:26 - INFO -     <<< loose_type: True
10/12/2023 21:42:26 - INFO -     <<< lr: 0.0001
10/12/2023 21:42:26 - INFO -     <<< lr_decay: 0.9
10/12/2023 21:42:26 - INFO -     <<< manipulation: anet_train1_seed42
10/12/2023 21:42:26 - INFO -     <<< margin: 0.1
10/12/2023 21:42:26 - INFO -     <<< max_frames: 12
10/12/2023 21:42:26 - INFO -     <<< max_words: 60
10/12/2023 21:42:26 - INFO -     <<< n_display: 1
10/12/2023 21:42:26 - INFO -     <<< n_gpu: 1
10/12/2023 21:42:26 - INFO -     <<< n_pair: 1
10/12/2023 21:42:26 - INFO -     <<< negative_weighting: 1
10/12/2023 21:42:26 - INFO -     <<< num_thread_reader: 16
10/12/2023 21:42:26 - INFO -     <<< output_dir: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue
10/12/2023 21:42:26 - INFO -     <<< pretrained_clip_name: ViT-B/32
10/12/2023 21:42:26 - INFO -     <<< rank: 0
10/12/2023 21:42:26 - INFO -     <<< resume_model: None
10/12/2023 21:42:26 - INFO -     <<< sampled_use_mil: False
10/12/2023 21:42:26 - INFO -     <<< scale: 0
10/12/2023 21:42:26 - INFO -     <<< seed: 42
10/12/2023 21:42:26 - INFO -     <<< sim_header: seqTransf
10/12/2023 21:42:26 - INFO -     <<< slice_framepos: 2
10/12/2023 21:42:26 - INFO -     <<< task_type: retrieval
10/12/2023 21:42:26 - INFO -     <<< test_file: temporal_contact_swap.csv
10/12/2023 21:42:26 - INFO -     <<< text_num_hidden_layers: 12
10/12/2023 21:42:26 - INFO -     <<< train_csv: data/.train.csv
10/12/2023 21:42:26 - INFO -     <<< train_file: train_1.csv
10/12/2023 21:42:26 - INFO -     <<< train_frame_order: 0
10/12/2023 21:42:26 - INFO -     <<< use_mil: False
10/12/2023 21:42:26 - INFO -     <<< val_csv: data/.val.csv
10/12/2023 21:42:26 - INFO -     <<< val_file: temporal_contact_swap.csv
10/12/2023 21:42:26 - INFO -     <<< video_dim: 1024
10/12/2023 21:42:26 - INFO -     <<< visual_num_hidden_layers: 12
10/12/2023 21:42:26 - INFO -     <<< warmup_proportion: 0.1
10/12/2023 21:42:26 - INFO -     <<< world_size: 2
10/12/2023 21:42:26 - INFO -   device: cuda:0 n_gpu: 2
10/12/2023 21:42:31 - INFO -   loading archive file /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base
10/12/2023 21:42:31 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

10/12/2023 21:42:31 - INFO -   Weight doesn't exsits. /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base/cross_pytorch_model.bin
10/12/2023 21:42:31 - WARNING -   Stage-One:True, Stage-Two:False
10/12/2023 21:42:31 - WARNING -   Test retrieval by loose type.
10/12/2023 21:42:31 - WARNING -   	 embed_dim: 512
10/12/2023 21:42:31 - WARNING -   	 image_resolution: 224
10/12/2023 21:42:31 - WARNING -   	 vision_layers: 12
10/12/2023 21:42:31 - WARNING -   	 vision_width: 768
10/12/2023 21:42:31 - WARNING -   	 vision_patch_size: 32
10/12/2023 21:42:31 - WARNING -   	 context_length: 77
10/12/2023 21:42:31 - WARNING -   	 vocab_size: 49408
10/12/2023 21:42:31 - WARNING -   	 transformer_width: 512
10/12/2023 21:42:31 - WARNING -   	 transformer_heads: 8
10/12/2023 21:42:31 - WARNING -   	 transformer_layers: 12
10/12/2023 21:42:31 - WARNING -   		 linear_patch: 2d
10/12/2023 21:42:31 - WARNING -   	 cut_top_layer: 0
10/12/2023 21:42:34 - WARNING -   	 sim_header: seqTransf
10/12/2023 21:42:46 - INFO -   --------------------
10/12/2023 21:42:46 - INFO -   Weights from pretrained model not used in XCLIP: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
10/12/2023 21:42:47 - INFO -   ***** Running test *****
10/12/2023 21:42:47 - INFO -     Num examples = 184
10/12/2023 21:42:47 - INFO -     Batch size = 64
10/12/2023 21:42:47 - INFO -     Num steps = 3
10/12/2023 21:42:47 - INFO -   ***** Running val *****
10/12/2023 21:42:47 - INFO -     Num examples = 184
10/12/2023 21:42:51 - INFO -   ***** Running training *****
10/12/2023 21:42:51 - INFO -     Num examples = 9155
10/12/2023 21:42:51 - INFO -     Batch size = 64
10/12/2023 21:42:51 - INFO -     Num steps = 715
10/12/2023 23:07:53 - INFO -   Epoch: 1/5, Step: 1/143, Lr: 0.000000001-0.000001399, Loss: 1.027124, Time/step: 5101.514336
10/12/2023 23:16:20 - INFO -   Epoch: 1/5, Step: 2/143, Lr: 0.000000003-0.000002797, Loss: 0.991395, Time/step: 507.398914
10/12/2023 23:16:34 - INFO -   Epoch: 1/5, Step: 3/143, Lr: 0.000000004-0.000004196, Loss: 0.965223, Time/step: 13.573823
10/12/2023 23:16:48 - INFO -   Epoch: 1/5, Step: 4/143, Lr: 0.000000006-0.000005594, Loss: 0.856386, Time/step: 13.436501
10/12/2023 23:40:33 - INFO -   Epoch: 1/5, Step: 5/143, Lr: 0.000000007-0.000006993, Loss: 1.340914, Time/step: 1425.429157
10/12/2023 23:40:45 - INFO -   Epoch: 1/5, Step: 6/143, Lr: 0.000000008-0.000008392, Loss: 0.844247, Time/step: 12.253626
10/12/2023 23:40:57 - INFO -   Epoch: 1/5, Step: 7/143, Lr: 0.000000010-0.000009790, Loss: 0.913763, Time/step: 11.152662
10/12/2023 23:41:09 - INFO -   Epoch: 1/5, Step: 8/143, Lr: 0.000000011-0.000011189, Loss: 0.564620, Time/step: 11.923280
10/12/2023 23:41:20 - INFO -   Epoch: 1/5, Step: 9/143, Lr: 0.000000013-0.000012587, Loss: 1.136293, Time/step: 11.860529
10/12/2023 23:41:33 - INFO -   Epoch: 1/5, Step: 10/143, Lr: 0.000000014-0.000013986, Loss: 1.082011, Time/step: 12.334517
10/12/2023 23:41:45 - INFO -   Epoch: 1/5, Step: 11/143, Lr: 0.000000015-0.000015385, Loss: 1.375750, Time/step: 12.137078
10/12/2023 23:41:56 - INFO -   Epoch: 1/5, Step: 12/143, Lr: 0.000000017-0.000016783, Loss: 1.344737, Time/step: 11.118147
10/12/2023 23:42:09 - INFO -   Epoch: 1/5, Step: 13/143, Lr: 0.000000018-0.000018182, Loss: 1.089942, Time/step: 12.919197
10/12/2023 23:42:20 - INFO -   Epoch: 1/5, Step: 14/143, Lr: 0.000000020-0.000019580, Loss: 0.983605, Time/step: 11.612093
10/12/2023 23:42:32 - INFO -   Epoch: 1/5, Step: 15/143, Lr: 0.000000021-0.000020979, Loss: 0.852872, Time/step: 11.974897
10/12/2023 23:42:45 - INFO -   Epoch: 1/5, Step: 16/143, Lr: 0.000000022-0.000022378, Loss: 0.901804, Time/step: 12.176569
10/13/2023 00:58:51 - INFO -   Epoch: 1/5, Step: 17/143, Lr: 0.000000024-0.000023776, Loss: 0.860083, Time/step: 4566.212655
10/13/2023 01:00:17 - INFO -   Epoch: 1/5, Step: 18/143, Lr: 0.000000025-0.000025175, Loss: 1.032413, Time/step: 85.725962
10/13/2023 01:00:28 - INFO -   Epoch: 1/5, Step: 19/143, Lr: 0.000000027-0.000026573, Loss: 0.989359, Time/step: 11.441718
10/13/2023 01:00:41 - INFO -   Epoch: 1/5, Step: 20/143, Lr: 0.000000028-0.000027972, Loss: 1.110375, Time/step: 12.315869
10/13/2023 01:08:05 - INFO -   Epoch: 1/5, Step: 21/143, Lr: 0.000000029-0.000029371, Loss: 1.001824, Time/step: 444.835135
10/13/2023 01:08:17 - INFO -   Epoch: 1/5, Step: 22/143, Lr: 0.000000031-0.000030769, Loss: 0.660706, Time/step: 11.594020
10/13/2023 01:08:29 - INFO -   Epoch: 1/5, Step: 23/143, Lr: 0.000000032-0.000032168, Loss: 0.851864, Time/step: 11.765488
10/13/2023 01:08:40 - INFO -   Epoch: 1/5, Step: 24/143, Lr: 0.000000034-0.000033566, Loss: 0.923743, Time/step: 11.228222
10/13/2023 01:08:52 - INFO -   Epoch: 1/5, Step: 25/143, Lr: 0.000000035-0.000034965, Loss: 1.166949, Time/step: 11.572670
10/13/2023 01:09:03 - INFO -   Epoch: 1/5, Step: 26/143, Lr: 0.000000036-0.000036364, Loss: 0.780769, Time/step: 11.240516
10/13/2023 01:09:14 - INFO -   Epoch: 1/5, Step: 27/143, Lr: 0.000000038-0.000037762, Loss: 0.839000, Time/step: 11.336037
10/13/2023 01:13:10 - INFO -   Epoch: 1/5, Step: 28/143, Lr: 0.000000039-0.000039161, Loss: 0.835879, Time/step: 235.198111
10/13/2023 01:13:22 - INFO -   Epoch: 1/5, Step: 29/143, Lr: 0.000000041-0.000040559, Loss: 0.940381, Time/step: 12.297890
10/13/2023 01:13:34 - INFO -   Epoch: 1/5, Step: 30/143, Lr: 0.000000042-0.000041958, Loss: 0.575210, Time/step: 12.038522
10/13/2023 01:13:45 - INFO -   Epoch: 1/5, Step: 31/143, Lr: 0.000000043-0.000043357, Loss: 1.162596, Time/step: 11.198679
10/13/2023 01:13:57 - INFO -   Epoch: 1/5, Step: 32/143, Lr: 0.000000045-0.000044755, Loss: 1.098262, Time/step: 12.265491
10/13/2023 02:53:09 - INFO -   Epoch: 1/5, Step: 33/143, Lr: 0.000000046-0.000046154, Loss: 0.918944, Time/step: 5951.800446
10/13/2023 02:53:21 - INFO -   Epoch: 1/5, Step: 34/143, Lr: 0.000000048-0.000047552, Loss: 0.929349, Time/step: 11.632821
10/13/2023 02:53:32 - INFO -   Epoch: 1/5, Step: 35/143, Lr: 0.000000049-0.000048951, Loss: 0.807216, Time/step: 11.003330
10/13/2023 02:53:43 - INFO -   Epoch: 1/5, Step: 36/143, Lr: 0.000000050-0.000050350, Loss: 1.044180, Time/step: 11.221897
10/13/2023 02:53:55 - INFO -   Epoch: 1/5, Step: 37/143, Lr: 0.000000052-0.000051748, Loss: 0.783209, Time/step: 11.413640
10/13/2023 02:54:05 - INFO -   Epoch: 1/5, Step: 38/143, Lr: 0.000000053-0.000053147, Loss: 0.771469, Time/step: 10.795285
10/13/2023 02:54:17 - INFO -   Epoch: 1/5, Step: 39/143, Lr: 0.000000055-0.000054545, Loss: 1.193971, Time/step: 11.516761
10/13/2023 02:54:28 - INFO -   Epoch: 1/5, Step: 40/143, Lr: 0.000000056-0.000055944, Loss: 1.175190, Time/step: 11.162586
10/13/2023 02:54:39 - INFO -   Epoch: 1/5, Step: 41/143, Lr: 0.000000057-0.000057343, Loss: 0.918855, Time/step: 10.735206
10/13/2023 02:54:51 - INFO -   Epoch: 1/5, Step: 42/143, Lr: 0.000000059-0.000058741, Loss: 0.880064, Time/step: 11.913557
10/13/2023 02:55:02 - INFO -   Epoch: 1/5, Step: 43/143, Lr: 0.000000060-0.000060140, Loss: 0.599280, Time/step: 11.342074
10/13/2023 02:55:14 - INFO -   Epoch: 1/5, Step: 44/143, Lr: 0.000000062-0.000061538, Loss: 1.377254, Time/step: 11.730893
10/13/2023 02:55:25 - INFO -   Epoch: 1/5, Step: 45/143, Lr: 0.000000063-0.000062937, Loss: 0.727581, Time/step: 10.775776
10/13/2023 02:55:36 - INFO -   Epoch: 1/5, Step: 46/143, Lr: 0.000000064-0.000064336, Loss: 1.275769, Time/step: 11.695030
10/13/2023 02:55:48 - INFO -   Epoch: 1/5, Step: 47/143, Lr: 0.000000066-0.000065734, Loss: 0.578969, Time/step: 11.555801
10/13/2023 02:56:00 - INFO -   Epoch: 1/5, Step: 48/143, Lr: 0.000000067-0.000067133, Loss: 0.738352, Time/step: 12.180416
10/13/2023 04:32:30 - INFO -   Epoch: 1/5, Step: 49/143, Lr: 0.000000069-0.000068531, Loss: 0.915809, Time/step: 5790.272570
10/13/2023 04:32:40 - INFO -   Epoch: 1/5, Step: 50/143, Lr: 0.000000070-0.000069930, Loss: 1.091215, Time/step: 9.878833
10/13/2023 04:32:50 - INFO -   Epoch: 1/5, Step: 51/143, Lr: 0.000000071-0.000071329, Loss: 0.822624, Time/step: 9.582181
10/13/2023 04:33:00 - INFO -   Epoch: 1/5, Step: 52/143, Lr: 0.000000073-0.000072727, Loss: 1.071560, Time/step: 9.999681
10/13/2023 04:33:10 - INFO -   Epoch: 1/5, Step: 53/143, Lr: 0.000000074-0.000074126, Loss: 0.766358, Time/step: 10.120601
10/13/2023 04:33:20 - INFO -   Epoch: 1/5, Step: 54/143, Lr: 0.000000076-0.000075524, Loss: 0.990354, Time/step: 9.948110
10/13/2023 04:33:30 - INFO -   Epoch: 1/5, Step: 55/143, Lr: 0.000000077-0.000076923, Loss: 0.872856, Time/step: 10.387333
10/13/2023 04:33:41 - INFO -   Epoch: 1/5, Step: 56/143, Lr: 0.000000078-0.000078322, Loss: 0.891959, Time/step: 10.583625
10/13/2023 04:33:51 - INFO -   Epoch: 1/5, Step: 57/143, Lr: 0.000000080-0.000079720, Loss: 1.184607, Time/step: 10.424214
10/13/2023 04:34:02 - INFO -   Epoch: 1/5, Step: 58/143, Lr: 0.000000081-0.000081119, Loss: 0.645359, Time/step: 10.655837
10/13/2023 04:34:12 - INFO -   Epoch: 1/5, Step: 59/143, Lr: 0.000000083-0.000082517, Loss: 1.001316, Time/step: 10.613810
10/13/2023 04:34:23 - INFO -   Epoch: 1/5, Step: 60/143, Lr: 0.000000084-0.000083916, Loss: 0.764853, Time/step: 10.514624
10/13/2023 04:34:34 - INFO -   Epoch: 1/5, Step: 61/143, Lr: 0.000000085-0.000085315, Loss: 0.919946, Time/step: 11.281123
10/13/2023 04:34:46 - INFO -   Epoch: 1/5, Step: 62/143, Lr: 0.000000087-0.000086713, Loss: 0.721223, Time/step: 11.085075
10/13/2023 04:34:57 - INFO -   Epoch: 1/5, Step: 63/143, Lr: 0.000000088-0.000088112, Loss: 0.814038, Time/step: 11.548057
10/13/2023 04:35:09 - INFO -   Epoch: 1/5, Step: 64/143, Lr: 0.000000090-0.000089510, Loss: 0.910726, Time/step: 11.921031
10/13/2023 06:01:06 - INFO -   Epoch: 1/5, Step: 65/143, Lr: 0.000000091-0.000090909, Loss: 1.313925, Time/step: 5156.738852
10/13/2023 06:01:16 - INFO -   Epoch: 1/5, Step: 66/143, Lr: 0.000000092-0.000092308, Loss: 0.845567, Time/step: 10.433750
10/13/2023 06:01:27 - INFO -   Epoch: 1/5, Step: 67/143, Lr: 0.000000094-0.000093706, Loss: 0.858630, Time/step: 10.608084
10/13/2023 06:01:38 - INFO -   Epoch: 1/5, Step: 68/143, Lr: 0.000000095-0.000095105, Loss: 0.688389, Time/step: 10.779919
10/13/2023 06:01:49 - INFO -   Epoch: 1/5, Step: 69/143, Lr: 0.000000097-0.000096503, Loss: 0.632641, Time/step: 10.912502
10/13/2023 06:02:00 - INFO -   Epoch: 1/5, Step: 70/143, Lr: 0.000000098-0.000097902, Loss: 0.915032, Time/step: 11.263300
10/13/2023 06:02:11 - INFO -   Epoch: 1/5, Step: 71/143, Lr: 0.000000099-0.000099301, Loss: 0.617150, Time/step: 11.605530
10/13/2023 06:02:23 - INFO -   Epoch: 1/5, Step: 72/143, Lr: 0.000000098-0.000097519, Loss: 0.904284, Time/step: 11.538425
10/13/2023 06:02:34 - INFO -   Epoch: 1/5, Step: 73/143, Lr: 0.000000097-0.000097450, Loss: 0.945835, Time/step: 11.448997
10/13/2023 06:02:46 - INFO -   Epoch: 1/5, Step: 74/143, Lr: 0.000000097-0.000097380, Loss: 0.959554, Time/step: 11.328734
10/13/2023 06:02:57 - INFO -   Epoch: 1/5, Step: 75/143, Lr: 0.000000097-0.000097310, Loss: 0.754679, Time/step: 11.491567
10/13/2023 06:03:09 - INFO -   Epoch: 1/5, Step: 76/143, Lr: 0.000000097-0.000097238, Loss: 0.689189, Time/step: 11.801763
10/13/2023 06:03:21 - INFO -   Epoch: 1/5, Step: 77/143, Lr: 0.000000097-0.000097166, Loss: 0.761148, Time/step: 11.909399
10/13/2023 06:03:32 - INFO -   Epoch: 1/5, Step: 78/143, Lr: 0.000000097-0.000097092, Loss: 0.963957, Time/step: 11.215848
10/13/2023 06:03:45 - INFO -   Epoch: 1/5, Step: 79/143, Lr: 0.000000097-0.000097018, Loss: 0.961426, Time/step: 12.555714
10/13/2023 06:03:57 - INFO -   Epoch: 1/5, Step: 80/143, Lr: 0.000000097-0.000096943, Loss: 0.686590, Time/step: 11.906379
10/13/2023 07:37:22 - INFO -   Epoch: 1/5, Step: 81/143, Lr: 0.000000097-0.000096867, Loss: 1.192777, Time/step: 5605.333585
10/13/2023 07:37:33 - INFO -   Epoch: 1/5, Step: 82/143, Lr: 0.000000097-0.000096790, Loss: 0.847073, Time/step: 10.995254
10/13/2023 07:37:46 - INFO -   Epoch: 1/5, Step: 83/143, Lr: 0.000000097-0.000096712, Loss: 0.718428, Time/step: 12.315164
10/13/2023 07:37:57 - INFO -   Epoch: 1/5, Step: 84/143, Lr: 0.000000097-0.000096633, Loss: 0.575876, Time/step: 11.527165
10/13/2023 07:38:08 - INFO -   Epoch: 1/5, Step: 85/143, Lr: 0.000000097-0.000096553, Loss: 0.493483, Time/step: 11.091892
10/13/2023 07:38:20 - INFO -   Epoch: 1/5, Step: 86/143, Lr: 0.000000096-0.000096473, Loss: 0.898720, Time/step: 11.261446
10/13/2023 07:38:31 - INFO -   Epoch: 1/5, Step: 87/143, Lr: 0.000000096-0.000096391, Loss: 0.568098, Time/step: 11.602575
10/13/2023 07:38:43 - INFO -   Epoch: 1/5, Step: 88/143, Lr: 0.000000096-0.000096309, Loss: 1.005557, Time/step: 11.990624
10/13/2023 07:38:55 - INFO -   Epoch: 1/5, Step: 89/143, Lr: 0.000000096-0.000096225, Loss: 0.834179, Time/step: 11.615303
10/13/2023 07:39:06 - INFO -   Epoch: 1/5, Step: 90/143, Lr: 0.000000096-0.000096141, Loss: 1.066303, Time/step: 11.471182
10/13/2023 07:39:18 - INFO -   Epoch: 1/5, Step: 91/143, Lr: 0.000000096-0.000096056, Loss: 0.932085, Time/step: 11.504783
10/13/2023 07:39:29 - INFO -   Epoch: 1/5, Step: 92/143, Lr: 0.000000096-0.000095970, Loss: 0.645388, Time/step: 11.143842
10/13/2023 07:39:41 - INFO -   Epoch: 1/5, Step: 93/143, Lr: 0.000000096-0.000095883, Loss: 0.796578, Time/step: 11.948704
10/13/2023 07:39:53 - INFO -   Epoch: 1/5, Step: 94/143, Lr: 0.000000096-0.000095796, Loss: 0.740841, Time/step: 11.741576
10/13/2023 07:40:05 - INFO -   Epoch: 1/5, Step: 95/143, Lr: 0.000000096-0.000095707, Loss: 0.621235, Time/step: 12.335587
10/13/2023 07:40:17 - INFO -   Epoch: 1/5, Step: 96/143, Lr: 0.000000096-0.000095618, Loss: 0.603250, Time/step: 11.825449
10/13/2023 08:45:02 - INFO -   Epoch: 1/5, Step: 97/143, Lr: 0.000000096-0.000095527, Loss: 0.742817, Time/step: 3885.305352
10/13/2023 08:45:14 - INFO -   Epoch: 1/5, Step: 98/143, Lr: 0.000000095-0.000095436, Loss: 0.916714, Time/step: 11.960606
10/13/2023 08:45:25 - INFO -   Epoch: 1/5, Step: 99/143, Lr: 0.000000095-0.000095344, Loss: 0.515609, Time/step: 11.358165
10/13/2023 08:45:38 - INFO -   Epoch: 1/5, Step: 100/143, Lr: 0.000000095-0.000095251, Loss: 0.711139, Time/step: 12.914495
10/13/2023 08:45:51 - INFO -   Epoch: 1/5, Step: 101/143, Lr: 0.000000095-0.000095157, Loss: 0.682313, Time/step: 12.220544
10/13/2023 08:59:02 - INFO -   Epoch: 1/5, Step: 102/143, Lr: 0.000000095-0.000095062, Loss: 0.741823, Time/step: 791.187434
10/13/2023 08:59:13 - INFO -   Epoch: 1/5, Step: 103/143, Lr: 0.000000095-0.000094966, Loss: 0.386148, Time/step: 11.124812
10/13/2023 08:59:25 - INFO -   Epoch: 1/5, Step: 104/143, Lr: 0.000000095-0.000094870, Loss: 0.560156, Time/step: 12.110166
10/13/2023 08:59:37 - INFO -   Epoch: 1/5, Step: 105/143, Lr: 0.000000095-0.000094773, Loss: 0.910591, Time/step: 11.694649
10/13/2023 09:02:06 - INFO -   Epoch: 1/5, Step: 106/143, Lr: 0.000000095-0.000094674, Loss: 1.158938, Time/step: 148.704698
10/13/2023 09:02:17 - INFO -   Epoch: 1/5, Step: 107/143, Lr: 0.000000095-0.000094575, Loss: 1.328389, Time/step: 11.616869
10/13/2023 09:25:06 - INFO -   Epoch: 1/5, Step: 108/143, Lr: 0.000000094-0.000094475, Loss: 0.694744, Time/step: 1368.238588
10/13/2023 09:25:17 - INFO -   Epoch: 1/5, Step: 109/143, Lr: 0.000000094-0.000094374, Loss: 0.889720, Time/step: 11.082784
10/13/2023 09:25:28 - INFO -   Epoch: 1/5, Step: 110/143, Lr: 0.000000094-0.000094273, Loss: 0.521359, Time/step: 11.608961
10/13/2023 09:25:40 - INFO -   Epoch: 1/5, Step: 111/143, Lr: 0.000000094-0.000094170, Loss: 0.887987, Time/step: 11.270958
10/13/2023 09:25:52 - INFO -   Epoch: 1/5, Step: 112/143, Lr: 0.000000094-0.000094067, Loss: 0.610941, Time/step: 12.381123
10/13/2023 09:51:30 - INFO -   Epoch: 1/5, Step: 113/143, Lr: 0.000000094-0.000093963, Loss: 0.750364, Time/step: 1537.695895
10/13/2023 10:07:17 - INFO -   Epoch: 1/5, Step: 114/143, Lr: 0.000000094-0.000093858, Loss: 0.958055, Time/step: 947.477780
10/13/2023 10:07:29 - INFO -   Epoch: 1/5, Step: 115/143, Lr: 0.000000094-0.000093752, Loss: 1.146983, Time/step: 11.210134
10/13/2023 10:07:40 - INFO -   Epoch: 1/5, Step: 116/143, Lr: 0.000000094-0.000093645, Loss: 0.883685, Time/step: 11.040541
10/13/2023 10:14:38 - INFO -   Epoch: 1/5, Step: 117/143, Lr: 0.000000094-0.000093537, Loss: 0.771183, Time/step: 418.084145
10/13/2023 10:14:49 - INFO -   Epoch: 1/5, Step: 118/143, Lr: 0.000000093-0.000093429, Loss: 0.775382, Time/step: 10.826176
10/13/2023 10:15:00 - INFO -   Epoch: 1/5, Step: 119/143, Lr: 0.000000093-0.000093320, Loss: 0.818692, Time/step: 11.447923
10/13/2023 10:15:11 - INFO -   Epoch: 1/5, Step: 120/143, Lr: 0.000000093-0.000093209, Loss: 0.678847, Time/step: 10.432150
10/13/2023 10:15:22 - INFO -   Epoch: 1/5, Step: 121/143, Lr: 0.000000093-0.000093098, Loss: 0.697369, Time/step: 10.944212
10/13/2023 10:30:56 - INFO -   Epoch: 1/5, Step: 122/143, Lr: 0.000000093-0.000092987, Loss: 0.539207, Time/step: 934.136072
10/13/2023 10:31:05 - INFO -   Epoch: 1/5, Step: 123/143, Lr: 0.000000093-0.000092874, Loss: 0.780523, Time/step: 9.445026
10/13/2023 10:44:10 - INFO -   Epoch: 1/5, Step: 124/143, Lr: 0.000000093-0.000092761, Loss: 0.510140, Time/step: 785.146346
10/13/2023 10:44:19 - INFO -   Epoch: 1/5, Step: 125/143, Lr: 0.000000093-0.000092646, Loss: 0.531524, Time/step: 8.241269
10/13/2023 10:44:27 - INFO -   Epoch: 1/5, Step: 126/143, Lr: 0.000000093-0.000092531, Loss: 0.720722, Time/step: 8.184396
10/13/2023 10:44:35 - INFO -   Epoch: 1/5, Step: 127/143, Lr: 0.000000092-0.000092415, Loss: 0.700592, Time/step: 8.464349
10/13/2023 10:44:44 - INFO -   Epoch: 1/5, Step: 128/143, Lr: 0.000000092-0.000092299, Loss: 0.718642, Time/step: 8.516227
10/13/2023 10:59:06 - INFO -   Epoch: 1/5, Step: 129/143, Lr: 0.000000092-0.000092181, Loss: 0.628526, Time/step: 862.303665
10/13/2023 11:01:12 - INFO -   Epoch: 1/5, Step: 130/143, Lr: 0.000000092-0.000092063, Loss: 0.846044, Time/step: 125.595515
10/13/2023 11:01:14 - INFO -   Epoch: 1/5, Step: 131/143, Lr: 0.000000092-0.000091943, Loss: 0.437594, Time/step: 2.474793
10/13/2023 11:01:17 - INFO -   Epoch: 1/5, Step: 132/143, Lr: 0.000000092-0.000091824, Loss: 0.595475, Time/step: 2.697446
10/13/2023 11:03:34 - INFO -   Epoch: 1/5, Step: 133/143, Lr: 0.000000092-0.000091703, Loss: 0.717737, Time/step: 136.841031
10/13/2023 11:03:36 - INFO -   Epoch: 1/5, Step: 134/143, Lr: 0.000000092-0.000091581, Loss: 0.673944, Time/step: 2.133767
10/13/2023 11:03:38 - INFO -   Epoch: 1/5, Step: 135/143, Lr: 0.000000091-0.000091459, Loss: 0.681625, Time/step: 2.157492
10/13/2023 11:03:40 - INFO -   Epoch: 1/5, Step: 136/143, Lr: 0.000000091-0.000091335, Loss: 0.491179, Time/step: 2.223501
10/13/2023 11:03:43 - INFO -   Epoch: 1/5, Step: 137/143, Lr: 0.000000091-0.000091211, Loss: 0.778330, Time/step: 2.189613
10/13/2023 11:04:43 - INFO -   Epoch: 1/5, Step: 138/143, Lr: 0.000000091-0.000091087, Loss: 0.544961, Time/step: 60.038539
10/13/2023 11:04:44 - INFO -   Epoch: 1/5, Step: 139/143, Lr: 0.000000091-0.000090961, Loss: 0.540456, Time/step: 1.105391
10/13/2023 11:04:45 - INFO -   Epoch: 1/5, Step: 140/143, Lr: 0.000000091-0.000090835, Loss: 0.514922, Time/step: 1.070084
10/13/2023 11:04:46 - INFO -   Epoch: 1/5, Step: 141/143, Lr: 0.000000091-0.000090708, Loss: 0.832964, Time/step: 1.101412
10/13/2023 11:04:47 - INFO -   Epoch: 1/5, Step: 142/143, Lr: 0.000000091-0.000090580, Loss: 0.518826, Time/step: 1.077816
10/13/2023 11:04:48 - INFO -   Epoch: 1/5, Step: 143/143, Lr: 0.000000090-0.000090451, Loss: 0.549467, Time/step: 1.325940
10/13/2023 11:04:50 - INFO -   Epoch 1/5 Finished, Train Loss: 0.838012
10/13/2023 11:05:05 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_model.bin.0
10/13/2023 11:05:05 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_opt.bin.0
10/13/2023 11:05:05 - INFO -   Eval on val dataset
10/13/2023 12:46:27 - INFO -   sim matrix size: 184, 184
10/13/2023 12:46:27 - INFO -   	 Length-T: 184, Length-V:184
10/13/2023 12:46:27 - INFO -   Text-to-Video:
10/13/2023 12:46:27 - INFO -   	>>>  R@1: 58.7 - R@5: 81.5 - R@10: 87.5 - Median R: 1.0 - Mean R: 5.9
10/13/2023 12:46:27 - INFO -   Video-to-Text:
10/13/2023 12:46:27 - INFO -   	>>>  V2T$R@1: 57.1 - V2T$R@5: 85.9 - V2T$R@10: 89.7 - V2T$Median R: 1.0 - V2T$Mean R: 5.1
10/13/2023 12:46:27 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_model.bin.0, the R1 is: 58.6957
10/13/2023 13:31:10 - INFO -   Epoch: 2/5, Step: 1/143, Lr: 0.000000090-0.000090321, Loss: 0.404074, Time/step: 2682.003106
10/13/2023 13:39:13 - INFO -   Epoch: 2/5, Step: 2/143, Lr: 0.000000090-0.000090191, Loss: 0.376501, Time/step: 482.958816
10/13/2023 13:39:20 - INFO -   Epoch: 2/5, Step: 3/143, Lr: 0.000000090-0.000090060, Loss: 0.274801, Time/step: 6.910173
10/13/2023 13:41:25 - INFO -   Epoch: 2/5, Step: 4/143, Lr: 0.000000090-0.000089928, Loss: 0.518149, Time/step: 125.305149
10/13/2023 13:41:33 - INFO -   Epoch: 2/5, Step: 5/143, Lr: 0.000000090-0.000089795, Loss: 0.491890, Time/step: 7.574620
10/13/2023 13:41:41 - INFO -   Epoch: 2/5, Step: 6/143, Lr: 0.000000090-0.000089662, Loss: 0.539128, Time/step: 7.944080
10/13/2023 13:41:49 - INFO -   Epoch: 2/5, Step: 7/143, Lr: 0.000000090-0.000089528, Loss: 0.384224, Time/step: 8.555087
10/13/2023 13:41:58 - INFO -   Epoch: 2/5, Step: 8/143, Lr: 0.000000089-0.000089393, Loss: 0.380084, Time/step: 8.648504
10/13/2023 13:42:07 - INFO -   Epoch: 2/5, Step: 9/143, Lr: 0.000000089-0.000089257, Loss: 0.286648, Time/step: 9.331282
10/13/2023 13:42:17 - INFO -   Epoch: 2/5, Step: 10/143, Lr: 0.000000089-0.000089121, Loss: 0.426101, Time/step: 9.868843
10/13/2023 13:42:27 - INFO -   Epoch: 2/5, Step: 11/143, Lr: 0.000000089-0.000088984, Loss: 0.360198, Time/step: 10.313359
10/13/2023 13:42:39 - INFO -   Epoch: 2/5, Step: 12/143, Lr: 0.000000089-0.000088846, Loss: 0.644408, Time/step: 11.317553
10/13/2023 13:56:55 - INFO -   Epoch: 2/5, Step: 13/143, Lr: 0.000000089-0.000088707, Loss: 0.187632, Time/step: 856.561978
10/13/2023 13:57:06 - INFO -   Epoch: 2/5, Step: 14/143, Lr: 0.000000089-0.000088568, Loss: 0.426300, Time/step: 11.158128
10/13/2023 13:57:18 - INFO -   Epoch: 2/5, Step: 15/143, Lr: 0.000000088-0.000088427, Loss: 0.240727, Time/step: 11.691889
10/13/2023 13:57:30 - INFO -   Epoch: 2/5, Step: 16/143, Lr: 0.000000088-0.000088287, Loss: 0.638403, Time/step: 11.577616
10/13/2023 15:08:03 - INFO -   Epoch: 2/5, Step: 17/143, Lr: 0.000000088-0.000088145, Loss: 0.350183, Time/step: 4232.958243
10/13/2023 15:08:12 - INFO -   Epoch: 2/5, Step: 18/143, Lr: 0.000000088-0.000088002, Loss: 0.477313, Time/step: 9.508856
10/13/2023 15:08:21 - INFO -   Epoch: 2/5, Step: 19/143, Lr: 0.000000088-0.000087859, Loss: 0.519766, Time/step: 9.049407
10/13/2023 15:08:31 - INFO -   Epoch: 2/5, Step: 20/143, Lr: 0.000000088-0.000087715, Loss: 0.350853, Time/step: 9.630015
10/13/2023 15:08:41 - INFO -   Epoch: 2/5, Step: 21/143, Lr: 0.000000088-0.000087571, Loss: 0.314370, Time/step: 9.742926
10/13/2023 15:08:51 - INFO -   Epoch: 2/5, Step: 22/143, Lr: 0.000000087-0.000087426, Loss: 0.507575, Time/step: 10.089811
10/13/2023 15:09:01 - INFO -   Epoch: 2/5, Step: 23/143, Lr: 0.000000087-0.000087279, Loss: 0.555764, Time/step: 10.400881
10/13/2023 15:15:12 - INFO -   Epoch: 2/5, Step: 24/143, Lr: 0.000000087-0.000087133, Loss: 0.683551, Time/step: 371.392939
10/13/2023 15:15:23 - INFO -   Epoch: 2/5, Step: 25/143, Lr: 0.000000087-0.000086985, Loss: 0.355876, Time/step: 10.369083
10/13/2023 15:15:34 - INFO -   Epoch: 2/5, Step: 26/143, Lr: 0.000000087-0.000086837, Loss: 0.345088, Time/step: 10.638061
10/13/2023 15:15:45 - INFO -   Epoch: 2/5, Step: 27/143, Lr: 0.000000087-0.000086688, Loss: 0.331650, Time/step: 11.059342
10/13/2023 15:15:56 - INFO -   Epoch: 2/5, Step: 28/143, Lr: 0.000000087-0.000086539, Loss: 0.453326, Time/step: 11.247037
10/13/2023 15:16:08 - INFO -   Epoch: 2/5, Step: 29/143, Lr: 0.000000086-0.000086388, Loss: 0.208634, Time/step: 11.585655
10/13/2023 15:16:20 - INFO -   Epoch: 2/5, Step: 30/143, Lr: 0.000000086-0.000086237, Loss: 0.186539, Time/step: 12.082769
10/13/2023 15:16:31 - INFO -   Epoch: 2/5, Step: 31/143, Lr: 0.000000086-0.000086085, Loss: 0.332621, Time/step: 11.690829
10/13/2023 15:16:44 - INFO -   Epoch: 2/5, Step: 32/143, Lr: 0.000000086-0.000085933, Loss: 0.537803, Time/step: 12.676645
10/13/2023 16:33:14 - INFO -   Epoch: 2/5, Step: 33/143, Lr: 0.000000086-0.000085780, Loss: 0.477880, Time/step: 4590.047996
10/13/2023 16:33:25 - INFO -   Epoch: 2/5, Step: 34/143, Lr: 0.000000086-0.000085626, Loss: 0.282989, Time/step: 10.926962
10/13/2023 16:33:37 - INFO -   Epoch: 2/5, Step: 35/143, Lr: 0.000000085-0.000085472, Loss: 0.361781, Time/step: 12.196115
10/13/2023 16:38:01 - INFO -   Epoch: 2/5, Step: 36/143, Lr: 0.000000085-0.000085316, Loss: 0.285309, Time/step: 263.296108
10/13/2023 16:41:25 - INFO -   Epoch: 2/5, Step: 37/143, Lr: 0.000000085-0.000085161, Loss: 0.728861, Time/step: 204.463932
10/13/2023 16:41:36 - INFO -   Epoch: 2/5, Step: 38/143, Lr: 0.000000085-0.000085004, Loss: 0.439341, Time/step: 10.827474
10/13/2023 16:43:29 - INFO -   Epoch: 2/5, Step: 39/143, Lr: 0.000000085-0.000084847, Loss: 0.284003, Time/step: 113.064113
10/13/2023 17:09:38 - INFO -   Epoch: 2/5, Step: 40/143, Lr: 0.000000085-0.000084689, Loss: 0.242559, Time/step: 1568.864711
10/13/2023 17:09:48 - INFO -   Epoch: 2/5, Step: 41/143, Lr: 0.000000085-0.000084530, Loss: 0.461488, Time/step: 9.407485
10/13/2023 17:09:58 - INFO -   Epoch: 2/5, Step: 42/143, Lr: 0.000000084-0.000084371, Loss: 0.467065, Time/step: 9.896494
10/13/2023 17:10:08 - INFO -   Epoch: 2/5, Step: 43/143, Lr: 0.000000084-0.000084211, Loss: 0.425987, Time/step: 10.591253
10/13/2023 17:10:19 - INFO -   Epoch: 2/5, Step: 44/143, Lr: 0.000000084-0.000084051, Loss: 0.370229, Time/step: 10.384627
10/13/2023 17:10:29 - INFO -   Epoch: 2/5, Step: 45/143, Lr: 0.000000084-0.000083890, Loss: 0.334054, Time/step: 10.107645
10/13/2023 17:10:40 - INFO -   Epoch: 2/5, Step: 46/143, Lr: 0.000000084-0.000083728, Loss: 0.444974, Time/step: 11.567754
10/13/2023 17:10:52 - INFO -   Epoch: 2/5, Step: 47/143, Lr: 0.000000084-0.000083565, Loss: 0.375918, Time/step: 11.139798
10/13/2023 17:11:04 - INFO -   Epoch: 2/5, Step: 48/143, Lr: 0.000000083-0.000083402, Loss: 0.430768, Time/step: 12.436133
10/13/2023 17:50:51 - INFO -   Epoch: 2/5, Step: 49/143, Lr: 0.000000083-0.000083238, Loss: 0.497717, Time/step: 2386.882186
10/13/2023 17:51:24 - INFO -   Epoch: 2/5, Step: 50/143, Lr: 0.000000083-0.000083074, Loss: 0.491774, Time/step: 33.194993
10/13/2023 18:01:49 - INFO -   Epoch: 2/5, Step: 51/143, Lr: 0.000000083-0.000082909, Loss: 0.638435, Time/step: 624.872579
10/13/2023 18:02:01 - INFO -   Epoch: 2/5, Step: 52/143, Lr: 0.000000083-0.000082743, Loss: 0.513424, Time/step: 11.924886
10/13/2023 18:14:28 - INFO -   Epoch: 2/5, Step: 53/143, Lr: 0.000000083-0.000082577, Loss: 0.251185, Time/step: 747.347471
10/13/2023 18:14:41 - INFO -   Epoch: 2/5, Step: 54/143, Lr: 0.000000082-0.000082410, Loss: 0.324827, Time/step: 12.120589
10/13/2023 18:14:53 - INFO -   Epoch: 2/5, Step: 55/143, Lr: 0.000000082-0.000082242, Loss: 0.534053, Time/step: 12.372045
10/13/2023 18:51:33 - INFO -   Epoch: 2/5, Step: 56/143, Lr: 0.000000082-0.000082074, Loss: 0.462290, Time/step: 2200.241383
10/13/2023 18:51:42 - INFO -   Epoch: 2/5, Step: 57/143, Lr: 0.000000082-0.000081905, Loss: 0.312643, Time/step: 9.219689
10/13/2023 18:51:52 - INFO -   Epoch: 2/5, Step: 58/143, Lr: 0.000000082-0.000081736, Loss: 0.345348, Time/step: 9.894703
10/13/2023 18:52:03 - INFO -   Epoch: 2/5, Step: 59/143, Lr: 0.000000082-0.000081566, Loss: 0.124396, Time/step: 10.516627
10/13/2023 18:52:14 - INFO -   Epoch: 2/5, Step: 60/143, Lr: 0.000000081-0.000081395, Loss: 0.568711, Time/step: 10.897774
10/13/2023 18:52:25 - INFO -   Epoch: 2/5, Step: 61/143, Lr: 0.000000081-0.000081224, Loss: 0.281753, Time/step: 10.779512
10/13/2023 18:52:35 - INFO -   Epoch: 2/5, Step: 62/143, Lr: 0.000000081-0.000081052, Loss: 0.410904, Time/step: 10.584536
10/13/2023 18:52:47 - INFO -   Epoch: 2/5, Step: 63/143, Lr: 0.000000081-0.000080879, Loss: 0.264669, Time/step: 12.174975
10/13/2023 18:52:59 - INFO -   Epoch: 2/5, Step: 64/143, Lr: 0.000000081-0.000080706, Loss: 0.298250, Time/step: 11.735528
10/13/2023 19:09:19 - INFO -   Epoch: 2/5, Step: 65/143, Lr: 0.000000081-0.000080532, Loss: 0.422179, Time/step: 979.462566
10/13/2023 19:13:43 - INFO -   Epoch: 2/5, Step: 66/143, Lr: 0.000000080-0.000080358, Loss: 0.481217, Time/step: 264.146918
10/13/2023 19:19:07 - INFO -   Epoch: 2/5, Step: 67/143, Lr: 0.000000080-0.000080183, Loss: 0.572702, Time/step: 323.989201
10/13/2023 19:19:19 - INFO -   Epoch: 2/5, Step: 68/143, Lr: 0.000000080-0.000080008, Loss: 0.600383, Time/step: 12.390426
10/13/2023 19:59:16 - INFO -   Epoch: 2/5, Step: 69/143, Lr: 0.000000080-0.000079832, Loss: 0.310083, Time/step: 2396.771508
10/13/2023 19:59:28 - INFO -   Epoch: 2/5, Step: 70/143, Lr: 0.000000080-0.000079655, Loss: 0.256906, Time/step: 11.506832
10/13/2023 19:59:39 - INFO -   Epoch: 2/5, Step: 71/143, Lr: 0.000000079-0.000079478, Loss: 0.299190, Time/step: 11.069589
10/13/2023 20:13:56 - INFO -   Epoch: 2/5, Step: 72/143, Lr: 0.000000079-0.000079300, Loss: 0.454834, Time/step: 856.740037
10/13/2023 20:14:05 - INFO -   Epoch: 2/5, Step: 73/143, Lr: 0.000000079-0.000079122, Loss: 0.544189, Time/step: 9.774539
10/13/2023 20:14:16 - INFO -   Epoch: 2/5, Step: 74/143, Lr: 0.000000079-0.000078943, Loss: 0.292527, Time/step: 10.405138
10/13/2023 20:14:27 - INFO -   Epoch: 2/5, Step: 75/143, Lr: 0.000000079-0.000078764, Loss: 0.288212, Time/step: 10.820397
10/13/2023 20:14:38 - INFO -   Epoch: 2/5, Step: 76/143, Lr: 0.000000079-0.000078584, Loss: 0.336600, Time/step: 11.193187
10/13/2023 20:14:48 - INFO -   Epoch: 2/5, Step: 77/143, Lr: 0.000000078-0.000078403, Loss: 0.561983, Time/step: 10.352736
10/13/2023 20:15:00 - INFO -   Epoch: 2/5, Step: 78/143, Lr: 0.000000078-0.000078222, Loss: 0.558797, Time/step: 11.524520
10/13/2023 20:15:11 - INFO -   Epoch: 2/5, Step: 79/143, Lr: 0.000000078-0.000078041, Loss: 0.300109, Time/step: 11.404909
10/13/2023 20:15:23 - INFO -   Epoch: 2/5, Step: 80/143, Lr: 0.000000078-0.000077858, Loss: 0.221800, Time/step: 11.730655
10/13/2023 20:53:51 - INFO -   Epoch: 2/5, Step: 81/143, Lr: 0.000000078-0.000077676, Loss: 0.497653, Time/step: 2307.956357
10/13/2023 21:02:37 - INFO -   Epoch: 2/5, Step: 82/143, Lr: 0.000000077-0.000077492, Loss: 0.495112, Time/step: 525.509168
10/13/2023 21:02:49 - INFO -   Epoch: 2/5, Step: 83/143, Lr: 0.000000077-0.000077309, Loss: 0.419587, Time/step: 12.189692
10/13/2023 21:03:01 - INFO -   Epoch: 2/5, Step: 84/143, Lr: 0.000000077-0.000077124, Loss: 0.414479, Time/step: 12.518148
10/13/2023 21:49:37 - INFO -   Epoch: 2/5, Step: 85/143, Lr: 0.000000077-0.000076940, Loss: 0.352754, Time/step: 2796.033983
10/13/2023 21:49:47 - INFO -   Epoch: 2/5, Step: 86/143, Lr: 0.000000077-0.000076754, Loss: 0.344846, Time/step: 9.036968
10/13/2023 21:49:56 - INFO -   Epoch: 2/5, Step: 87/143, Lr: 0.000000077-0.000076568, Loss: 0.529902, Time/step: 9.499377
10/13/2023 21:50:06 - INFO -   Epoch: 2/5, Step: 88/143, Lr: 0.000000076-0.000076382, Loss: 0.441620, Time/step: 9.712550
10/13/2023 21:50:16 - INFO -   Epoch: 2/5, Step: 89/143, Lr: 0.000000076-0.000076195, Loss: 0.479218, Time/step: 10.094390
10/13/2023 21:50:27 - INFO -   Epoch: 2/5, Step: 90/143, Lr: 0.000000076-0.000076008, Loss: 0.277770, Time/step: 10.555918
10/13/2023 21:50:38 - INFO -   Epoch: 2/5, Step: 91/143, Lr: 0.000000076-0.000075820, Loss: 0.639902, Time/step: 11.112311
10/13/2023 21:50:49 - INFO -   Epoch: 2/5, Step: 92/143, Lr: 0.000000076-0.000075631, Loss: 0.465843, Time/step: 11.496489
10/13/2023 21:51:00 - INFO -   Epoch: 2/5, Step: 93/143, Lr: 0.000000075-0.000075443, Loss: 0.463267, Time/step: 10.943304
10/13/2023 21:51:12 - INFO -   Epoch: 2/5, Step: 94/143, Lr: 0.000000075-0.000075253, Loss: 0.351260, Time/step: 11.385503
10/13/2023 21:51:23 - INFO -   Epoch: 2/5, Step: 95/143, Lr: 0.000000075-0.000075063, Loss: 0.504310, Time/step: 11.894484
10/13/2023 21:51:35 - INFO -   Epoch: 2/5, Step: 96/143, Lr: 0.000000075-0.000074873, Loss: 0.506016, Time/step: 11.858287
10/13/2023 22:02:38 - INFO -   Epoch: 2/5, Step: 97/143, Lr: 0.000000075-0.000074682, Loss: 0.314443, Time/step: 662.859688
10/13/2023 22:11:53 - INFO -   Epoch: 2/5, Step: 98/143, Lr: 0.000000074-0.000074491, Loss: 0.546289, Time/step: 554.854255
10/13/2023 22:12:05 - INFO -   Epoch: 2/5, Step: 99/143, Lr: 0.000000074-0.000074299, Loss: 0.328883, Time/step: 11.490916
10/13/2023 22:12:17 - INFO -   Epoch: 2/5, Step: 100/143, Lr: 0.000000074-0.000074107, Loss: 0.415702, Time/step: 12.826919
10/13/2023 23:11:53 - INFO -   Epoch: 2/5, Step: 101/143, Lr: 0.000000074-0.000073914, Loss: 0.496553, Time/step: 3575.863643
10/13/2023 23:12:05 - INFO -   Epoch: 2/5, Step: 102/143, Lr: 0.000000074-0.000073721, Loss: 0.340656, Time/step: 11.231251
10/13/2023 23:12:16 - INFO -   Epoch: 2/5, Step: 103/143, Lr: 0.000000074-0.000073527, Loss: 0.252291, Time/step: 11.450773
10/13/2023 23:33:05 - INFO -   Epoch: 2/5, Step: 104/143, Lr: 0.000000073-0.000073333, Loss: 0.533979, Time/step: 1249.021389
10/13/2023 23:33:14 - INFO -   Epoch: 2/5, Step: 105/143, Lr: 0.000000073-0.000073139, Loss: 0.514892, Time/step: 8.897794
10/13/2023 23:33:24 - INFO -   Epoch: 2/5, Step: 106/143, Lr: 0.000000073-0.000072944, Loss: 0.521508, Time/step: 9.558420
10/13/2023 23:33:33 - INFO -   Epoch: 2/5, Step: 107/143, Lr: 0.000000073-0.000072748, Loss: 0.340817, Time/step: 9.258221
10/13/2023 23:33:43 - INFO -   Epoch: 2/5, Step: 108/143, Lr: 0.000000073-0.000072553, Loss: 0.568770, Time/step: 9.683609
10/13/2023 23:33:53 - INFO -   Epoch: 2/5, Step: 109/143, Lr: 0.000000072-0.000072356, Loss: 0.484211, Time/step: 10.846750
10/13/2023 23:34:04 - INFO -   Epoch: 2/5, Step: 110/143, Lr: 0.000000072-0.000072160, Loss: 0.532959, Time/step: 10.715706
10/13/2023 23:34:15 - INFO -   Epoch: 2/5, Step: 111/143, Lr: 0.000000072-0.000071962, Loss: 0.476166, Time/step: 10.799795
10/13/2023 23:34:26 - INFO -   Epoch: 2/5, Step: 112/143, Lr: 0.000000072-0.000071765, Loss: 0.398208, Time/step: 11.027531
10/13/2023 23:48:12 - INFO -   Epoch: 2/5, Step: 113/143, Lr: 0.000000072-0.000071567, Loss: 0.388263, Time/step: 826.075401
10/13/2023 23:48:22 - INFO -   Epoch: 2/5, Step: 114/143, Lr: 0.000000071-0.000071368, Loss: 0.546916, Time/step: 10.384148
10/13/2023 23:48:34 - INFO -   Epoch: 2/5, Step: 115/143, Lr: 0.000000071-0.000071170, Loss: 0.553125, Time/step: 11.665012
10/13/2023 23:48:45 - INFO -   Epoch: 2/5, Step: 116/143, Lr: 0.000000071-0.000070970, Loss: 0.479136, Time/step: 10.599726
10/14/2023 00:24:03 - INFO -   Epoch: 2/5, Step: 117/143, Lr: 0.000000071-0.000070771, Loss: 0.314753, Time/step: 2118.137948
10/14/2023 00:24:11 - INFO -   Epoch: 2/5, Step: 118/143, Lr: 0.000000071-0.000070571, Loss: 0.361999, Time/step: 8.586249
10/14/2023 00:24:20 - INFO -   Epoch: 2/5, Step: 119/143, Lr: 0.000000070-0.000070370, Loss: 0.493091, Time/step: 8.662438
10/14/2023 00:27:57 - INFO -   Epoch: 2/5, Step: 120/143, Lr: 0.000000070-0.000070169, Loss: 0.636493, Time/step: 216.918536
10/14/2023 00:28:06 - INFO -   Epoch: 2/5, Step: 121/143, Lr: 0.000000070-0.000069968, Loss: 0.554755, Time/step: 8.627816
10/14/2023 00:28:15 - INFO -   Epoch: 2/5, Step: 122/143, Lr: 0.000000070-0.000069767, Loss: 0.546926, Time/step: 8.698044
10/14/2023 00:28:23 - INFO -   Epoch: 2/5, Step: 123/143, Lr: 0.000000070-0.000069565, Loss: 0.467266, Time/step: 8.870484
10/14/2023 00:28:32 - INFO -   Epoch: 2/5, Step: 124/143, Lr: 0.000000069-0.000069362, Loss: 0.525460, Time/step: 8.447755
10/14/2023 00:28:40 - INFO -   Epoch: 2/5, Step: 125/143, Lr: 0.000000069-0.000069160, Loss: 0.299926, Time/step: 8.548055
10/14/2023 00:28:49 - INFO -   Epoch: 2/5, Step: 126/143, Lr: 0.000000069-0.000068956, Loss: 0.694514, Time/step: 8.402213
10/14/2023 00:28:58 - INFO -   Epoch: 2/5, Step: 127/143, Lr: 0.000000069-0.000068753, Loss: 0.628255, Time/step: 8.759300
10/14/2023 00:29:06 - INFO -   Epoch: 2/5, Step: 128/143, Lr: 0.000000069-0.000068549, Loss: 0.291124, Time/step: 8.580762
10/14/2023 00:36:24 - INFO -   Epoch: 2/5, Step: 129/143, Lr: 0.000000068-0.000068345, Loss: 0.593937, Time/step: 438.338076
10/14/2023 00:43:06 - INFO -   Epoch: 2/5, Step: 130/143, Lr: 0.000000068-0.000068140, Loss: 0.411306, Time/step: 401.663100
10/14/2023 00:47:59 - INFO -   Epoch: 2/5, Step: 131/143, Lr: 0.000000068-0.000067935, Loss: 0.309834, Time/step: 293.077497
10/14/2023 00:48:02 - INFO -   Epoch: 2/5, Step: 132/143, Lr: 0.000000068-0.000067730, Loss: 0.732424, Time/step: 3.131460
10/14/2023 00:54:26 - INFO -   Epoch: 2/5, Step: 133/143, Lr: 0.000000068-0.000067525, Loss: 0.635877, Time/step: 383.387914
10/14/2023 00:54:27 - INFO -   Epoch: 2/5, Step: 134/143, Lr: 0.000000067-0.000067319, Loss: 0.496117, Time/step: 1.440516
10/14/2023 00:54:29 - INFO -   Epoch: 2/5, Step: 135/143, Lr: 0.000000067-0.000067112, Loss: 0.295682, Time/step: 1.461599
10/14/2023 00:54:30 - INFO -   Epoch: 2/5, Step: 136/143, Lr: 0.000000067-0.000066906, Loss: 0.262250, Time/step: 1.421283
10/14/2023 00:54:32 - INFO -   Epoch: 2/5, Step: 137/143, Lr: 0.000000067-0.000066699, Loss: 0.514924, Time/step: 1.431067
10/14/2023 00:54:33 - INFO -   Epoch: 2/5, Step: 138/143, Lr: 0.000000066-0.000066492, Loss: 0.926955, Time/step: 1.476698
10/14/2023 00:54:35 - INFO -   Epoch: 2/5, Step: 139/143, Lr: 0.000000066-0.000066284, Loss: 0.782550, Time/step: 1.416743
10/14/2023 00:54:52 - INFO -   Epoch: 2/5, Step: 140/143, Lr: 0.000000066-0.000066076, Loss: 0.885603, Time/step: 17.952971
10/14/2023 00:54:54 - INFO -   Epoch: 2/5, Step: 141/143, Lr: 0.000000066-0.000065868, Loss: 0.724208, Time/step: 1.090771
10/14/2023 00:54:55 - INFO -   Epoch: 2/5, Step: 142/143, Lr: 0.000000066-0.000065660, Loss: 0.582113, Time/step: 1.057034
10/14/2023 00:54:56 - INFO -   Epoch: 2/5, Step: 143/143, Lr: 0.000000065-0.000065451, Loss: 0.864878, Time/step: 1.078700
10/14/2023 00:54:58 - INFO -   Epoch 2/5 Finished, Train Loss: 0.443189
10/14/2023 00:55:13 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_model.bin.1
10/14/2023 00:55:13 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_opt.bin.1
10/14/2023 00:55:13 - INFO -   Eval on val dataset
10/14/2023 02:36:59 - INFO -   sim matrix size: 184, 184
10/14/2023 02:36:59 - INFO -   	 Length-T: 184, Length-V:184
10/14/2023 02:36:59 - INFO -   Text-to-Video:
10/14/2023 02:36:59 - INFO -   	>>>  R@1: 54.3 - R@5: 83.2 - R@10: 87.5 - Median R: 1.0 - Mean R: 5.5
10/14/2023 02:36:59 - INFO -   Video-to-Text:
10/14/2023 02:36:59 - INFO -   	>>>  V2T$R@1: 58.7 - V2T$R@5: 83.2 - V2T$R@10: 90.2 - V2T$Median R: 1.0 - V2T$Mean R: 5.8
10/14/2023 02:36:59 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue/pytorch_model.bin.0, the R1 is: 58.6957
10/14/2023 03:28:47 - INFO -   Epoch: 3/5, Step: 1/143, Lr: 0.000000065-0.000065242, Loss: 0.316572, Time/step: 3106.825261
10/14/2023 03:28:54 - INFO -   Epoch: 3/5, Step: 2/143, Lr: 0.000000065-0.000065032, Loss: 0.352371, Time/step: 7.221360
10/14/2023 03:29:01 - INFO -   Epoch: 3/5, Step: 3/143, Lr: 0.000000065-0.000064823, Loss: 0.183141, Time/step: 7.121906
10/14/2023 03:31:40 - INFO -   Epoch: 3/5, Step: 4/143, Lr: 0.000000065-0.000064613, Loss: 0.342384, Time/step: 158.409227
10/14/2023 03:31:48 - INFO -   Epoch: 3/5, Step: 5/143, Lr: 0.000000064-0.000064403, Loss: 0.136214, Time/step: 7.994828
10/14/2023 03:31:56 - INFO -   Epoch: 3/5, Step: 6/143, Lr: 0.000000064-0.000064192, Loss: 0.273421, Time/step: 8.144475
10/14/2023 03:32:05 - INFO -   Epoch: 3/5, Step: 7/143, Lr: 0.000000064-0.000063981, Loss: 0.207028, Time/step: 8.684158
10/14/2023 03:47:36 - INFO -   Epoch: 3/5, Step: 8/143, Lr: 0.000000064-0.000063770, Loss: 0.219900, Time/step: 931.097757
10/14/2023 03:47:45 - INFO -   Epoch: 3/5, Step: 9/143, Lr: 0.000000064-0.000063559, Loss: 0.211502, Time/step: 8.976939
10/14/2023 03:47:55 - INFO -   Epoch: 3/5, Step: 10/143, Lr: 0.000000063-0.000063347, Loss: 0.357758, Time/step: 9.824914
10/14/2023 03:48:05 - INFO -   Epoch: 3/5, Step: 11/143, Lr: 0.000000063-0.000063135, Loss: 0.233268, Time/step: 10.011255
10/14/2023 03:48:15 - INFO -   Epoch: 3/5, Step: 12/143, Lr: 0.000000063-0.000062923, Loss: 0.138821, Time/step: 10.480653
10/14/2023 03:48:25 - INFO -   Epoch: 3/5, Step: 13/143, Lr: 0.000000063-0.000062711, Loss: 0.135808, Time/step: 10.418962
10/14/2023 03:48:36 - INFO -   Epoch: 3/5, Step: 14/143, Lr: 0.000000062-0.000062498, Loss: 0.347199, Time/step: 10.850529
10/14/2023 03:48:48 - INFO -   Epoch: 3/5, Step: 15/143, Lr: 0.000000062-0.000062285, Loss: 0.269163, Time/step: 11.304203
10/14/2023 03:49:00 - INFO -   Epoch: 3/5, Step: 16/143, Lr: 0.000000062-0.000062072, Loss: 0.258970, Time/step: 12.141497
10/14/2023 04:50:40 - INFO -   Epoch: 3/5, Step: 17/143, Lr: 0.000000062-0.000061859, Loss: 0.308846, Time/step: 3699.974749
10/14/2023 04:50:52 - INFO -   Epoch: 3/5, Step: 18/143, Lr: 0.000000062-0.000061646, Loss: 0.285763, Time/step: 12.528689
10/14/2023 04:51:04 - INFO -   Epoch: 3/5, Step: 19/143, Lr: 0.000000061-0.000061432, Loss: 0.298586, Time/step: 11.134484
10/14/2023 05:12:02 - INFO -   Epoch: 3/5, Step: 20/143, Lr: 0.000000061-0.000061218, Loss: 0.224117, Time/step: 1258.097147
10/14/2023 05:12:12 - INFO -   Epoch: 3/5, Step: 21/143, Lr: 0.000000061-0.000061004, Loss: 0.186558, Time/step: 9.775399
10/14/2023 05:12:22 - INFO -   Epoch: 3/5, Step: 22/143, Lr: 0.000000061-0.000060789, Loss: 0.182868, Time/step: 10.452842
10/14/2023 05:12:32 - INFO -   Epoch: 3/5, Step: 23/143, Lr: 0.000000061-0.000060575, Loss: 0.268460, Time/step: 10.442840
10/14/2023 05:23:52 - INFO -   Epoch: 3/5, Step: 24/143, Lr: 0.000000060-0.000060360, Loss: 0.173605, Time/step: 679.251836
10/14/2023 05:24:02 - INFO -   Epoch: 3/5, Step: 25/143, Lr: 0.000000060-0.000060145, Loss: 0.245040, Time/step: 9.976962
10/14/2023 05:24:12 - INFO -   Epoch: 3/5, Step: 26/143, Lr: 0.000000060-0.000059930, Loss: 0.286942, Time/step: 9.896572
10/14/2023 05:24:22 - INFO -   Epoch: 3/5, Step: 27/143, Lr: 0.000000060-0.000059714, Loss: 0.198137, Time/step: 10.199055
10/14/2023 05:24:32 - INFO -   Epoch: 3/5, Step: 28/143, Lr: 0.000000059-0.000059499, Loss: 0.207946, Time/step: 10.325763
10/14/2023 05:24:43 - INFO -   Epoch: 3/5, Step: 29/143, Lr: 0.000000059-0.000059283, Loss: 0.223274, Time/step: 10.791907
10/14/2023 05:24:54 - INFO -   Epoch: 3/5, Step: 30/143, Lr: 0.000000059-0.000059067, Loss: 0.297849, Time/step: 10.710778
10/14/2023 05:25:05 - INFO -   Epoch: 3/5, Step: 31/143, Lr: 0.000000059-0.000058851, Loss: 0.249888, Time/step: 11.571001
10/14/2023 05:25:17 - INFO -   Epoch: 3/5, Step: 32/143, Lr: 0.000000059-0.000058634, Loss: 0.197053, Time/step: 11.682156
10/14/2023 06:45:16 - INFO -   Epoch: 3/5, Step: 33/143, Lr: 0.000000058-0.000058418, Loss: 0.217928, Time/step: 4799.185393
10/14/2023 06:45:24 - INFO -   Epoch: 3/5, Step: 34/143, Lr: 0.000000058-0.000058201, Loss: 0.270036, Time/step: 7.906753
10/14/2023 06:45:33 - INFO -   Epoch: 3/5, Step: 35/143, Lr: 0.000000058-0.000057984, Loss: 0.140177, Time/step: 8.587630
10/14/2023 06:49:41 - INFO -   Epoch: 3/5, Step: 36/143, Lr: 0.000000058-0.000057767, Loss: 0.294527, Time/step: 248.081235
10/14/2023 06:49:49 - INFO -   Epoch: 3/5, Step: 37/143, Lr: 0.000000058-0.000057550, Loss: 0.158656, Time/step: 8.379080
10/14/2023 06:49:58 - INFO -   Epoch: 3/5, Step: 38/143, Lr: 0.000000057-0.000057333, Loss: 0.297468, Time/step: 9.104602
10/14/2023 06:50:08 - INFO -   Epoch: 3/5, Step: 39/143, Lr: 0.000000057-0.000057116, Loss: 0.222342, Time/step: 9.316741
10/14/2023 06:55:38 - INFO -   Epoch: 3/5, Step: 40/143, Lr: 0.000000057-0.000056898, Loss: 0.181151, Time/step: 330.809920
10/14/2023 06:55:48 - INFO -   Epoch: 3/5, Step: 41/143, Lr: 0.000000057-0.000056681, Loss: 0.152913, Time/step: 9.778986
10/14/2023 06:55:58 - INFO -   Epoch: 3/5, Step: 42/143, Lr: 0.000000056-0.000056463, Loss: 0.280191, Time/step: 10.180557
10/14/2023 06:56:09 - INFO -   Epoch: 3/5, Step: 43/143, Lr: 0.000000056-0.000056245, Loss: 0.256346, Time/step: 10.118711
10/14/2023 06:56:19 - INFO -   Epoch: 3/5, Step: 44/143, Lr: 0.000000056-0.000056027, Loss: 0.252512, Time/step: 10.344861
10/14/2023 06:56:30 - INFO -   Epoch: 3/5, Step: 45/143, Lr: 0.000000056-0.000055809, Loss: 0.312861, Time/step: 10.998061
10/14/2023 06:56:41 - INFO -   Epoch: 3/5, Step: 46/143, Lr: 0.000000056-0.000055590, Loss: 0.395404, Time/step: 10.725422
10/14/2023 06:56:53 - INFO -   Epoch: 3/5, Step: 47/143, Lr: 0.000000055-0.000055372, Loss: 0.445192, Time/step: 12.249421
10/14/2023 06:57:04 - INFO -   Epoch: 3/5, Step: 48/143, Lr: 0.000000055-0.000055154, Loss: 0.118834, Time/step: 11.213798
10/14/2023 08:32:31 - INFO -   Epoch: 3/5, Step: 49/143, Lr: 0.000000055-0.000054935, Loss: 0.219351, Time/step: 5726.370730
10/14/2023 08:32:38 - INFO -   Epoch: 3/5, Step: 50/143, Lr: 0.000000055-0.000054716, Loss: 0.265310, Time/step: 7.650757
10/14/2023 08:32:46 - INFO -   Epoch: 3/5, Step: 51/143, Lr: 0.000000054-0.000054498, Loss: 0.167600, Time/step: 7.608154
10/14/2023 08:32:53 - INFO -   Epoch: 3/5, Step: 52/143, Lr: 0.000000054-0.000054279, Loss: 0.153635, Time/step: 7.679984
10/14/2023 08:33:02 - INFO -   Epoch: 3/5, Step: 53/143, Lr: 0.000000054-0.000054060, Loss: 0.185199, Time/step: 8.612351
10/14/2023 08:33:11 - INFO -   Epoch: 3/5, Step: 54/143, Lr: 0.000000054-0.000053841, Loss: 0.339144, Time/step: 9.012340
10/14/2023 08:33:20 - INFO -   Epoch: 3/5, Step: 55/143, Lr: 0.000000054-0.000053622, Loss: 0.240541, Time/step: 9.277309
10/14/2023 08:33:30 - INFO -   Epoch: 3/5, Step: 56/143, Lr: 0.000000053-0.000053403, Loss: 0.215603, Time/step: 9.617304
10/14/2023 08:33:40 - INFO -   Epoch: 3/5, Step: 57/143, Lr: 0.000000053-0.000053183, Loss: 0.306478, Time/step: 9.727196
10/14/2023 08:33:49 - INFO -   Epoch: 3/5, Step: 58/143, Lr: 0.000000053-0.000052964, Loss: 0.315233, Time/step: 9.432211
10/14/2023 08:33:59 - INFO -   Epoch: 3/5, Step: 59/143, Lr: 0.000000053-0.000052745, Loss: 0.190899, Time/step: 9.805179
10/14/2023 08:34:09 - INFO -   Epoch: 3/5, Step: 60/143, Lr: 0.000000053-0.000052525, Loss: 0.313630, Time/step: 9.735180
10/14/2023 08:34:20 - INFO -   Epoch: 3/5, Step: 61/143, Lr: 0.000000052-0.000052306, Loss: 0.118032, Time/step: 11.350129
10/14/2023 08:34:31 - INFO -   Epoch: 3/5, Step: 62/143, Lr: 0.000000052-0.000052086, Loss: 0.198095, Time/step: 11.409424
10/14/2023 08:34:42 - INFO -   Epoch: 3/5, Step: 63/143, Lr: 0.000000052-0.000051867, Loss: 0.325973, Time/step: 10.712996
10/14/2023 08:34:55 - INFO -   Epoch: 3/5, Step: 64/143, Lr: 0.000000052-0.000051647, Loss: 0.116927, Time/step: 12.519077
[ERROR:0@130188.453] global cap.cpp:164 open VIDEOIO(CV_IMAGES): raised OpenCV exception:

OpenCV(4.7.0) /io/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): /home/wiss/zhang/nfs/Anet-compressed/v_-K_cgWfJxiU.mkv in function 'icvExtractPattern'


10/14/2023 09:56:08 - INFO -   Epoch: 3/5, Step: 65/143, Lr: 0.000000051-0.000051428, Loss: 0.338461, Time/step: 4873.001431
10/14/2023 09:56:18 - INFO -   Epoch: 3/5, Step: 66/143, Lr: 0.000000051-0.000051208, Loss: 0.182662, Time/step: 10.172029
10/14/2023 09:56:29 - INFO -   Epoch: 3/5, Step: 67/143, Lr: 0.000000051-0.000050989, Loss: 0.344169, Time/step: 10.450665
10/14/2023 09:56:39 - INFO -   Epoch: 3/5, Step: 68/143, Lr: 0.000000051-0.000050769, Loss: 0.105550, Time/step: 10.370077
10/14/2023 09:56:49 - INFO -   Epoch: 3/5, Step: 69/143, Lr: 0.000000051-0.000050549, Loss: 0.349565, Time/step: 9.951618
10/14/2023 09:57:00 - INFO -   Epoch: 3/5, Step: 70/143, Lr: 0.000000050-0.000050330, Loss: 0.334696, Time/step: 11.221612
10/14/2023 09:57:12 - INFO -   Epoch: 3/5, Step: 71/143, Lr: 0.000000050-0.000050110, Loss: 0.239930, Time/step: 11.711744
10/14/2023 09:57:24 - INFO -   Epoch: 3/5, Step: 72/143, Lr: 0.000000050-0.000049890, Loss: 0.246454, Time/step: 11.724832
10/14/2023 09:57:35 - INFO -   Epoch: 3/5, Step: 73/143, Lr: 0.000000050-0.000049670, Loss: 0.313766, Time/step: 11.486435
10/14/2023 09:57:47 - INFO -   Epoch: 3/5, Step: 74/143, Lr: 0.000000049-0.000049451, Loss: 0.250055, Time/step: 12.157065
10/14/2023 09:57:59 - INFO -   Epoch: 3/5, Step: 75/143, Lr: 0.000000049-0.000049231, Loss: 0.330232, Time/step: 11.869204
10/14/2023 09:58:12 - INFO -   Epoch: 3/5, Step: 76/143, Lr: 0.000000049-0.000049011, Loss: 0.295002, Time/step: 12.521091
10/14/2023 09:58:24 - INFO -   Epoch: 3/5, Step: 77/143, Lr: 0.000000049-0.000048792, Loss: 0.199748, Time/step: 12.037460
10/14/2023 09:58:36 - INFO -   Epoch: 3/5, Step: 78/143, Lr: 0.000000049-0.000048572, Loss: 0.211056, Time/step: 12.617539
10/14/2023 09:58:50 - INFO -   Epoch: 3/5, Step: 79/143, Lr: 0.000000048-0.000048353, Loss: 0.383429, Time/step: 13.160550
10/14/2023 09:59:02 - INFO -   Epoch: 3/5, Step: 80/143, Lr: 0.000000048-0.000048133, Loss: 0.269336, Time/step: 12.686270
10/14/2023 11:25:11 - INFO -   Epoch: 3/5, Step: 81/143, Lr: 0.000000048-0.000047914, Loss: 0.161779, Time/step: 5168.997510
10/14/2023 11:25:23 - INFO -   Epoch: 3/5, Step: 82/143, Lr: 0.000000048-0.000047694, Loss: 0.176812, Time/step: 12.123282
Traceback (most recent call last):
  File "main_xclip.py", line 555, in <module>
    ## ##############################################################
  File "main_xclip.py", line 529, in main
    logger.info("  Batch size = %d", args.batch_size_val)
  File "main_xclip.py", line 267, in train_epoch
    for step, batch in enumerate(train_dataloader):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1065, in _next_data
    return self._process_data(data)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 2.
Original Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 188, in __getitem__
    video, video_mask = self._get_rawvideo(choice_video_ids)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 179, in _get_rawvideo
    raise excep
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 149, in _get_rawvideo
    raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 85, in get_video_data
    image_input = self.video_to_tensor(video_path, self.transform, sample_fp=self.framerate, start_time=start_time, end_time=end_time)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 45, in video_to_tensor
    total_duration = (frameCount + fps - 1) // fps
ZeroDivisionError: integer division or modulo by zero

Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 255, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/home/wiss/zhang/anaconda3/envs/clip4clip/bin/python', '-u', 'main_xclip.py', '--local_rank=1', '--do_train', '--num_thread_reader=16', '--epochs=5', '--batch_size=64', '--n_display=1', '--data_path', '/home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/', '--features_path', '/home/wiss/zhang/nfs/Anet-compressed', '--output_dir', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42_continue', '--lr', '1e-4', '--max_words', '60', '--max_frames', '12', '--batch_size_val', '64', '--datatype', 'moviegraph', '--feature_framerate', '1', '--coef_lr', '1e-3', '--freeze_layer_num', '0', '--slice_framepos', '2', '--loose_type', '--linear_patch', '2d', '--sim_header', 'seqTransf', '--pretrained_clip_name', 'ViT-B/32', '--init_model', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.1', '--manipulation', 'anet_train1_seed42', '--scale', '0', '--dataset_ckpt', 'anet_train1_seed42', '--train_file', 'train_1.csv', '--val_file', 'temporal_contact_swap.csv', '--test_file', 'temporal_contact_swap.csv', '--seed', '42']' returned non-zero exit status 1.
