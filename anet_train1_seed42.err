10/09/2023 17:03:48 - INFO -   Effective parameters:
10/09/2023 17:03:48 - INFO -     <<< batch_size: 64
10/09/2023 17:03:48 - INFO -     <<< batch_size_val: 64
10/09/2023 17:03:48 - INFO -     <<< cache_dir: 
10/09/2023 17:03:48 - INFO -     <<< coef_lr: 0.001
10/09/2023 17:03:48 - INFO -     <<< cross_model: cross-base
10/09/2023 17:03:48 - INFO -     <<< cross_num_hidden_layers: 4
10/09/2023 17:03:48 - INFO -     <<< data_path: /home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/
10/09/2023 17:03:48 - INFO -     <<< dataset_ckpt: anet_train1_seed42
10/09/2023 17:03:48 - INFO -     <<< datatype: moviegraph
10/09/2023 17:03:48 - INFO -     <<< do_eval: False
10/09/2023 17:03:48 - INFO -     <<< do_lower_case: False
10/09/2023 17:03:48 - INFO -     <<< do_pretrain: False
10/09/2023 17:03:48 - INFO -     <<< do_train: True
10/09/2023 17:03:48 - INFO -     <<< epochs: 10
10/09/2023 17:03:48 - INFO -     <<< eval_frame_order: 0
10/09/2023 17:03:48 - INFO -     <<< expand_msrvtt_sentences: False
10/09/2023 17:03:48 - INFO -     <<< feature_framerate: 1
10/09/2023 17:03:48 - INFO -     <<< features_path: /home/wiss/zhang/nfs/Anet-compressed
10/09/2023 17:03:48 - INFO -     <<< fp16: False
10/09/2023 17:03:48 - INFO -     <<< fp16_opt_level: O1
10/09/2023 17:03:48 - INFO -     <<< freeze_layer_num: 0
10/09/2023 17:03:48 - INFO -     <<< gradient_accumulation_steps: 1
10/09/2023 17:03:48 - INFO -     <<< hard_negative_rate: 0.5
10/09/2023 17:03:48 - INFO -     <<< init_model: None
10/09/2023 17:03:48 - INFO -     <<< linear_patch: 2d
10/09/2023 17:03:48 - INFO -     <<< local_rank: 0
10/09/2023 17:03:48 - INFO -     <<< loose_type: True
10/09/2023 17:03:48 - INFO -     <<< lr: 0.0001
10/09/2023 17:03:48 - INFO -     <<< lr_decay: 0.9
10/09/2023 17:03:48 - INFO -     <<< manipulation: anet_train1_seed42
10/09/2023 17:03:48 - INFO -     <<< margin: 0.1
10/09/2023 17:03:48 - INFO -     <<< max_frames: 12
10/09/2023 17:03:48 - INFO -     <<< max_words: 60
10/09/2023 17:03:48 - INFO -     <<< n_display: 1
10/09/2023 17:03:48 - INFO -     <<< n_gpu: 1
10/09/2023 17:03:48 - INFO -     <<< n_pair: 1
10/09/2023 17:03:48 - INFO -     <<< negative_weighting: 1
10/09/2023 17:03:48 - INFO -     <<< num_thread_reader: 16
10/09/2023 17:03:48 - INFO -     <<< output_dir: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42
10/09/2023 17:03:48 - INFO -     <<< pretrained_clip_name: ViT-B/32
10/09/2023 17:03:48 - INFO -     <<< rank: 0
10/09/2023 17:03:48 - INFO -     <<< resume_model: None
10/09/2023 17:03:48 - INFO -     <<< sampled_use_mil: False
10/09/2023 17:03:48 - INFO -     <<< scale: 0
10/09/2023 17:03:48 - INFO -     <<< seed: 42
10/09/2023 17:03:48 - INFO -     <<< sim_header: seqTransf
10/09/2023 17:03:48 - INFO -     <<< slice_framepos: 2
10/09/2023 17:03:48 - INFO -     <<< task_type: retrieval
10/09/2023 17:03:48 - INFO -     <<< test_file: temporal_contact_swap.csv
10/09/2023 17:03:48 - INFO -     <<< text_num_hidden_layers: 12
10/09/2023 17:03:48 - INFO -     <<< train_csv: data/.train.csv
10/09/2023 17:03:48 - INFO -     <<< train_file: train_1.csv
10/09/2023 17:03:48 - INFO -     <<< train_frame_order: 0
10/09/2023 17:03:48 - INFO -     <<< use_mil: False
10/09/2023 17:03:48 - INFO -     <<< val_csv: data/.val.csv
10/09/2023 17:03:48 - INFO -     <<< val_file: temporal_contact_swap.csv
10/09/2023 17:03:48 - INFO -     <<< video_dim: 1024
10/09/2023 17:03:48 - INFO -     <<< visual_num_hidden_layers: 12
10/09/2023 17:03:48 - INFO -     <<< warmup_proportion: 0.1
10/09/2023 17:03:48 - INFO -     <<< world_size: 2
10/09/2023 17:03:48 - INFO -   device: cuda:0 n_gpu: 2
10/09/2023 17:03:48 - INFO -   device: cuda:1 n_gpu: 2
10/09/2023 17:03:50 - INFO -   loading archive file /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base
10/09/2023 17:03:50 - INFO -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

10/09/2023 17:03:50 - INFO -   Weight doesn't exsits. /home/wiss/zhang/Jinhe/X-CLIP/modules/cross-base/cross_pytorch_model.bin
10/09/2023 17:03:50 - WARNING -   Stage-One:True, Stage-Two:False
10/09/2023 17:03:50 - WARNING -   Test retrieval by loose type.
10/09/2023 17:03:50 - WARNING -   	 embed_dim: 512
10/09/2023 17:03:50 - WARNING -   	 image_resolution: 224
10/09/2023 17:03:50 - WARNING -   	 vision_layers: 12
10/09/2023 17:03:50 - WARNING -   	 vision_width: 768
10/09/2023 17:03:50 - WARNING -   	 vision_patch_size: 32
10/09/2023 17:03:50 - WARNING -   	 context_length: 77
10/09/2023 17:03:50 - WARNING -   	 vocab_size: 49408
10/09/2023 17:03:50 - WARNING -   	 transformer_width: 512
10/09/2023 17:03:50 - WARNING -   	 transformer_heads: 8
10/09/2023 17:03:50 - WARNING -   	 transformer_layers: 12
10/09/2023 17:03:50 - WARNING -   		 linear_patch: 2d
10/09/2023 17:03:50 - WARNING -   	 cut_top_layer: 0
10/09/2023 17:03:55 - WARNING -   	 sim_header: seqTransf
10/09/2023 17:04:14 - INFO -   --------------------
10/09/2023 17:04:14 - INFO -   Weights of XCLIP not initialized from pretrained model: 
   global_mat_weight
   word_logit_weight
   frame_logit_weight
   local_mat_weight
   frame_mat_weight
   word_mat_weight
   frame_mat_weight2
   word_mat_weight2
10/09/2023 17:04:14 - INFO -   Weights from pretrained model not used in XCLIP: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
10/09/2023 17:04:15 - INFO -   ***** Running test *****
10/09/2023 17:04:15 - INFO -     Num examples = 184
10/09/2023 17:04:15 - INFO -     Batch size = 64
10/09/2023 17:04:15 - INFO -     Num steps = 3
10/09/2023 17:04:15 - INFO -   ***** Running val *****
10/09/2023 17:04:15 - INFO -     Num examples = 184
10/09/2023 17:04:23 - INFO -   ***** Running training *****
10/09/2023 17:04:23 - INFO -     Num examples = 9155
10/09/2023 17:04:23 - INFO -     Batch size = 64
10/09/2023 17:04:23 - INFO -     Num steps = 1430
10/09/2023 18:55:51 - INFO -   Epoch: 1/10, Step: 1/143, Lr: 0.000000001-0.000000699, Loss: 2.706127, Time/step: 6687.767107
10/09/2023 19:06:30 - INFO -   Epoch: 1/10, Step: 2/143, Lr: 0.000000001-0.000001399, Loss: 2.696066, Time/step: 638.555625
10/09/2023 19:06:46 - INFO -   Epoch: 1/10, Step: 3/143, Lr: 0.000000002-0.000002098, Loss: 2.610188, Time/step: 15.994025
10/09/2023 19:07:01 - INFO -   Epoch: 1/10, Step: 4/143, Lr: 0.000000003-0.000002797, Loss: 2.719953, Time/step: 14.787131
10/09/2023 19:37:54 - INFO -   Epoch: 1/10, Step: 5/143, Lr: 0.000000003-0.000003497, Loss: 3.229115, Time/step: 1853.277239
10/09/2023 19:38:09 - INFO -   Epoch: 1/10, Step: 6/143, Lr: 0.000000004-0.000004196, Loss: 2.615895, Time/step: 15.213117
10/09/2023 19:38:24 - INFO -   Epoch: 1/10, Step: 7/143, Lr: 0.000000005-0.000004895, Loss: 2.576956, Time/step: 14.944632
10/09/2023 19:38:39 - INFO -   Epoch: 1/10, Step: 8/143, Lr: 0.000000006-0.000005594, Loss: 2.345651, Time/step: 14.937707
10/09/2023 19:38:54 - INFO -   Epoch: 1/10, Step: 9/143, Lr: 0.000000006-0.000006294, Loss: 3.278685, Time/step: 14.475985
10/09/2023 19:39:08 - INFO -   Epoch: 1/10, Step: 10/143, Lr: 0.000000007-0.000006993, Loss: 3.089949, Time/step: 14.904095
10/09/2023 19:39:24 - INFO -   Epoch: 1/10, Step: 11/143, Lr: 0.000000008-0.000007692, Loss: 3.332125, Time/step: 15.069246
10/09/2023 19:39:39 - INFO -   Epoch: 1/10, Step: 12/143, Lr: 0.000000008-0.000008392, Loss: 2.909682, Time/step: 14.994013
10/09/2023 19:39:54 - INFO -   Epoch: 1/10, Step: 13/143, Lr: 0.000000009-0.000009091, Loss: 3.284359, Time/step: 15.589557
10/09/2023 19:40:09 - INFO -   Epoch: 1/10, Step: 14/143, Lr: 0.000000010-0.000009790, Loss: 2.897702, Time/step: 14.577912
10/09/2023 19:40:24 - INFO -   Epoch: 1/10, Step: 15/143, Lr: 0.000000010-0.000010490, Loss: 2.275041, Time/step: 15.027282
10/09/2023 19:40:40 - INFO -   Epoch: 1/10, Step: 16/143, Lr: 0.000000011-0.000011189, Loss: 2.351685, Time/step: 15.751166
10/09/2023 21:24:03 - INFO -   Epoch: 1/10, Step: 17/143, Lr: 0.000000012-0.000011888, Loss: 2.423211, Time/step: 6203.571909
10/09/2023 21:25:43 - INFO -   Epoch: 1/10, Step: 18/143, Lr: 0.000000013-0.000012587, Loss: 2.298812, Time/step: 99.602256
10/09/2023 21:26:01 - INFO -   Epoch: 1/10, Step: 19/143, Lr: 0.000000013-0.000013287, Loss: 2.454785, Time/step: 17.771223
10/09/2023 21:26:16 - INFO -   Epoch: 1/10, Step: 20/143, Lr: 0.000000014-0.000013986, Loss: 2.486195, Time/step: 14.900544
10/09/2023 21:33:43 - INFO -   Epoch: 1/10, Step: 21/143, Lr: 0.000000015-0.000014685, Loss: 2.686073, Time/step: 446.868048
10/09/2023 21:33:58 - INFO -   Epoch: 1/10, Step: 22/143, Lr: 0.000000015-0.000015385, Loss: 2.219178, Time/step: 14.874133
10/09/2023 21:34:12 - INFO -   Epoch: 1/10, Step: 23/143, Lr: 0.000000016-0.000016084, Loss: 2.213518, Time/step: 14.134161
10/09/2023 21:34:27 - INFO -   Epoch: 1/10, Step: 24/143, Lr: 0.000000017-0.000016783, Loss: 2.923272, Time/step: 14.882394
10/09/2023 21:34:41 - INFO -   Epoch: 1/10, Step: 25/143, Lr: 0.000000017-0.000017483, Loss: 2.496621, Time/step: 14.286312
10/09/2023 21:34:56 - INFO -   Epoch: 1/10, Step: 26/143, Lr: 0.000000018-0.000018182, Loss: 2.395959, Time/step: 14.717297
10/09/2023 21:35:10 - INFO -   Epoch: 1/10, Step: 27/143, Lr: 0.000000019-0.000018881, Loss: 2.119127, Time/step: 14.514283
10/09/2023 21:41:51 - INFO -   Epoch: 1/10, Step: 28/143, Lr: 0.000000020-0.000019580, Loss: 2.497346, Time/step: 400.891020
10/09/2023 21:42:06 - INFO -   Epoch: 1/10, Step: 29/143, Lr: 0.000000020-0.000020280, Loss: 2.404909, Time/step: 14.512818
10/09/2023 21:42:21 - INFO -   Epoch: 1/10, Step: 30/143, Lr: 0.000000021-0.000020979, Loss: 2.098561, Time/step: 14.758005
10/09/2023 21:42:35 - INFO -   Epoch: 1/10, Step: 31/143, Lr: 0.000000022-0.000021678, Loss: 2.839521, Time/step: 14.227581
10/09/2023 21:42:50 - INFO -   Epoch: 1/10, Step: 32/143, Lr: 0.000000022-0.000022378, Loss: 2.603140, Time/step: 15.106638
10/09/2023 23:56:14 - INFO -   Epoch: 1/10, Step: 33/143, Lr: 0.000000023-0.000023077, Loss: 2.229789, Time/step: 8003.605282
10/09/2023 23:56:28 - INFO -   Epoch: 1/10, Step: 34/143, Lr: 0.000000024-0.000023776, Loss: 2.423597, Time/step: 14.281299
10/09/2023 23:56:42 - INFO -   Epoch: 1/10, Step: 35/143, Lr: 0.000000024-0.000024476, Loss: 2.027051, Time/step: 13.853353
10/09/2023 23:56:56 - INFO -   Epoch: 1/10, Step: 36/143, Lr: 0.000000025-0.000025175, Loss: 2.413609, Time/step: 13.911754
10/09/2023 23:57:10 - INFO -   Epoch: 1/10, Step: 37/143, Lr: 0.000000026-0.000025874, Loss: 2.344881, Time/step: 14.067383
10/09/2023 23:57:24 - INFO -   Epoch: 1/10, Step: 38/143, Lr: 0.000000027-0.000026573, Loss: 2.188488, Time/step: 14.024319
10/09/2023 23:57:38 - INFO -   Epoch: 1/10, Step: 39/143, Lr: 0.000000027-0.000027273, Loss: 2.466363, Time/step: 14.292871
10/09/2023 23:57:52 - INFO -   Epoch: 1/10, Step: 40/143, Lr: 0.000000028-0.000027972, Loss: 2.525997, Time/step: 13.225668
10/09/2023 23:58:06 - INFO -   Epoch: 1/10, Step: 41/143, Lr: 0.000000029-0.000028671, Loss: 2.378575, Time/step: 13.940117
10/09/2023 23:58:19 - INFO -   Epoch: 1/10, Step: 42/143, Lr: 0.000000029-0.000029371, Loss: 1.940331, Time/step: 13.480224
10/09/2023 23:58:33 - INFO -   Epoch: 1/10, Step: 43/143, Lr: 0.000000030-0.000030070, Loss: 1.799477, Time/step: 14.210269
10/09/2023 23:58:47 - INFO -   Epoch: 1/10, Step: 44/143, Lr: 0.000000031-0.000030769, Loss: 2.769435, Time/step: 14.200346
10/09/2023 23:59:01 - INFO -   Epoch: 1/10, Step: 45/143, Lr: 0.000000031-0.000031469, Loss: 1.718756, Time/step: 13.939100
10/09/2023 23:59:16 - INFO -   Epoch: 1/10, Step: 46/143, Lr: 0.000000032-0.000032168, Loss: 2.662946, Time/step: 14.452202
10/09/2023 23:59:31 - INFO -   Epoch: 1/10, Step: 47/143, Lr: 0.000000033-0.000032867, Loss: 1.809707, Time/step: 14.850012
10/09/2023 23:59:46 - INFO -   Epoch: 1/10, Step: 48/143, Lr: 0.000000034-0.000033566, Loss: 2.138808, Time/step: 15.279646
10/10/2023 02:07:20 - INFO -   Epoch: 1/10, Step: 49/143, Lr: 0.000000034-0.000034266, Loss: 2.462283, Time/step: 7654.308025
10/10/2023 02:07:33 - INFO -   Epoch: 1/10, Step: 50/143, Lr: 0.000000035-0.000034965, Loss: 2.210635, Time/step: 12.185434
10/10/2023 02:07:45 - INFO -   Epoch: 1/10, Step: 51/143, Lr: 0.000000036-0.000035664, Loss: 2.216660, Time/step: 12.439395
10/10/2023 02:07:57 - INFO -   Epoch: 1/10, Step: 52/143, Lr: 0.000000036-0.000036364, Loss: 2.355560, Time/step: 12.227455
10/10/2023 02:08:09 - INFO -   Epoch: 1/10, Step: 53/143, Lr: 0.000000037-0.000037063, Loss: 2.099043, Time/step: 12.220705
10/10/2023 02:08:22 - INFO -   Epoch: 1/10, Step: 54/143, Lr: 0.000000038-0.000037762, Loss: 2.028983, Time/step: 12.233057
10/10/2023 02:08:34 - INFO -   Epoch: 1/10, Step: 55/143, Lr: 0.000000038-0.000038462, Loss: 2.019229, Time/step: 12.210920
10/10/2023 02:08:48 - INFO -   Epoch: 1/10, Step: 56/143, Lr: 0.000000039-0.000039161, Loss: 1.908462, Time/step: 13.551203
10/10/2023 02:09:01 - INFO -   Epoch: 1/10, Step: 57/143, Lr: 0.000000040-0.000039860, Loss: 2.490498, Time/step: 13.152566
10/10/2023 02:09:14 - INFO -   Epoch: 1/10, Step: 58/143, Lr: 0.000000041-0.000040559, Loss: 1.724963, Time/step: 13.420439
10/10/2023 02:09:28 - INFO -   Epoch: 1/10, Step: 59/143, Lr: 0.000000041-0.000041259, Loss: 2.127637, Time/step: 13.590555
10/10/2023 02:09:41 - INFO -   Epoch: 1/10, Step: 60/143, Lr: 0.000000042-0.000041958, Loss: 2.135405, Time/step: 13.582861
10/10/2023 02:09:55 - INFO -   Epoch: 1/10, Step: 61/143, Lr: 0.000000043-0.000042657, Loss: 2.147318, Time/step: 13.393120
10/10/2023 02:10:09 - INFO -   Epoch: 1/10, Step: 62/143, Lr: 0.000000043-0.000043357, Loss: 1.753635, Time/step: 14.068897
10/10/2023 02:10:23 - INFO -   Epoch: 1/10, Step: 63/143, Lr: 0.000000044-0.000044056, Loss: 1.949512, Time/step: 14.090230
10/10/2023 02:10:38 - INFO -   Epoch: 1/10, Step: 64/143, Lr: 0.000000045-0.000044755, Loss: 2.425417, Time/step: 15.008178
10/10/2023 04:04:11 - INFO -   Epoch: 1/10, Step: 65/143, Lr: 0.000000045-0.000045455, Loss: 2.525358, Time/step: 6812.433424
10/10/2023 04:04:23 - INFO -   Epoch: 1/10, Step: 66/143, Lr: 0.000000046-0.000046154, Loss: 1.941752, Time/step: 12.688920
10/10/2023 04:04:36 - INFO -   Epoch: 1/10, Step: 67/143, Lr: 0.000000047-0.000046853, Loss: 1.915541, Time/step: 12.715183
10/10/2023 04:04:49 - INFO -   Epoch: 1/10, Step: 68/143, Lr: 0.000000048-0.000047552, Loss: 1.697954, Time/step: 13.250909
10/10/2023 04:05:03 - INFO -   Epoch: 1/10, Step: 69/143, Lr: 0.000000048-0.000048252, Loss: 1.656428, Time/step: 14.020087
10/10/2023 04:05:17 - INFO -   Epoch: 1/10, Step: 70/143, Lr: 0.000000049-0.000048951, Loss: 2.035128, Time/step: 13.665996
10/10/2023 04:05:31 - INFO -   Epoch: 1/10, Step: 71/143, Lr: 0.000000050-0.000049650, Loss: 1.731459, Time/step: 13.683641
10/10/2023 04:05:45 - INFO -   Epoch: 1/10, Step: 72/143, Lr: 0.000000050-0.000050350, Loss: 2.000666, Time/step: 14.373240
10/10/2023 04:05:59 - INFO -   Epoch: 1/10, Step: 73/143, Lr: 0.000000051-0.000051049, Loss: 2.169733, Time/step: 14.311445
10/10/2023 04:06:14 - INFO -   Epoch: 1/10, Step: 74/143, Lr: 0.000000052-0.000051748, Loss: 1.879827, Time/step: 14.311963
10/10/2023 04:06:28 - INFO -   Epoch: 1/10, Step: 75/143, Lr: 0.000000052-0.000052448, Loss: 1.672841, Time/step: 14.492584
10/10/2023 04:06:43 - INFO -   Epoch: 1/10, Step: 76/143, Lr: 0.000000053-0.000053147, Loss: 1.817317, Time/step: 14.429737
10/10/2023 04:06:57 - INFO -   Epoch: 1/10, Step: 77/143, Lr: 0.000000054-0.000053846, Loss: 1.886135, Time/step: 14.192013
10/10/2023 04:07:12 - INFO -   Epoch: 1/10, Step: 78/143, Lr: 0.000000055-0.000054545, Loss: 2.086099, Time/step: 14.725132
10/10/2023 04:07:27 - INFO -   Epoch: 1/10, Step: 79/143, Lr: 0.000000055-0.000055245, Loss: 1.833058, Time/step: 15.288303
10/10/2023 04:07:42 - INFO -   Epoch: 1/10, Step: 80/143, Lr: 0.000000056-0.000055944, Loss: 1.882174, Time/step: 15.115774
10/10/2023 06:11:16 - INFO -   Epoch: 1/10, Step: 81/143, Lr: 0.000000057-0.000056643, Loss: 2.324708, Time/step: 7414.117767
10/10/2023 06:11:30 - INFO -   Epoch: 1/10, Step: 82/143, Lr: 0.000000057-0.000057343, Loss: 1.974172, Time/step: 14.161150
10/10/2023 06:11:44 - INFO -   Epoch: 1/10, Step: 83/143, Lr: 0.000000058-0.000058042, Loss: 1.942274, Time/step: 13.765864
10/10/2023 06:11:58 - INFO -   Epoch: 1/10, Step: 84/143, Lr: 0.000000059-0.000058741, Loss: 1.791029, Time/step: 14.305363
10/10/2023 06:12:12 - INFO -   Epoch: 1/10, Step: 85/143, Lr: 0.000000059-0.000059441, Loss: 1.440304, Time/step: 13.974775
10/10/2023 06:12:26 - INFO -   Epoch: 1/10, Step: 86/143, Lr: 0.000000060-0.000060140, Loss: 1.861451, Time/step: 13.933118
10/10/2023 06:12:41 - INFO -   Epoch: 1/10, Step: 87/143, Lr: 0.000000061-0.000060839, Loss: 1.478527, Time/step: 14.562479
10/10/2023 06:12:56 - INFO -   Epoch: 1/10, Step: 88/143, Lr: 0.000000062-0.000061538, Loss: 1.921843, Time/step: 15.328978
10/10/2023 06:13:10 - INFO -   Epoch: 1/10, Step: 89/143, Lr: 0.000000062-0.000062238, Loss: 1.787112, Time/step: 14.143873
10/10/2023 06:13:25 - INFO -   Epoch: 1/10, Step: 90/143, Lr: 0.000000063-0.000062937, Loss: 2.033716, Time/step: 14.992496
10/10/2023 06:13:40 - INFO -   Epoch: 1/10, Step: 91/143, Lr: 0.000000064-0.000063636, Loss: 2.065514, Time/step: 14.856593
10/10/2023 06:13:54 - INFO -   Epoch: 1/10, Step: 92/143, Lr: 0.000000064-0.000064336, Loss: 1.708426, Time/step: 14.238514
10/10/2023 06:14:10 - INFO -   Epoch: 1/10, Step: 93/143, Lr: 0.000000065-0.000065035, Loss: 1.728003, Time/step: 15.405664
10/10/2023 06:14:25 - INFO -   Epoch: 1/10, Step: 94/143, Lr: 0.000000066-0.000065734, Loss: 1.888203, Time/step: 15.472896
10/10/2023 06:14:40 - INFO -   Epoch: 1/10, Step: 95/143, Lr: 0.000000066-0.000066434, Loss: 1.653903, Time/step: 14.616746
10/10/2023 06:14:55 - INFO -   Epoch: 1/10, Step: 96/143, Lr: 0.000000067-0.000067133, Loss: 1.582536, Time/step: 14.954667
10/10/2023 07:41:40 - INFO -   Epoch: 1/10, Step: 97/143, Lr: 0.000000068-0.000067832, Loss: 1.997990, Time/step: 5205.635838
10/10/2023 07:41:55 - INFO -   Epoch: 1/10, Step: 98/143, Lr: 0.000000069-0.000068531, Loss: 2.144083, Time/step: 14.285612
10/10/2023 07:42:10 - INFO -   Epoch: 1/10, Step: 99/143, Lr: 0.000000069-0.000069231, Loss: 1.799657, Time/step: 15.143631
10/10/2023 07:42:25 - INFO -   Epoch: 1/10, Step: 100/143, Lr: 0.000000070-0.000069930, Loss: 1.767103, Time/step: 14.653854
10/10/2023 07:42:39 - INFO -   Epoch: 1/10, Step: 101/143, Lr: 0.000000071-0.000070629, Loss: 1.822098, Time/step: 14.898603
10/10/2023 07:56:32 - INFO -   Epoch: 1/10, Step: 102/143, Lr: 0.000000071-0.000071329, Loss: 1.781587, Time/step: 832.717922
10/10/2023 07:56:47 - INFO -   Epoch: 1/10, Step: 103/143, Lr: 0.000000072-0.000072028, Loss: 1.203427, Time/step: 14.503653
10/10/2023 07:57:01 - INFO -   Epoch: 1/10, Step: 104/143, Lr: 0.000000073-0.000072727, Loss: 1.493046, Time/step: 14.791827
10/10/2023 07:57:16 - INFO -   Epoch: 1/10, Step: 105/143, Lr: 0.000000073-0.000073427, Loss: 2.127493, Time/step: 14.563400
10/10/2023 08:01:03 - INFO -   Epoch: 1/10, Step: 106/143, Lr: 0.000000074-0.000074126, Loss: 2.207783, Time/step: 226.950123
10/10/2023 08:01:17 - INFO -   Epoch: 1/10, Step: 107/143, Lr: 0.000000075-0.000074825, Loss: 2.344750, Time/step: 14.046789
10/10/2023 08:31:32 - INFO -   Epoch: 1/10, Step: 108/143, Lr: 0.000000076-0.000075524, Loss: 1.683929, Time/step: 1815.283258
10/10/2023 08:31:47 - INFO -   Epoch: 1/10, Step: 109/143, Lr: 0.000000076-0.000076224, Loss: 2.105858, Time/step: 14.504530
10/10/2023 08:32:01 - INFO -   Epoch: 1/10, Step: 110/143, Lr: 0.000000077-0.000076923, Loss: 1.428896, Time/step: 14.270215
10/10/2023 08:32:16 - INFO -   Epoch: 1/10, Step: 111/143, Lr: 0.000000078-0.000077622, Loss: 2.133519, Time/step: 14.790320
10/10/2023 08:32:31 - INFO -   Epoch: 1/10, Step: 112/143, Lr: 0.000000078-0.000078322, Loss: 1.866130, Time/step: 14.593329
10/10/2023 09:09:49 - INFO -   Epoch: 1/10, Step: 113/143, Lr: 0.000000079-0.000079021, Loss: 1.836152, Time/step: 2238.118215
10/10/2023 09:32:12 - INFO -   Epoch: 1/10, Step: 114/143, Lr: 0.000000080-0.000079720, Loss: 1.900594, Time/step: 1343.226339
10/10/2023 09:32:26 - INFO -   Epoch: 1/10, Step: 115/143, Lr: 0.000000080-0.000080420, Loss: 2.192497, Time/step: 13.521368
10/10/2023 09:32:39 - INFO -   Epoch: 1/10, Step: 116/143, Lr: 0.000000081-0.000081119, Loss: 2.060663, Time/step: 13.415055
10/10/2023 09:39:02 - INFO -   Epoch: 1/10, Step: 117/143, Lr: 0.000000082-0.000081818, Loss: 1.974031, Time/step: 382.661797
10/10/2023 09:39:16 - INFO -   Epoch: 1/10, Step: 118/143, Lr: 0.000000083-0.000082517, Loss: 2.020143, Time/step: 13.786480
10/10/2023 09:39:29 - INFO -   Epoch: 1/10, Step: 119/143, Lr: 0.000000083-0.000083217, Loss: 1.791354, Time/step: 13.738243
10/10/2023 09:39:43 - INFO -   Epoch: 1/10, Step: 120/143, Lr: 0.000000084-0.000083916, Loss: 1.816789, Time/step: 13.401779
10/10/2023 09:39:57 - INFO -   Epoch: 1/10, Step: 121/143, Lr: 0.000000085-0.000084615, Loss: 1.763254, Time/step: 13.955946
10/10/2023 09:59:02 - INFO -   Epoch: 1/10, Step: 122/143, Lr: 0.000000085-0.000085315, Loss: 1.524844, Time/step: 1145.395517
10/10/2023 09:59:14 - INFO -   Epoch: 1/10, Step: 123/143, Lr: 0.000000086-0.000086014, Loss: 1.927364, Time/step: 11.771665
10/10/2023 10:17:11 - INFO -   Epoch: 1/10, Step: 124/143, Lr: 0.000000087-0.000086713, Loss: 1.490429, Time/step: 1076.920503
10/10/2023 10:17:22 - INFO -   Epoch: 1/10, Step: 125/143, Lr: 0.000000087-0.000087413, Loss: 1.804778, Time/step: 10.662930
10/10/2023 10:17:32 - INFO -   Epoch: 1/10, Step: 126/143, Lr: 0.000000088-0.000088112, Loss: 2.008116, Time/step: 10.637380
10/10/2023 10:17:43 - INFO -   Epoch: 1/10, Step: 127/143, Lr: 0.000000089-0.000088811, Loss: 1.787618, Time/step: 10.163052
10/10/2023 10:17:53 - INFO -   Epoch: 1/10, Step: 128/143, Lr: 0.000000090-0.000089510, Loss: 1.987232, Time/step: 10.623187
10/10/2023 10:39:38 - INFO -   Epoch: 1/10, Step: 129/143, Lr: 0.000000090-0.000090210, Loss: 1.707725, Time/step: 1304.781720
10/10/2023 10:41:53 - INFO -   Epoch: 1/10, Step: 130/143, Lr: 0.000000091-0.000090909, Loss: 1.765809, Time/step: 134.636937
10/10/2023 10:41:56 - INFO -   Epoch: 1/10, Step: 131/143, Lr: 0.000000092-0.000091608, Loss: 1.610368, Time/step: 2.794743
10/10/2023 10:41:58 - INFO -   Epoch: 1/10, Step: 132/143, Lr: 0.000000092-0.000092308, Loss: 1.683296, Time/step: 2.790391
10/10/2023 10:45:14 - INFO -   Epoch: 1/10, Step: 133/143, Lr: 0.000000093-0.000093007, Loss: 1.690882, Time/step: 195.781607
10/10/2023 10:45:17 - INFO -   Epoch: 1/10, Step: 134/143, Lr: 0.000000094-0.000093706, Loss: 1.684701, Time/step: 2.401502
10/10/2023 10:45:19 - INFO -   Epoch: 1/10, Step: 135/143, Lr: 0.000000094-0.000094406, Loss: 2.060595, Time/step: 2.371688
10/10/2023 10:45:21 - INFO -   Epoch: 1/10, Step: 136/143, Lr: 0.000000095-0.000095105, Loss: 1.648302, Time/step: 2.464914
10/10/2023 10:45:24 - INFO -   Epoch: 1/10, Step: 137/143, Lr: 0.000000096-0.000095804, Loss: 2.037661, Time/step: 2.452648
10/10/2023 10:46:34 - INFO -   Epoch: 1/10, Step: 138/143, Lr: 0.000000097-0.000096503, Loss: 1.749213, Time/step: 70.399745
10/10/2023 10:46:35 - INFO -   Epoch: 1/10, Step: 139/143, Lr: 0.000000097-0.000097203, Loss: 1.919689, Time/step: 1.094149
10/10/2023 10:46:36 - INFO -   Epoch: 1/10, Step: 140/143, Lr: 0.000000098-0.000097902, Loss: 1.632604, Time/step: 1.067298
10/10/2023 10:46:38 - INFO -   Epoch: 1/10, Step: 141/143, Lr: 0.000000099-0.000098601, Loss: 1.906681, Time/step: 1.104222
10/10/2023 10:46:39 - INFO -   Epoch: 1/10, Step: 142/143, Lr: 0.000000099-0.000099301, Loss: 1.538489, Time/step: 1.100094
10/10/2023 10:46:40 - INFO -   Epoch: 1/10, Step: 143/143, Lr: 0.000000098-0.000097553, Loss: 1.840232, Time/step: 1.080264
10/10/2023 10:46:42 - INFO -   Epoch 1/10 Finished, Train Loss: 2.098987
10/10/2023 10:47:01 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.0
10/10/2023 10:47:01 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_opt.bin.0
10/10/2023 10:47:01 - INFO -   Eval on val dataset
10/10/2023 13:01:15 - INFO -   sim matrix size: 184, 184
10/10/2023 13:01:15 - INFO -   	 Length-T: 184, Length-V:184
10/10/2023 13:01:15 - INFO -   Text-to-Video:
10/10/2023 13:01:15 - INFO -   	>>>  R@1: 56.5 - R@5: 82.1 - R@10: 92.4 - Median R: 1.0 - Mean R: 4.5
10/10/2023 13:01:15 - INFO -   Video-to-Text:
10/10/2023 13:01:15 - INFO -   	>>>  V2T$R@1: 57.6 - V2T$R@5: 84.2 - V2T$R@10: 91.8 - V2T$Median R: 1.0 - V2T$Mean R: 4.1
10/10/2023 13:01:15 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.0, the R1 is: 56.5217
10/10/2023 14:00:10 - INFO -   Epoch: 2/10, Step: 1/143, Lr: 0.000000098-0.000097519, Loss: 1.503743, Time/step: 3533.300206
10/10/2023 14:12:48 - INFO -   Epoch: 2/10, Step: 2/143, Lr: 0.000000097-0.000097484, Loss: 1.388177, Time/step: 758.295598
10/10/2023 14:12:57 - INFO -   Epoch: 2/10, Step: 3/143, Lr: 0.000000097-0.000097450, Loss: 1.272678, Time/step: 8.634429
10/10/2023 14:13:55 - INFO -   Epoch: 2/10, Step: 4/143, Lr: 0.000000097-0.000097415, Loss: 1.665631, Time/step: 57.894413
10/10/2023 14:14:04 - INFO -   Epoch: 2/10, Step: 5/143, Lr: 0.000000097-0.000097380, Loss: 1.579959, Time/step: 9.597222
10/10/2023 14:14:15 - INFO -   Epoch: 2/10, Step: 6/143, Lr: 0.000000097-0.000097345, Loss: 1.771838, Time/step: 10.298313
10/10/2023 14:14:25 - INFO -   Epoch: 2/10, Step: 7/143, Lr: 0.000000097-0.000097310, Loss: 1.421115, Time/step: 10.789809
10/10/2023 14:14:37 - INFO -   Epoch: 2/10, Step: 8/143, Lr: 0.000000097-0.000097274, Loss: 1.265110, Time/step: 11.450684
10/10/2023 14:14:48 - INFO -   Epoch: 2/10, Step: 9/143, Lr: 0.000000097-0.000097238, Loss: 1.217638, Time/step: 11.546932
10/10/2023 14:15:00 - INFO -   Epoch: 2/10, Step: 10/143, Lr: 0.000000097-0.000097202, Loss: 1.358477, Time/step: 12.006184
10/10/2023 14:15:12 - INFO -   Epoch: 2/10, Step: 11/143, Lr: 0.000000097-0.000097166, Loss: 1.225564, Time/step: 12.077395
10/10/2023 14:15:25 - INFO -   Epoch: 2/10, Step: 12/143, Lr: 0.000000097-0.000097129, Loss: 1.798383, Time/step: 12.722965
10/10/2023 14:33:58 - INFO -   Epoch: 2/10, Step: 13/143, Lr: 0.000000097-0.000097092, Loss: 1.075025, Time/step: 1112.585757
10/10/2023 14:34:12 - INFO -   Epoch: 2/10, Step: 14/143, Lr: 0.000000097-0.000097055, Loss: 1.542715, Time/step: 13.628349
10/10/2023 14:34:26 - INFO -   Epoch: 2/10, Step: 15/143, Lr: 0.000000097-0.000097018, Loss: 1.267626, Time/step: 14.318639
10/10/2023 14:34:40 - INFO -   Epoch: 2/10, Step: 16/143, Lr: 0.000000097-0.000096980, Loss: 1.978859, Time/step: 14.418634
10/10/2023 16:09:24 - INFO -   Epoch: 2/10, Step: 17/143, Lr: 0.000000097-0.000096943, Loss: 1.495960, Time/step: 5683.584354
10/10/2023 16:09:35 - INFO -   Epoch: 2/10, Step: 18/143, Lr: 0.000000097-0.000096905, Loss: 1.557847, Time/step: 11.522690
10/10/2023 16:09:47 - INFO -   Epoch: 2/10, Step: 19/143, Lr: 0.000000097-0.000096867, Loss: 1.668867, Time/step: 11.649947
10/10/2023 16:09:59 - INFO -   Epoch: 2/10, Step: 20/143, Lr: 0.000000097-0.000096828, Loss: 1.230830, Time/step: 11.551300
10/10/2023 16:10:11 - INFO -   Epoch: 2/10, Step: 21/143, Lr: 0.000000097-0.000096790, Loss: 1.829787, Time/step: 11.958323
10/10/2023 16:10:22 - INFO -   Epoch: 2/10, Step: 22/143, Lr: 0.000000097-0.000096751, Loss: 1.339829, Time/step: 11.840691
10/10/2023 16:10:35 - INFO -   Epoch: 2/10, Step: 23/143, Lr: 0.000000097-0.000096712, Loss: 1.913004, Time/step: 11.976451
10/10/2023 16:15:48 - INFO -   Epoch: 2/10, Step: 24/143, Lr: 0.000000097-0.000096672, Loss: 1.709262, Time/step: 313.897927
10/10/2023 16:16:01 - INFO -   Epoch: 2/10, Step: 25/143, Lr: 0.000000097-0.000096633, Loss: 1.413006, Time/step: 12.822700
10/10/2023 16:16:15 - INFO -   Epoch: 2/10, Step: 26/143, Lr: 0.000000097-0.000096593, Loss: 1.182225, Time/step: 13.462992
10/10/2023 16:16:28 - INFO -   Epoch: 2/10, Step: 27/143, Lr: 0.000000097-0.000096553, Loss: 1.221835, Time/step: 13.465940
10/10/2023 16:16:42 - INFO -   Epoch: 2/10, Step: 28/143, Lr: 0.000000097-0.000096513, Loss: 1.705030, Time/step: 14.236001
10/10/2023 16:16:57 - INFO -   Epoch: 2/10, Step: 29/143, Lr: 0.000000096-0.000096473, Loss: 1.394454, Time/step: 14.767156
10/10/2023 16:17:12 - INFO -   Epoch: 2/10, Step: 30/143, Lr: 0.000000096-0.000096432, Loss: 1.223993, Time/step: 15.259326
10/10/2023 16:17:28 - INFO -   Epoch: 2/10, Step: 31/143, Lr: 0.000000096-0.000096391, Loss: 1.360322, Time/step: 15.527245
10/10/2023 16:17:43 - INFO -   Epoch: 2/10, Step: 32/143, Lr: 0.000000096-0.000096350, Loss: 1.742455, Time/step: 14.812713
10/10/2023 18:02:02 - INFO -   Epoch: 2/10, Step: 33/143, Lr: 0.000000096-0.000096309, Loss: 1.557869, Time/step: 6258.766281
10/10/2023 18:02:15 - INFO -   Epoch: 2/10, Step: 34/143, Lr: 0.000000096-0.000096267, Loss: 1.344672, Time/step: 12.844426
10/10/2023 18:02:28 - INFO -   Epoch: 2/10, Step: 35/143, Lr: 0.000000096-0.000096225, Loss: 1.300136, Time/step: 13.277976
10/10/2023 18:06:30 - INFO -   Epoch: 2/10, Step: 36/143, Lr: 0.000000096-0.000096183, Loss: 1.341424, Time/step: 241.716116
10/10/2023 18:09:41 - INFO -   Epoch: 2/10, Step: 37/143, Lr: 0.000000096-0.000096141, Loss: 1.880838, Time/step: 191.216222
10/10/2023 18:09:54 - INFO -   Epoch: 2/10, Step: 38/143, Lr: 0.000000096-0.000096099, Loss: 1.340058, Time/step: 13.442787
10/10/2023 18:12:53 - INFO -   Epoch: 2/10, Step: 39/143, Lr: 0.000000096-0.000096056, Loss: 1.044624, Time/step: 178.758783
10/10/2023 18:45:44 - INFO -   Epoch: 2/10, Step: 40/143, Lr: 0.000000096-0.000096013, Loss: 1.241568, Time/step: 1971.244766
10/10/2023 18:45:57 - INFO -   Epoch: 2/10, Step: 41/143, Lr: 0.000000096-0.000095970, Loss: 1.512660, Time/step: 12.295639
10/10/2023 18:46:09 - INFO -   Epoch: 2/10, Step: 42/143, Lr: 0.000000096-0.000095927, Loss: 1.770645, Time/step: 12.255285
10/10/2023 18:46:22 - INFO -   Epoch: 2/10, Step: 43/143, Lr: 0.000000096-0.000095883, Loss: 1.665520, Time/step: 13.103390
10/10/2023 18:46:35 - INFO -   Epoch: 2/10, Step: 44/143, Lr: 0.000000096-0.000095840, Loss: 1.324905, Time/step: 13.105087
10/10/2023 18:46:48 - INFO -   Epoch: 2/10, Step: 45/143, Lr: 0.000000096-0.000095796, Loss: 1.122624, Time/step: 13.006018
10/10/2023 18:47:02 - INFO -   Epoch: 2/10, Step: 46/143, Lr: 0.000000096-0.000095751, Loss: 1.351418, Time/step: 14.087726
10/10/2023 18:47:17 - INFO -   Epoch: 2/10, Step: 47/143, Lr: 0.000000096-0.000095707, Loss: 1.553277, Time/step: 14.270682
10/10/2023 18:47:31 - INFO -   Epoch: 2/10, Step: 48/143, Lr: 0.000000096-0.000095662, Loss: 1.630669, Time/step: 14.474301
10/10/2023 19:45:25 - INFO -   Epoch: 2/10, Step: 49/143, Lr: 0.000000096-0.000095618, Loss: 1.366291, Time/step: 3474.243465
10/10/2023 19:51:27 - INFO -   Epoch: 2/10, Step: 50/143, Lr: 0.000000096-0.000095572, Loss: 1.732828, Time/step: 361.530520
10/10/2023 19:57:18 - INFO -   Epoch: 2/10, Step: 51/143, Lr: 0.000000096-0.000095527, Loss: 1.751832, Time/step: 350.817224
10/10/2023 19:57:32 - INFO -   Epoch: 2/10, Step: 52/143, Lr: 0.000000095-0.000095482, Loss: 1.453566, Time/step: 14.018593
10/10/2023 20:10:59 - INFO -   Epoch: 2/10, Step: 53/143, Lr: 0.000000095-0.000095436, Loss: 1.188769, Time/step: 806.945907
10/10/2023 20:11:14 - INFO -   Epoch: 2/10, Step: 54/143, Lr: 0.000000095-0.000095390, Loss: 1.313436, Time/step: 15.619301
10/10/2023 20:11:30 - INFO -   Epoch: 2/10, Step: 55/143, Lr: 0.000000095-0.000095344, Loss: 1.339300, Time/step: 15.412349
10/10/2023 21:00:42 - INFO -   Epoch: 2/10, Step: 56/143, Lr: 0.000000095-0.000095297, Loss: 1.314473, Time/step: 2951.705366
10/10/2023 21:00:54 - INFO -   Epoch: 2/10, Step: 57/143, Lr: 0.000000095-0.000095251, Loss: 1.440974, Time/step: 11.917066
10/10/2023 21:01:07 - INFO -   Epoch: 2/10, Step: 58/143, Lr: 0.000000095-0.000095204, Loss: 1.332952, Time/step: 12.950155
10/10/2023 21:01:19 - INFO -   Epoch: 2/10, Step: 59/143, Lr: 0.000000095-0.000095157, Loss: 0.975569, Time/step: 12.664809
10/10/2023 21:01:33 - INFO -   Epoch: 2/10, Step: 60/143, Lr: 0.000000095-0.000095110, Loss: 1.692591, Time/step: 13.311024
10/10/2023 21:01:46 - INFO -   Epoch: 2/10, Step: 61/143, Lr: 0.000000095-0.000095062, Loss: 1.262156, Time/step: 13.528782
10/10/2023 21:02:00 - INFO -   Epoch: 2/10, Step: 62/143, Lr: 0.000000095-0.000095014, Loss: 1.610970, Time/step: 13.659662
10/10/2023 21:02:14 - INFO -   Epoch: 2/10, Step: 63/143, Lr: 0.000000095-0.000094966, Loss: 1.226304, Time/step: 14.418688
10/10/2023 21:02:29 - INFO -   Epoch: 2/10, Step: 64/143, Lr: 0.000000095-0.000094918, Loss: 1.237188, Time/step: 14.811684
10/10/2023 21:28:56 - INFO -   Epoch: 2/10, Step: 65/143, Lr: 0.000000095-0.000094870, Loss: 1.443338, Time/step: 1586.982834
10/10/2023 21:42:05 - INFO -   Epoch: 2/10, Step: 66/143, Lr: 0.000000095-0.000094821, Loss: 1.441272, Time/step: 788.413064
10/10/2023 21:42:20 - INFO -   Epoch: 2/10, Step: 67/143, Lr: 0.000000095-0.000094773, Loss: 1.780024, Time/step: 15.158535
10/10/2023 21:42:35 - INFO -   Epoch: 2/10, Step: 68/143, Lr: 0.000000095-0.000094724, Loss: 1.772415, Time/step: 15.626097
10/10/2023 22:29:21 - INFO -   Epoch: 2/10, Step: 69/143, Lr: 0.000000095-0.000094674, Loss: 1.426515, Time/step: 2805.596232
10/10/2023 22:29:35 - INFO -   Epoch: 2/10, Step: 70/143, Lr: 0.000000095-0.000094625, Loss: 1.334779, Time/step: 14.254481
10/10/2023 22:29:50 - INFO -   Epoch: 2/10, Step: 71/143, Lr: 0.000000095-0.000094575, Loss: 1.157027, Time/step: 14.697382
10/10/2023 22:48:52 - INFO -   Epoch: 2/10, Step: 72/143, Lr: 0.000000095-0.000094525, Loss: 1.624788, Time/step: 1141.815284
10/10/2023 22:49:06 - INFO -   Epoch: 2/10, Step: 73/143, Lr: 0.000000094-0.000094475, Loss: 1.467129, Time/step: 13.560751
10/10/2023 22:49:19 - INFO -   Epoch: 2/10, Step: 74/143, Lr: 0.000000094-0.000094425, Loss: 1.381602, Time/step: 13.233764
10/10/2023 22:49:33 - INFO -   Epoch: 2/10, Step: 75/143, Lr: 0.000000094-0.000094374, Loss: 1.421677, Time/step: 13.906842
10/10/2023 22:49:47 - INFO -   Epoch: 2/10, Step: 76/143, Lr: 0.000000094-0.000094324, Loss: 1.288527, Time/step: 13.864584
10/10/2023 22:50:00 - INFO -   Epoch: 2/10, Step: 77/143, Lr: 0.000000094-0.000094273, Loss: 1.521629, Time/step: 13.935277
10/10/2023 22:50:14 - INFO -   Epoch: 2/10, Step: 78/143, Lr: 0.000000094-0.000094222, Loss: 1.894451, Time/step: 13.792607
10/10/2023 22:50:29 - INFO -   Epoch: 2/10, Step: 79/143, Lr: 0.000000094-0.000094170, Loss: 1.308322, Time/step: 14.397221
10/10/2023 22:50:43 - INFO -   Epoch: 2/10, Step: 80/143, Lr: 0.000000094-0.000094119, Loss: 1.236501, Time/step: 14.590525
10/10/2023 23:46:17 - INFO -   Epoch: 2/10, Step: 81/143, Lr: 0.000000094-0.000094067, Loss: 1.571919, Time/step: 3333.907322
10/11/2023 00:06:17 - INFO -   Epoch: 2/10, Step: 82/143, Lr: 0.000000094-0.000094015, Loss: 1.528114, Time/step: 1199.255730
10/11/2023 00:06:31 - INFO -   Epoch: 2/10, Step: 83/143, Lr: 0.000000094-0.000093963, Loss: 1.567199, Time/step: 14.438602
10/11/2023 00:06:47 - INFO -   Epoch: 2/10, Step: 84/143, Lr: 0.000000094-0.000093910, Loss: 1.554515, Time/step: 15.709351
10/11/2023 00:54:23 - INFO -   Epoch: 2/10, Step: 85/143, Lr: 0.000000094-0.000093858, Loss: 1.291263, Time/step: 2855.948373
10/11/2023 00:54:34 - INFO -   Epoch: 2/10, Step: 86/143, Lr: 0.000000094-0.000093805, Loss: 1.362239, Time/step: 10.845298
10/11/2023 00:54:45 - INFO -   Epoch: 2/10, Step: 87/143, Lr: 0.000000094-0.000093752, Loss: 1.558033, Time/step: 11.408370
10/11/2023 00:54:57 - INFO -   Epoch: 2/10, Step: 88/143, Lr: 0.000000094-0.000093698, Loss: 1.446578, Time/step: 11.897948
10/11/2023 00:55:10 - INFO -   Epoch: 2/10, Step: 89/143, Lr: 0.000000094-0.000093645, Loss: 1.662450, Time/step: 12.582256
10/11/2023 00:55:23 - INFO -   Epoch: 2/10, Step: 90/143, Lr: 0.000000094-0.000093591, Loss: 1.278776, Time/step: 13.698823
10/11/2023 00:55:37 - INFO -   Epoch: 2/10, Step: 91/143, Lr: 0.000000094-0.000093537, Loss: 2.056535, Time/step: 14.080896
10/11/2023 00:55:52 - INFO -   Epoch: 2/10, Step: 92/143, Lr: 0.000000093-0.000093483, Loss: 1.513161, Time/step: 14.238723
10/11/2023 00:56:06 - INFO -   Epoch: 2/10, Step: 93/143, Lr: 0.000000093-0.000093429, Loss: 1.211800, Time/step: 13.934787
10/11/2023 00:56:20 - INFO -   Epoch: 2/10, Step: 94/143, Lr: 0.000000093-0.000093374, Loss: 1.298766, Time/step: 14.421849
10/11/2023 00:56:35 - INFO -   Epoch: 2/10, Step: 95/143, Lr: 0.000000093-0.000093320, Loss: 1.435610, Time/step: 14.962950
10/11/2023 00:56:50 - INFO -   Epoch: 2/10, Step: 96/143, Lr: 0.000000093-0.000093265, Loss: 1.649871, Time/step: 14.729745
10/11/2023 01:18:01 - INFO -   Epoch: 2/10, Step: 97/143, Lr: 0.000000093-0.000093209, Loss: 1.400677, Time/step: 1271.406577
10/11/2023 01:39:40 - INFO -   Epoch: 2/10, Step: 98/143, Lr: 0.000000093-0.000093154, Loss: 1.871285, Time/step: 1298.746946
10/11/2023 01:39:55 - INFO -   Epoch: 2/10, Step: 99/143, Lr: 0.000000093-0.000093098, Loss: 1.428924, Time/step: 15.217674
10/11/2023 01:40:11 - INFO -   Epoch: 2/10, Step: 100/143, Lr: 0.000000093-0.000093043, Loss: 1.632647, Time/step: 15.386655
10/11/2023 02:42:22 - INFO -   Epoch: 2/10, Step: 101/143, Lr: 0.000000093-0.000092987, Loss: 1.550340, Time/step: 3731.285881
10/11/2023 02:42:36 - INFO -   Epoch: 2/10, Step: 102/143, Lr: 0.000000093-0.000092930, Loss: 1.346690, Time/step: 14.051151
10/11/2023 02:42:50 - INFO -   Epoch: 2/10, Step: 103/143, Lr: 0.000000093-0.000092874, Loss: 1.123155, Time/step: 14.140810
10/11/2023 03:09:31 - INFO -   Epoch: 2/10, Step: 104/143, Lr: 0.000000093-0.000092817, Loss: 1.631667, Time/step: 1601.143857
10/11/2023 03:09:42 - INFO -   Epoch: 2/10, Step: 105/143, Lr: 0.000000093-0.000092761, Loss: 1.851372, Time/step: 10.801316
10/11/2023 03:09:54 - INFO -   Epoch: 2/10, Step: 106/143, Lr: 0.000000093-0.000092704, Loss: 1.615448, Time/step: 12.038314
10/11/2023 03:10:07 - INFO -   Epoch: 2/10, Step: 107/143, Lr: 0.000000093-0.000092646, Loss: 1.319723, Time/step: 12.553359
10/11/2023 03:10:20 - INFO -   Epoch: 2/10, Step: 108/143, Lr: 0.000000093-0.000092589, Loss: 1.808706, Time/step: 13.047047
10/11/2023 03:10:33 - INFO -   Epoch: 2/10, Step: 109/143, Lr: 0.000000093-0.000092531, Loss: 1.289599, Time/step: 13.282940
10/11/2023 03:10:47 - INFO -   Epoch: 2/10, Step: 110/143, Lr: 0.000000092-0.000092473, Loss: 1.531599, Time/step: 13.961931
10/11/2023 03:11:02 - INFO -   Epoch: 2/10, Step: 111/143, Lr: 0.000000092-0.000092415, Loss: 1.805311, Time/step: 14.337379
10/11/2023 03:11:16 - INFO -   Epoch: 2/10, Step: 112/143, Lr: 0.000000092-0.000092357, Loss: 1.421186, Time/step: 14.103495
10/11/2023 03:37:11 - INFO -   Epoch: 2/10, Step: 113/143, Lr: 0.000000092-0.000092299, Loss: 1.497644, Time/step: 1554.697159
10/11/2023 03:37:24 - INFO -   Epoch: 2/10, Step: 114/143, Lr: 0.000000092-0.000092240, Loss: 1.739130, Time/step: 13.379655
10/11/2023 03:37:38 - INFO -   Epoch: 2/10, Step: 115/143, Lr: 0.000000092-0.000092181, Loss: 1.619451, Time/step: 13.585301
10/11/2023 03:37:51 - INFO -   Epoch: 2/10, Step: 116/143, Lr: 0.000000092-0.000092122, Loss: 1.645717, Time/step: 13.598498
10/11/2023 04:20:35 - INFO -   Epoch: 2/10, Step: 117/143, Lr: 0.000000092-0.000092063, Loss: 1.515095, Time/step: 2563.365648
10/11/2023 04:20:46 - INFO -   Epoch: 2/10, Step: 118/143, Lr: 0.000000092-0.000092003, Loss: 1.450377, Time/step: 11.103305
10/11/2023 04:20:57 - INFO -   Epoch: 2/10, Step: 119/143, Lr: 0.000000092-0.000091943, Loss: 1.716407, Time/step: 10.862889
10/11/2023 04:23:46 - INFO -   Epoch: 2/10, Step: 120/143, Lr: 0.000000092-0.000091884, Loss: 1.716326, Time/step: 168.943543
10/11/2023 04:23:57 - INFO -   Epoch: 2/10, Step: 121/143, Lr: 0.000000092-0.000091824, Loss: 1.610426, Time/step: 11.095231
10/11/2023 04:24:08 - INFO -   Epoch: 2/10, Step: 122/143, Lr: 0.000000092-0.000091763, Loss: 1.460840, Time/step: 10.817641
10/11/2023 04:24:19 - INFO -   Epoch: 2/10, Step: 123/143, Lr: 0.000000092-0.000091703, Loss: 1.362676, Time/step: 10.865398
10/11/2023 04:24:30 - INFO -   Epoch: 2/10, Step: 124/143, Lr: 0.000000092-0.000091642, Loss: 1.426956, Time/step: 11.398402
10/11/2023 04:24:41 - INFO -   Epoch: 2/10, Step: 125/143, Lr: 0.000000092-0.000091581, Loss: 1.139436, Time/step: 11.205296
10/11/2023 04:24:52 - INFO -   Epoch: 2/10, Step: 126/143, Lr: 0.000000092-0.000091520, Loss: 1.549038, Time/step: 10.791191
10/11/2023 04:25:02 - INFO -   Epoch: 2/10, Step: 127/143, Lr: 0.000000091-0.000091459, Loss: 1.563397, Time/step: 10.336210
10/11/2023 04:25:13 - INFO -   Epoch: 2/10, Step: 128/143, Lr: 0.000000091-0.000091397, Loss: 1.266692, Time/step: 10.574014
10/11/2023 04:39:14 - INFO -   Epoch: 2/10, Step: 129/143, Lr: 0.000000091-0.000091335, Loss: 1.467171, Time/step: 841.004643
10/11/2023 04:50:10 - INFO -   Epoch: 2/10, Step: 130/143, Lr: 0.000000091-0.000091274, Loss: 1.376285, Time/step: 656.273074
10/11/2023 04:51:56 - INFO -   Epoch: 2/10, Step: 131/143, Lr: 0.000000091-0.000091211, Loss: 1.137796, Time/step: 106.236691
10/11/2023 04:52:00 - INFO -   Epoch: 2/10, Step: 132/143, Lr: 0.000000091-0.000091149, Loss: 1.761018, Time/step: 3.594027
10/11/2023 05:00:12 - INFO -   Epoch: 2/10, Step: 133/143, Lr: 0.000000091-0.000091087, Loss: 1.597676, Time/step: 492.443902
10/11/2023 05:00:14 - INFO -   Epoch: 2/10, Step: 134/143, Lr: 0.000000091-0.000091024, Loss: 1.407488, Time/step: 1.522686
10/11/2023 05:00:16 - INFO -   Epoch: 2/10, Step: 135/143, Lr: 0.000000091-0.000090961, Loss: 1.072650, Time/step: 1.516409
10/11/2023 05:00:17 - INFO -   Epoch: 2/10, Step: 136/143, Lr: 0.000000091-0.000090898, Loss: 1.142083, Time/step: 1.497259
10/11/2023 05:00:19 - INFO -   Epoch: 2/10, Step: 137/143, Lr: 0.000000091-0.000090835, Loss: 1.408007, Time/step: 1.514920
10/11/2023 05:00:20 - INFO -   Epoch: 2/10, Step: 138/143, Lr: 0.000000091-0.000090771, Loss: 1.744396, Time/step: 1.600248
10/11/2023 05:00:22 - INFO -   Epoch: 2/10, Step: 139/143, Lr: 0.000000091-0.000090708, Loss: 1.602698, Time/step: 1.533044
10/11/2023 05:00:54 - INFO -   Epoch: 2/10, Step: 140/143, Lr: 0.000000091-0.000090644, Loss: 1.804065, Time/step: 32.698896
10/11/2023 05:00:55 - INFO -   Epoch: 2/10, Step: 141/143, Lr: 0.000000091-0.000090580, Loss: 1.697112, Time/step: 1.065488
10/11/2023 05:00:57 - INFO -   Epoch: 2/10, Step: 142/143, Lr: 0.000000091-0.000090515, Loss: 1.320280, Time/step: 1.095122
10/11/2023 05:00:58 - INFO -   Epoch: 2/10, Step: 143/143, Lr: 0.000000090-0.000090451, Loss: 1.444303, Time/step: 1.339167
10/11/2023 05:01:00 - INFO -   Epoch 2/10 Finished, Train Loss: 1.474973
10/11/2023 05:01:19 - INFO -   Model saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.1
10/11/2023 05:01:19 - INFO -   Optimizer saved to /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_opt.bin.1
10/11/2023 05:01:19 - INFO -   Eval on val dataset
10/11/2023 07:15:01 - INFO -   sim matrix size: 184, 184
10/11/2023 07:15:01 - INFO -   	 Length-T: 184, Length-V:184
10/11/2023 07:15:01 - INFO -   Text-to-Video:
10/11/2023 07:15:02 - INFO -   	>>>  R@1: 59.8 - R@5: 84.2 - R@10: 89.1 - Median R: 1.0 - Mean R: 4.6
10/11/2023 07:15:02 - INFO -   Video-to-Text:
10/11/2023 07:15:02 - INFO -   	>>>  V2T$R@1: 59.8 - V2T$R@5: 85.9 - V2T$R@10: 90.8 - V2T$Median R: 1.0 - V2T$Mean R: 4.2
10/11/2023 07:15:02 - INFO -   The best model is: /home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42/pytorch_model.bin.1, the R1 is: 59.7826
10/11/2023 08:23:39 - INFO -   Epoch: 3/10, Step: 1/143, Lr: 0.000000090-0.000090386, Loss: 1.013731, Time/step: 4116.428999
10/11/2023 08:23:47 - INFO -   Epoch: 3/10, Step: 2/143, Lr: 0.000000090-0.000090321, Loss: 0.849285, Time/step: 8.195606
10/11/2023 08:23:56 - INFO -   Epoch: 3/10, Step: 3/143, Lr: 0.000000090-0.000090256, Loss: 0.823881, Time/step: 9.039462
10/11/2023 08:26:46 - INFO -   Epoch: 3/10, Step: 4/143, Lr: 0.000000090-0.000090191, Loss: 1.044995, Time/step: 169.778858
10/11/2023 08:26:56 - INFO -   Epoch: 3/10, Step: 5/143, Lr: 0.000000090-0.000090126, Loss: 0.530416, Time/step: 9.488343
10/11/2023 08:27:06 - INFO -   Epoch: 3/10, Step: 6/143, Lr: 0.000000090-0.000090060, Loss: 0.969135, Time/step: 10.302369
10/11/2023 08:27:16 - INFO -   Epoch: 3/10, Step: 7/143, Lr: 0.000000090-0.000089994, Loss: 0.734055, Time/step: 10.296996
10/11/2023 08:47:15 - INFO -   Epoch: 3/10, Step: 8/143, Lr: 0.000000090-0.000089928, Loss: 0.474441, Time/step: 1198.559331
10/11/2023 08:47:26 - INFO -   Epoch: 3/10, Step: 9/143, Lr: 0.000000090-0.000089862, Loss: 0.749984, Time/step: 11.349926
10/11/2023 08:47:38 - INFO -   Epoch: 3/10, Step: 10/143, Lr: 0.000000090-0.000089795, Loss: 0.955082, Time/step: 11.854696
10/11/2023 08:47:51 - INFO -   Epoch: 3/10, Step: 11/143, Lr: 0.000000090-0.000089729, Loss: 0.626638, Time/step: 12.748120
10/11/2023 08:48:04 - INFO -   Epoch: 3/10, Step: 12/143, Lr: 0.000000090-0.000089662, Loss: 1.006542, Time/step: 12.756540
10/11/2023 08:48:17 - INFO -   Epoch: 3/10, Step: 13/143, Lr: 0.000000090-0.000089595, Loss: 0.697274, Time/step: 13.228680
10/11/2023 08:48:30 - INFO -   Epoch: 3/10, Step: 14/143, Lr: 0.000000090-0.000089528, Loss: 0.923446, Time/step: 13.597224
10/11/2023 08:48:45 - INFO -   Epoch: 3/10, Step: 15/143, Lr: 0.000000089-0.000089461, Loss: 0.877087, Time/step: 14.156252
10/11/2023 08:48:59 - INFO -   Epoch: 3/10, Step: 16/143, Lr: 0.000000089-0.000089393, Loss: 1.193058, Time/step: 14.652474
10/11/2023 10:11:12 - INFO -   Epoch: 3/10, Step: 17/143, Lr: 0.000000089-0.000089325, Loss: 0.821544, Time/step: 4932.697639
10/11/2023 10:11:27 - INFO -   Epoch: 3/10, Step: 18/143, Lr: 0.000000089-0.000089257, Loss: 0.976229, Time/step: 14.710765
10/11/2023 10:11:42 - INFO -   Epoch: 3/10, Step: 19/143, Lr: 0.000000089-0.000089189, Loss: 0.872596, Time/step: 14.737063
10/11/2023 10:37:59 - INFO -   Epoch: 3/10, Step: 20/143, Lr: 0.000000089-0.000089121, Loss: 0.886095, Time/step: 1577.942732
10/11/2023 10:38:12 - INFO -   Epoch: 3/10, Step: 21/143, Lr: 0.000000089-0.000089052, Loss: 0.745876, Time/step: 12.614607
10/11/2023 10:38:26 - INFO -   Epoch: 3/10, Step: 22/143, Lr: 0.000000089-0.000088984, Loss: 0.960828, Time/step: 13.543649
10/11/2023 10:38:39 - INFO -   Epoch: 3/10, Step: 23/143, Lr: 0.000000089-0.000088915, Loss: 0.891946, Time/step: 13.585523
10/11/2023 10:53:35 - INFO -   Epoch: 3/10, Step: 24/143, Lr: 0.000000089-0.000088846, Loss: 0.664222, Time/step: 895.483174
10/11/2023 10:53:47 - INFO -   Epoch: 3/10, Step: 25/143, Lr: 0.000000089-0.000088777, Loss: 0.765340, Time/step: 12.492492
10/11/2023 10:54:00 - INFO -   Epoch: 3/10, Step: 26/143, Lr: 0.000000089-0.000088707, Loss: 1.151407, Time/step: 13.195661
10/11/2023 10:54:14 - INFO -   Epoch: 3/10, Step: 27/143, Lr: 0.000000089-0.000088637, Loss: 0.759661, Time/step: 13.190094
10/11/2023 10:54:28 - INFO -   Epoch: 3/10, Step: 28/143, Lr: 0.000000089-0.000088568, Loss: 0.755331, Time/step: 14.173820
10/11/2023 10:54:42 - INFO -   Epoch: 3/10, Step: 29/143, Lr: 0.000000088-0.000088498, Loss: 0.660959, Time/step: 14.278347
10/11/2023 10:54:57 - INFO -   Epoch: 3/10, Step: 30/143, Lr: 0.000000088-0.000088427, Loss: 0.864517, Time/step: 14.513915
10/11/2023 10:55:11 - INFO -   Epoch: 3/10, Step: 31/143, Lr: 0.000000088-0.000088357, Loss: 0.782422, Time/step: 14.657716
10/11/2023 10:55:27 - INFO -   Epoch: 3/10, Step: 32/143, Lr: 0.000000088-0.000088287, Loss: 0.710327, Time/step: 15.292969
10/11/2023 12:42:13 - INFO -   Epoch: 3/10, Step: 33/143, Lr: 0.000000088-0.000088216, Loss: 0.968247, Time/step: 6406.035722
10/11/2023 12:42:23 - INFO -   Epoch: 3/10, Step: 34/143, Lr: 0.000000088-0.000088145, Loss: 0.929795, Time/step: 10.554580
10/11/2023 12:42:34 - INFO -   Epoch: 3/10, Step: 35/143, Lr: 0.000000088-0.000088074, Loss: 0.773308, Time/step: 10.743000
10/11/2023 12:47:12 - INFO -   Epoch: 3/10, Step: 36/143, Lr: 0.000000088-0.000088002, Loss: 0.843943, Time/step: 278.258183
10/11/2023 12:47:22 - INFO -   Epoch: 3/10, Step: 37/143, Lr: 0.000000088-0.000087931, Loss: 0.950313, Time/step: 10.296849
10/11/2023 12:47:34 - INFO -   Epoch: 3/10, Step: 38/143, Lr: 0.000000088-0.000087859, Loss: 0.769665, Time/step: 11.112860
10/11/2023 12:47:45 - INFO -   Epoch: 3/10, Step: 39/143, Lr: 0.000000088-0.000087787, Loss: 0.751435, Time/step: 11.434418
10/11/2023 12:54:36 - INFO -   Epoch: 3/10, Step: 40/143, Lr: 0.000000088-0.000087715, Loss: 0.722812, Time/step: 410.737257
10/11/2023 12:54:48 - INFO -   Epoch: 3/10, Step: 41/143, Lr: 0.000000088-0.000087643, Loss: 0.815174, Time/step: 11.698509
10/11/2023 12:55:00 - INFO -   Epoch: 3/10, Step: 42/143, Lr: 0.000000088-0.000087571, Loss: 1.010381, Time/step: 12.570286
10/11/2023 12:55:13 - INFO -   Epoch: 3/10, Step: 43/143, Lr: 0.000000087-0.000087498, Loss: 1.196869, Time/step: 13.121757
10/11/2023 12:55:27 - INFO -   Epoch: 3/10, Step: 44/143, Lr: 0.000000087-0.000087426, Loss: 0.890375, Time/step: 13.456772
10/11/2023 12:55:41 - INFO -   Epoch: 3/10, Step: 45/143, Lr: 0.000000087-0.000087353, Loss: 0.860914, Time/step: 14.070712
10/11/2023 12:55:55 - INFO -   Epoch: 3/10, Step: 46/143, Lr: 0.000000087-0.000087279, Loss: 1.113778, Time/step: 14.287131
10/11/2023 12:56:10 - INFO -   Epoch: 3/10, Step: 47/143, Lr: 0.000000087-0.000087206, Loss: 1.105139, Time/step: 14.968828
10/11/2023 12:56:25 - INFO -   Epoch: 3/10, Step: 48/143, Lr: 0.000000087-0.000087133, Loss: 0.562028, Time/step: 14.927664
10/11/2023 15:02:06 - INFO -   Epoch: 3/10, Step: 49/143, Lr: 0.000000087-0.000087059, Loss: 0.765033, Time/step: 7540.562911
10/11/2023 15:02:15 - INFO -   Epoch: 3/10, Step: 50/143, Lr: 0.000000087-0.000086985, Loss: 0.832243, Time/step: 9.510004
10/11/2023 15:02:25 - INFO -   Epoch: 3/10, Step: 51/143, Lr: 0.000000087-0.000086911, Loss: 0.806033, Time/step: 9.746197
10/11/2023 15:02:35 - INFO -   Epoch: 3/10, Step: 52/143, Lr: 0.000000087-0.000086837, Loss: 0.470103, Time/step: 9.888524
10/11/2023 15:02:46 - INFO -   Epoch: 3/10, Step: 53/143, Lr: 0.000000087-0.000086763, Loss: 0.659518, Time/step: 10.809667
10/11/2023 15:02:57 - INFO -   Epoch: 3/10, Step: 54/143, Lr: 0.000000087-0.000086688, Loss: 1.079943, Time/step: 11.199096
Traceback (most recent call last):
  File "main_xclip.py", line 555, in <module>
    main()
  File "main_xclip.py", line 529, in main
    tr_loss, global_step = train_epoch(epoch, args, model, train_dataloader, device, n_gpu, optimizer,
  File "main_xclip.py", line 267, in train_epoch
    for step, batch in enumerate(train_dataloader):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1065, in _next_data
    return self._process_data(data)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1111, in _process_data
    data.reraise()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ZeroDivisionError: Caught ZeroDivisionError in DataLoader worker process 6.
Original Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 198, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 188, in __getitem__
    video, video_mask = self._get_rawvideo(choice_video_ids)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 179, in _get_rawvideo
    raise excep
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/dataloader_moviegh_retrieval.py", line 149, in _get_rawvideo
    raw_video_data = self.rawVideoExtractor.get_video_data(video_path)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 85, in get_video_data
    image_input = self.video_to_tensor(video_path, self.transform, sample_fp=self.framerate, start_time=start_time, end_time=end_time)
  File "/home/wiss/zhang/Jinhe/X-CLIP/dataloaders/rawvideo_util.py", line 45, in video_to_tensor
    total_duration = (frameCount + fps - 1) // fps
ZeroDivisionError: integer division or modulo by zero

Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/wiss/zhang/anaconda3/envs/clip4clip/lib/python3.8/site-packages/torch/distributed/launch.py", line 255, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/home/wiss/zhang/anaconda3/envs/clip4clip/bin/python', '-u', 'main_xclip.py', '--local_rank=1', '--do_train', '--num_thread_reader=16', '--epochs=10', '--batch_size=64', '--n_display=1', '--data_path', '/home/wiss/zhang/Jinhe/video-attr-prober/Data/AnetQA/', '--features_path', '/home/wiss/zhang/nfs/Anet-compressed', '--output_dir', '/home/wiss/zhang/nfs/video_prober/xclip/anet_train1_seed42', '--lr', '1e-4', '--max_words', '60', '--max_frames', '12', '--batch_size_val', '64', '--datatype', 'moviegraph', '--feature_framerate', '1', '--coef_lr', '1e-3', '--freeze_layer_num', '0', '--slice_framepos', '2', '--loose_type', '--linear_patch', '2d', '--sim_header', 'seqTransf', '--pretrained_clip_name', 'ViT-B/32', '--manipulation', 'anet_train1_seed42', '--scale', '0', '--dataset_ckpt', 'anet_train1_seed42', '--train_file', 'train_1.csv', '--val_file', 'temporal_contact_swap.csv', '--test_file', 'temporal_contact_swap.csv', '--seed', '42']' returned non-zero exit status 1.
